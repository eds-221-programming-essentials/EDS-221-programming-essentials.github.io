[
  {
    "objectID": "course-materials/day1.html#class-materials",
    "href": "course-materials/day1.html#class-materials",
    "title": "Intro to programming",
    "section": "Class materials",
    "text": "Class materials\n\n\n\n\n\n\n\n\n Session\n Lecture slides\n Interactive session\n\n\n\n\nday 1 / morning\nCourse introduction, programming in EDS, meet our tools\nDon’t fear the Terminal - continuing with some commands, navigation, and more git\n\n\nday 1 / afternoon\nProject oriented workflows, file paths, naming things; good habits from the tidyverse style guide\nMeet here, project organization, adding data import to our workflow"
  },
  {
    "objectID": "course-materials/day1.html#end-of-day-practice",
    "href": "course-materials/day1.html#end-of-day-practice",
    "title": "Intro to programming",
    "section": "End-of-day practice",
    "text": "End-of-day practice\nComplete the following tasks / activities before heading home for the day!\n\n Day 1 Practice: Project organization, data import, file paths"
  },
  {
    "objectID": "course-materials/day1.html#additional-resources",
    "href": "course-materials/day1.html#additional-resources",
    "title": "Intro to programming",
    "section": "Additional Resources",
    "text": "Additional Resources\nTBD"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-1b.html",
    "href": "course-materials/interactive-sessions/interactive-session-1b.html",
    "title": "Interactive Session 1B",
    "section": "",
    "text": "Fork and clone this repo\nCheck out the project structure & files"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-1b.html#setup",
    "href": "course-materials/interactive-sessions/interactive-session-1b.html#setup",
    "title": "Interactive Session 1B",
    "section": "",
    "text": "Fork and clone this repo\nCheck out the project structure & files"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-1b.html#file-path-practice",
    "href": "course-materials/interactive-sessions/interactive-session-1b.html#file-path-practice",
    "title": "Interactive Session 1B",
    "section": "2. File path practice",
    "text": "2. File path practice\n\nWe’ll run through each line in the toolik_airtemp_summary.qmd to understand where it’s pointing, what it’s doing, and add a few more tools to our coding toolkit (readr::read_csv(), janitor::clean_names(), %&gt;%)\nSimilarly, we’ll create from scratch & work through one more example. We will:\n\nRead in the chlorophyll data\nExplore the imported data\nClean up the dataset names\nCreate a plot of chlorophyll concentration at varying measurement depth, do some customization\nExport the graph to /figs\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n# read in data\ntoolik_chlorophyll &lt;- read_csv(here::here(\"data\", \"data-raw\", \"toolik_chlorophyll.csv\"))\n\n# get data overview\nskimr::skim(toolik_chlorophyll)\n\ndim(toolik_chlorophyll)\nnames(toolik_chlorophyll)\n\n# clean names\ntoolik_chlorophyll &lt;- toolik_chlorophyll %&gt;% clean_names() \n\nna_if(toolik_chlorophyll$active_chl_a_ug_l, \".\") \n\ntoolik_chlorophyll$active_chl_a_ug_l &lt;- as.numeric(toolik_chlorophyll$active_chl_a_ug_l)\n\n# make plot\ntoolik_chlorophyll_plot &lt;- ggplot(data = toolik_chlorophyll, \n                                  aes(x = depth, y = as.numeric(active_chl_a_ug_l))) +\n  geom_point() +\n  theme_minimal() +\n  labs(title = \"Toolik Station Chlorophyll a concentration\",\n       x = \"Depth (m)\",\n       y = \"Chlorophyll a concentration (micrograms per liter)\")\n\ntoolik_chlorophyll_plot\n\n# save plot\nggsave(here::here(\"figs\", \"toolik_chlorophyll_plot.png\"), height = 6, width = 7)\n\n\n\n\n\n\n\n\n\n\nData sources\n\n\n\nAll datasets are collected and provided by scientists with the Toolik Station Long Term Ecological Research (LTER) site, Alaska.\nToolik Station Meteorological Data: toolik_weather.csv Shaver, G. 2019. A multi-year DAILY weather file for the Toolik Field Station at Toolik Lake, AK starting 1988 to present. ver 4. Environmental Data Initiative. https://doi.org/10.6073/pasta/ce0f300cdf87ec002909012abefd9c5c (Accessed 2021-08-08).\nToolik Lake Chlorophyll: toolik_chlorophyll.csv Miller, M. 2014. Chlorophyll A, and primary productivity of Toolik lake , Arctic LTER 1975 to 1988, Toolik Filed Station, Alaska. ver 5. Environmental Data Initiative. https://doi.org/10.6073/pasta/6738024bf0174f73b3f74486f43d1059 (Accessed 2021-08-08).\nToolik fish: toolik_fish.csv Budy, P., C. Luecke, and M. McDonald. 2020. Fish captures in lakes of the Arctic LTER region Toolik Field Station Alaska from 1986 to present. ver 6. Environmental Data Initiative. https://doi.org/10.6073/pasta/d0a9358f783339821b82510eb8c61b45 (Accessed 2021-08-08).\n\n\n\nEnd Interactive Session 1B"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-1a.html",
    "href": "course-materials/interactive-sessions/interactive-session-1a.html",
    "title": "Interactive Session 1A",
    "section": "",
    "text": "Source materials\n\n\n\nThese materials are modified from the following source:\nS. Jeanette Clark, Matthew B. Jones, Samantha Csik, Carmen Galaz García, Bryce Mecum, Natasha Haycock-ChavezDaphne Virlar-Knight. 2022. Scalable and Computationally Reproducible Approaches to Arctic Research.\nhttps://learning.nceas.ucsb.edu/2022-09-arctic/"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-1a.html#commonly-used-and-very-helpful-bash-commands",
    "href": "course-materials/interactive-sessions/interactive-session-1a.html#commonly-used-and-very-helpful-bash-commands",
    "title": "Interactive Session 1A",
    "section": "1. Commonly used (and very helpful) bash commands",
    "text": "1. Commonly used (and very helpful) bash commands\nBelow are just a few bash commands that you’re likely to use. Some may be extended with options (more on that in the next section) or even piped together (i.e. where the output of one command gets sent to the next command, using the | operator). You can also find some nice bash cheat sheets online, like this one. Alternatively, the Bash Reference Manual has all the content you need, albeit a bit dense.\n\n\n\n\n\n\n\nbash command\nwhat it does\n\n\n\n\npwd\nprint your current working directory\n\n\ncd\nchange directory\n\n\nls\nlist contents of a directory\n\n\ntree\ndisplay the contents of a directory in the form of a tree structure (not installed by default)\n\n\necho\nprint text that is passed in as an argument\n\n\nmv\nmove or rename a file\n\n\ncp\ncopy a file(s) or directory(ies)\n\n\ntouch\ncreate a new empty file\n\n\nmkdir\ncreate a new directory\n\n\nrm/rmdir\nremove a file/ empty directory (be careful – there is no “trash” folder!)\n\n\ngrep\nsearches a given file(s) for lines containing a match to a given pattern list\n\n\nawk\na text processing language that can be used in shell scripts or at a shell prompt for actions like pattern matching, printing specified fields, etc.\n\n\nsed\nstands for Stream Editor; a versatile command for editing files\n\n\ncut\nextract a specific portion of text in a file\n\n\njoin\njoin two files based on a key field present in both\n\n\ntop, htop\nview running processes in a Linux system (press Q to quit)"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-1a.html#general-command-syntax",
    "href": "course-materials/interactive-sessions/interactive-session-1a.html#general-command-syntax",
    "title": "Interactive Session 1A",
    "section": "2. General command syntax",
    "text": "2. General command syntax\nBash commands are typically are written as: command [options] [arguments] where the command must be an executable on your PATH and where options (settings that change the shell and/or script behavior) take one of two forms: short form (e.g. command -option-abbrev) or long form (e.g. command --option-name or command -o option-name). An example:\n# the `ls` command lists the files in a directory\nls file/path/to/directory\n\n# adding on the `-a` or `--all` option lists all files (including hidden files) in a directory\nls -a file/path/to/directory # short form\nls --all file/path/to/directory # long form\nls -o all file/path/to/directory # long form"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-1a.html#some-useful-keyboard-shortcuts",
    "href": "course-materials/interactive-sessions/interactive-session-1a.html#some-useful-keyboard-shortcuts",
    "title": "Interactive Session 1A",
    "section": "3. Some useful keyboard shortcuts",
    "text": "3. Some useful keyboard shortcuts\nIt can sometimes feel messy working on the command line. These keyboard shortcuts can make it a little easier:\n\nCtrl + L: clear your terminal window\nCtrl + U: delete the current line\nCtrl + C: abort a command\nup & down arrow keys: recall previously executed commands in chronological order\nTAB key: autocompletion"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-1a.html#practice-using-some-common-bash-commands",
    "href": "course-materials/interactive-sessions/interactive-session-1a.html#practice-using-some-common-bash-commands",
    "title": "Interactive Session 1A",
    "section": "4. Practice using some common bash commands",
    "text": "4. Practice using some common bash commands\n\nUse the pwd command to print your current location, or working directory. You should be in your home directory on the server (e.g. /home/yourusername).\nUse the ls command to list the contents (any files or subdirectories) of your home directory\nUse the mkdir command to create a new directory named bash_practice:\n\nmkdir bash_practice\n\nUse the cd command to move into your new bash_practice directory:\n\n# move from /home/yourusername to home/yourusername/bash_practice\ncd bash_practice\n\nTo move up a directory level, use two dots, .. :\n\n# move from /home/yourusername/bash_practice back to /home/yourusername\n$ cd ..\n\n\n\n\n\n\nNote\n\n\n\nTo quickly navigate back to your home directory from wherever you may be on your computer, use a tilde, ~ :\n# e.g. to move from from some subdirectory, /home/yourusername/Projects/project1/data, back to your home directory, home/yourusername\n$ cd ~\n\n# or use .. to back out three subdirectories\n$ cd ../../..\n\n\n\nAdd some .txt files (file1.txt, file2.txt, file3.txt) to your bash_practice subdirectory using the touch command (Note: be sure to cd into bash_practice if you’re not already there):\n\n# add one file at a time\ntouch file1.txt\ntouch file2.txt\ntouch file3.txt\n\n# or add all files simultanously like this:\ntouch file{1..3}.txt\n\n# or like this:\ntouch file1.txt file2.txt file3.txt\n\nYou can also add other file types (e.g. .py, .csv, etc.)\n\ntouch mypython.py mycsv.csv\n\nPrint out all the .txt files in bash_practice using a wildcard, *:\n\nls *.txt\n\nCount the number of .txt files in bash_practice by combining the ls and wc (word count) funtions using the pipe, |, operator:\n\n# `wc` returns a word count (lines, words, chrs)\n# the `-l` option only returns the number of lines\n# use a pipe, `|`, to send the output from `ls *.txt` to `wc -l`\nls *.txt | wc -l\n\nDelete mypython.py using the rm command:\n\nrm mypython.py \n\nCreate a new directory inside bash_practice called data and move mycsv.csv into it.\n\nmkdir data\nmv mycsv.csv ~/bash_practice/data\n\n# add the --interactive option (-i for short) to prevent a file from being overwritten by accident (e.g. in case there's a file with the same name in the destination location)\nmv -i mycsv.csv ~/bash_practice/data\n\nUse mv to rename mycsv.csv to mydata.csv\n\nmv mycsv.csv mydata.csv\n\nAdd column headers col1, col2, col3 to mydata.csv using echo + the &gt; operator\n\necho \"col1, col2, col3\" &gt; mydata.csv\n\n\n\n\n\n\nTip\n\n\n\nYou can check to see that mydata.csv was updated using GNU nano, a text editor for the command line that comes preinstalled on Linux machines (you can edit your file in nano as well). To do so, use the nano command followed by the file you want to open/edit:\nnano mydata.csv\nTo save and quit out of nano, use the control + X keyboard shortcut.\nYou can also create and open a file in nano in just one line of code. For example, running nano hello_world.sh is the same as creating the file first using touch hello_world.sh, then opening it with nano using nano hello_world.sh.\n\n\n\nAppend a row of data to mydata.csv using echo + the &gt;&gt; operator\n\n# using `&gt;` will overwrite the contents of an existing file; `&gt;&gt;` appends new information to an existing file\necho \"1, 2, 3\" &gt;&gt; mydata.csv"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-1a.html#git-via-a-shell",
    "href": "course-materials/interactive-sessions/interactive-session-1a.html#git-via-a-shell",
    "title": "Interactive Session 1A",
    "section": "5. Git via a shell",
    "text": "5. Git via a shell\nGit, a popular version control system and command line tool can be accessed via a shell. While there are lots of graphical user interfaces (GUIs) that faciliatate version control with Git, they often only implement a small subset of Git’s most-used functionality. By interacting with Git via the command line, you have access to all Git commands. While all-things Git is outside the scope of this workshop, we will use some basic Git commands in the shell to clone GitHub (remote) repositories to the server and save/store our changes to files. A few important Git commands:\n\n\n\n\n\n\n\nGit command\nwhat it does\n\n\n\n\ngit clone\ncreate a copy (clone) of repository in a new directory in a different location\n\n\ngit add\nadd a change in the working directory to the staging area\n\n\ngit commit\nrecord a snapshot of a repository; the -m option adds a commit message\n\n\ngit push\nsend commits from a local repository to a remote repository\n\n\ngit fetch\ndownloads contents (e.g. files, commits, refs) from a remote repo to a local repo\n\n\ngit pull\nfetches contents of a remote repo and merges changes into the local repo\n\n\n\n\nEnd Interactive Session 1A"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-4.html",
    "href": "course-materials/interactive-sessions/interactive-session-4.html",
    "title": "Interactive Session 4",
    "section": "",
    "text": "Let’s check out documentation for a few basic functions in R. This will help us get an idea of the type of features we may want to add to our functions in the future, and to familiarize ourselves with how to read and understand function documentation (which can admittedly be…a lot).\n\n\nTo see documentation for R functions, run ?functionname. This should bring up the function documentation in the Help tab in RStudio. For example, try running ?min.\nWhat are the different pieces in the documentation?\n\nDescription: gives an overview of what the function does\nUsage: shows general usage and default behaviors\nArguments: the arguments…\nDetails: any other details…\nValue: information about the output returned\nExamples: selected examples (but also…Google it)\n\n\n\n\nTo see function documentation in Python, run help(functionname). This will bring up a new window with information about the function (press q to escape). For example, try running help(min) in the Python interpreter."
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-4.html#learning-from-existing-functions",
    "href": "course-materials/interactive-sessions/interactive-session-4.html#learning-from-existing-functions",
    "title": "Interactive Session 4",
    "section": "",
    "text": "Let’s check out documentation for a few basic functions in R. This will help us get an idea of the type of features we may want to add to our functions in the future, and to familiarize ourselves with how to read and understand function documentation (which can admittedly be…a lot).\n\n\nTo see documentation for R functions, run ?functionname. This should bring up the function documentation in the Help tab in RStudio. For example, try running ?min.\nWhat are the different pieces in the documentation?\n\nDescription: gives an overview of what the function does\nUsage: shows general usage and default behaviors\nArguments: the arguments…\nDetails: any other details…\nValue: information about the output returned\nExamples: selected examples (but also…Google it)\n\n\n\n\nTo see function documentation in Python, run help(functionname). This will bring up a new window with information about the function (press q to escape). For example, try running help(min) in the Python interpreter."
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-4.html#basic-pieces-of-a-function",
    "href": "course-materials/interactive-sessions/interactive-session-4.html#basic-pieces-of-a-function",
    "title": "Interactive Session 4",
    "section": "2. Basic pieces of a function",
    "text": "2. Basic pieces of a function\n\nComponents of a function\nFrom Chapter 19 - Functions in R for Data Science: “There are three key steps to creating a new function:\n\nYou need to pick a name for the function.\nYou list the inputs, or arguments, to the function inside function.\nYou place the code you have developed in body of the function.”"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-4.html#getting-started---function-examples-in-r-python",
    "href": "course-materials/interactive-sessions/interactive-session-4.html#getting-started---function-examples-in-r-python",
    "title": "Interactive Session 4",
    "section": "3. Getting started - function examples in R & Python",
    "text": "3. Getting started - function examples in R & Python\n\nExample 1 (from lecture slides)\nThe bird-dog sum example in R:\n\nbirddog_sum &lt;- function(bird, dog) {\n  pets = bird + dog\n  return(pets)\n}\n\n# Use it! \nbirddog_sum(bird = 2, dog = 5)\n\n[1] 7\n\n\nThe bird-dog sum example in Python:\n\ndef birddog_sum(bird, dog):\n  pets = bird + dog\n  return(pets)\n  \nbirddog_sum(bird = 10, dog = 99)\n\n109\n\n\nNote the similarities and differences in syntax between R and Python functions.\n\n\nExample 2\nMake a function called double_it that doubles any value input value.\nIn R:\n\n# Create the function: \ndouble_it &lt;- function (x) {\n  print(2 * x)\n}\n\n# Try it out! \ndouble_it(24) \n\n[1] 48\n\n# And on a vector, still works: \ndouble_it(c(1, 0.5, -200))\n\n[1]    2    1 -400\n\n\nIn Python:\n\nimport numpy as np\n\ndef double_it(x):\n  print(2 * x)\n  \ndouble_it(25)\n\n50\n\n# Create a vector (NumPy array)\nv = np.array([4, 1])\n\n# Use the function to double all elements in the vector: \ndouble_it(v)\n\n[8 2]\n\n# Question: what if you apply double_it() to a LIST in Python? \nw = [3,5,8]\n\ndouble_it(w) # Note this behavior - lists & tuples are operated on differently than NumPy arrays / vectors! \n\n[3, 5, 8, 3, 5, 8]\n\n\n\n\nExample 3\nWrite a function that returns the statement “I am ___ years old!”, where the blank is entered by the user as argument age.\nIn R:\n\nexclaim_age &lt;- function(age) {\n  print(paste(\"I am\", age, \"years old!\"))\n}\n\nexclaim_age(age = 10)\n\n[1] \"I am 10 years old!\"\n\n\nIn Python:\n\ndef exclaim_age(age):\n  print(\"I am\", str(age), \"years old!\")\n  \nexclaim_age(age = 2)\n\nI am 2 years old!\n\n\n\n\nprint() versus return()\nWhat’s the difference between print() and return()?. The print() function just makes something visible to us. It does not get stored for later use. If we want an output to be stored for use, we use return().\n\n\n\n\n\n\nWhat?\n\n\n\n\n\nYeah the difference can be kind of tricky, because it sometimes seems like when we use print() it has stored something. Let’s check out an example that highlights the difference.\n\n\n\n\nExample 4\nA Python example:\n\ndef find_max(val_1, val_2):\n  if (val_1 &gt; val_2):\n    return(val_1)\n  elif (val_2 &gt; val_1):\n    return(val_2)\n\n# We can use that returned output for another calculation: \n5 * find_max(7, 3)\n\n35\n\n\nWhat happens if instead of return() we’d used print() here?\n\ndef find_max(val_1, val_2):\n  if (val_1 &gt; val_2):\n    print(val_1)\n  elif (val_2 &gt; val_1):\n    print(val_2)\n  \n# And when we try to use output for something else: \n5 * find_max(7, 3)"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-4.html#functions-with-conditionals",
    "href": "course-materials/interactive-sessions/interactive-session-4.html#functions-with-conditionals",
    "title": "Interactive Session 4",
    "section": "4. Functions with conditionals",
    "text": "4. Functions with conditionals\nSimilar to for loops, we can have conditionals within functions - this means that what the function does with arguments will change based on what those argument values are.\n\nExample\nReturning to an example that we saw previously, let’s say we want to make a function that returns the age of an animal in animal years, given the species and age in human years. For example: 1 human year = 7 dog years, and 1 human year = 4.7 goat years.\nWrite a function with two arguments: animal and age, which converts the animal’s age from human to animal years.\nIn R:\n\nanimal_age &lt;- function(animal, age) {\n  if (animal == \"dog\") {\n    print(age * 7)\n  } else if (animal == \"goat\") {\n    print(age * 4.7)\n  } \n}\n\n# Try an 8 year old dog.\nanimal_age(animal = \"dog\", age = 8)\n\n[1] 56\n\n# Try a cow & see what is returned. What happens? Consider.\nanimal_age(animal = \"cow\", age = 12)\n\n# Try a dog that is \"yellow\" years old:\n# animal_age(animal = \"dog\", age = \"yellow\")\n\n\n\n\n\n\n\nCritical thinking\n\n\n\n\n\nWhat if the input isn’t dog or goat? Remember this question - we’ll return to it later on.\nA question to keep in mind: it’s easy enough to manually code in the animal species and conversion factor since we only have two animals. Would we want to manually write this out if we had 20 species? 50 species?\n\n\n\nIn Python:\n\ndef animal_age(animal, age):\n  if (animal == \"dog\"):\n    print(age * 7)\n  elif (animal == \"goat\"):\n    print(age * 4.7)\n    \nanimal_age(animal = \"dog\", age = 15)\n\n105\n\n\n\n\nExample\nLet’s say we have a table of the dogs’ favorite foods.\n\n\n# A tibble: 4 × 2\n  dog_name food      \n  &lt;chr&gt;    &lt;chr&gt;     \n1 Khora    everything\n2 Teddy    salmon    \n3 Waffle   pancakes  \n4 Banjo    chicken   \n\n\nWrite a function that only requires the dog name as an input, then automatically pulls information from the data frame (stored as dog_choice) to return the phrase “My name is _____ and I love eating ____!”\nHere I’ll introduce a new function: dplyr::filter(). This is a fantastic function for creating subsets from our data. We’re going to be using it a LOT in our data wrangling lessons last week. For now, know that it returns a logical TRUE or FALSE based on whether or not elements in a vector satisfy the conditions.\nLet’s talk through what this code is actually doing:\n\ndog_menu &lt;- function(name) {\n  my_sub &lt;- dplyr::filter(dog_choice, dog_name == name)\n  print(paste(\"My name is\", my_sub$dog_name, \"and my favorite food is\", my_sub$food))\n}\n\n# Try it! What is Waffle's favorite food?\ndog_menu(name = \"Waffle\")\n\n[1] \"My name is Waffle and my favorite food is pancakes\"\n\n# And Khora? \ndog_menu(name = \"Khora\")\n\n[1] \"My name is Khora and my favorite food is everything\"\n\n\nAha - now we can see that we don’t have to write out every value in our function! We can pull elements directly from a table to switch parameters based on user selection / inputs!"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-4.html#functions-meet-for-loops",
    "href": "course-materials/interactive-sessions/interactive-session-4.html#functions-meet-for-loops",
    "title": "Interactive Session 4",
    "section": "5. Functions meet for loops",
    "text": "5. Functions meet for loops\nSometimes, we’ll want to iterate over different elements of a data structure (e.g. data frame columns), applying a function we write to each of them. We’ve learned a couple of coder-friendly tools to loop over columns (e.g. apply, purrr::map()), but let’s write one from scratch first.\n\nExample\nWrite a function that iterates over each column in a data frame (name gets specified), calculating the mean value for each and returning the phrase “The mean value of (column name) is _____.”\nNote: the colnames() function in base R returns column names.\n\ndf_means &lt;- function(df) {\n  for (i in 1:ncol(df)) {\n    col_mean &lt;- mean(df[[i]])\n    column_name &lt;- colnames(df[i])\n    print(paste(\"The mean value of\", column_name, \"is\", col_mean))\n  }\n}\n\ndf_means(df = mtcars)\n\n[1] \"The mean value of mpg is 20.090625\"\n[1] \"The mean value of cyl is 6.1875\"\n[1] \"The mean value of disp is 230.721875\"\n[1] \"The mean value of hp is 146.6875\"\n[1] \"The mean value of drat is 3.5965625\"\n[1] \"The mean value of wt is 3.21725\"\n[1] \"The mean value of qsec is 17.84875\"\n[1] \"The mean value of vs is 0.4375\"\n[1] \"The mean value of am is 0.40625\"\n[1] \"The mean value of gear is 3.6875\"\n[1] \"The mean value of carb is 2.8125\"\n\n\n\n\n\n\n\n\nCritical thinking\n\n\n\n\n\nWhy only the single square brackets to refer to the column names here? Try it! What is returned when we use colnames(mtcars[2]) versus colnames(mtcars[[2]])?\n\n\n\nSo, will this actually work on other data frames? Let’s make one!\n\nthe_fish &lt;- tribble(\n  ~brown, ~rainbow, ~cutthroat,\n  16.2, 12.1, 21.9,\n  24.7, 14.6, 18.3,\n  12.1, 15.4, 30.2,\n  10.4, 11.8, 26.3\n)\n\ndf_means(df = the_fish)\n\n[1] \"The mean value of brown is 15.85\"\n[1] \"The mean value of rainbow is 13.475\"\n[1] \"The mean value of cutthroat is 24.175\""
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-4.html#adding-helpful-error-and-warning-messages",
    "href": "course-materials/interactive-sessions/interactive-session-4.html#adding-helpful-error-and-warning-messages",
    "title": "Interactive Session 4",
    "section": "6. Adding helpful error and warning messages",
    "text": "6. Adding helpful error and warning messages\nWe now know a bit about writing functions. But we also want them to be as helpful as possible - meaning that we need to create useful error messages, documentation and tests. We’ll start by adding some stop() statements to create error messages.\nFirst, it’s important when designing a function to think about what will make it fail. For example, if a function does an age conversion on a number, what happens if the user inputs a character? What happens if a user only enters one argument value, but the function requires two? Let’s take a look at some examples for adding error messages.\n\nAdding error messages with conditional checks + stop()\nReturning to our function to convert animal ages:\n\nanimal_age &lt;- function(animal, age) {\n  if (animal == \"dog\") {\n    print(age * 7)\n  } else if (animal == \"goat\") {\n    print(age * 4.7)\n  }\n}\n\nWe want to add some error messages that are helpful to the user of the function. We’ll use the stop() function\n\nanimal_age_stop &lt;- function(animal, age) {\n  \n  if (!animal %in% c(\"dog\", \"goat\")) {\n    stop(\"Oops! Animal must be a dog or a goat.\")\n  }\n  \n  if (is.numeric(age) == FALSE) {\n    stop(\"The age must be a number between 0 and 100\")\n  }\n  \n  if (age &lt;= 0) {\n    stop(\"Age must be a number greater than zero.\")\n  }\n  \n  if (animal == \"dog\") {\n    print(age * 7)\n  } else if (animal == \"goat\") {\n    print(age * 4.7)\n  }\n}\n\n\n\nAdding warning messages\nSometimes, you still want code to run (i.e., not throw an error message and stop), but there might be something suspicious about the inputs or outputs that you’d want to alert the user about. For example, maybe you’ll flag an input for dog age if the person adds a value over 22 years - it won’t not work, but it’ll give a friendly heads up that that’s a very old dog, are you sure that’s the value you wanted to enter?\nWe can add warning messages to functions in R using warning(). Keep in mind that the function will still run - this is very different than a hard stop from an error message.\nExample: Betz’ Limit\nThe full power in wind hitting a turbine is:\n\\[P = 0.5\\rho Av^3\\]\nwhere \\(P\\) is power in Watts (joules/second), \\(\\rho\\) is the air density (kg/m3), \\(A\\) is the area covered by the turbine blades (square meters), and \\(v\\) is the wind velocity (m/s).\nHowever, the Betz Limit means that turbines can only collect ~60% of the total wind power, which updates the theoretical “collectable” power (before accounting for inefficiencies, losses, etc.) to:\n\\[P = 0.3\\rho Av^3\\]\nWrite a function to calculate maximum collectable wind power (Watts) by a turbine requiring three inputs:\n\nAir density (in kg/m3)\nRotor radius (in meters)\nWind velocity (in m/s)\n\nAdd the following errors and warnings:\n\nA warning if the windspeed entered is &gt; 130 (m/s)\nA warning if the air density is &gt; 1.225 kg / m3 (air density at sea level)\nAn error if the rotor radius is &lt; 0\n\n\ncalc_windpower &lt;- function(rho, radius, windspeed) {\n  \n  if (windspeed &gt; 130) {\n    warning(\"Whoa, that's a high windspeed! Are you sure that's correct?\")\n  }\n  \n  if (rho &gt; 1.225) {\n    warning(\"That air density is suspicious.\")\n  }\n  \n  if (radius &lt; 0) {\n    stop(\"Rotor radius must be a positive value (meters).\")\n  }\n  \n  0.3*rho*pi*(radius^2)*(windspeed^3)\n  \n}\n\nNow test your function with different inputs. Are your messages working?"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-4.html#a-few-more-interesting-functions",
    "href": "course-materials/interactive-sessions/interactive-session-4.html#a-few-more-interesting-functions",
    "title": "Interactive Session 4",
    "section": "7. A few more interesting functions",
    "text": "7. A few more interesting functions\n\nPulling values from a data frame example\n\n# Let's create a data frame:\n\n\n# Now let's write a function that automatically switches depth based on\ngw_rate &lt;- function(site) {\n  \n  # Stored parameters for 4 different sites\n  gw_depths &lt;- data.frame(sitename = c(\"mountain\", \"prairie\", \"desert\", \"beach\"),\n                 depth = c(32, 41, 63, 2),\n                 slope = c(11.2, 0.4, 0.8, 2.6))\n  \n  # Subset for just that site information (creates a 1-row data frame)\n  site_select &lt;- filter(gw_depths, sitename == site)\n  \n  # Calculate using values from that 1-row data frame\n  transport_rate &lt;- 1.4 * site_select$slope + 3.6 * site_select$depth\n \n  # Return the output\n  return(transport_rate)\n  \n}\n\ngw_rate(site = \"beach\")\n\n[1] 10.84\n\n# Alternatively, with switch()\n\ngw_rate_switch &lt;- function(site) {\n  \n  # Stored parameters for 4 different sites\n  gw_depths &lt;- switch(site, \n                      \"mountain\" = c(32, 11.2),\n                      \"prairie\" = c(41, 0.4),\n                      \"desert\" = c(63, 0.8),\n                      \"beach\" = c(2, 2.6))\n  \n  # Calculate using values from that 1-row data frame\n  transport_rate &lt;- 1.4 * gw_depths[2] + 3.6 * gw_depths[1]\n \n  # Return the output\n  return(transport_rate)\n  \n}\n\n\ngw_rate_switch(\"beach\")\n\n[1] 10.84\n\n\n\n\nLogistic growth example\n\nLogistic growth equation (within a for loop where growth rate changes)\nSinusoidal function with varying parameters\n\n\n\nLogistic growth equation\nIn EDS 212, we learned about the logistic growth equation:\n\\[N_t=\\frac{K}{1+[\\frac{K-N_0}{N_0}]e^{-rt}}\\]\nWhere \\(N_0\\) is the initial population size at time (\\(t\\)) 0, \\(K\\) is the carrying capacity, \\(r\\) is the population growth rate, and \\(N_t\\) is the population size at time \\(t\\).\nFirst, let’s write write the bare-bones function:\n\n# Build & check the minimum function\nlogistic_growth &lt;- function(N0, K, r, time) {\n  Nt &lt;- K / (1 + ((K - N0) / N0) * exp(-r * time))\n  print(Nt)\n}\n\n# Do the values check out when you test this? \nlogistic_growth(N0 = 100, K = 6000, r = 0.27, time = 40)\n\n[1] 5992.787\n\n\nCool. So this seems to be working when we assign single values for the different parameters.\nNow, let’s explore what this looks like over a whole sequence of times (e.g. from t = 0 to t = 40):\n\n# Create a vector of times:\ntime_vec &lt;- seq(from = 0, to = 35, by = 0.1)\n\n# Apply the logistic growth function to that vector of times (& store):\npop_35 &lt;- logistic_growth(N0 = 100, K = 6000, r = 0.27, time = time_vec)\n\n# Bind together the time_vec and population:\npop_time_35 &lt;- data.frame(time_vec, pop_35)\n\n# Always take a look at it\n# View(pop_time_35)\n\n# Alternatively with an inner for loop: \npop_35_vec &lt;- vector(mode = \"numeric\", length = length(time_vec))\n\nfor(i in seq_along(time_vec)) {\n  population &lt;- logistic_growth(N0 = 100, K = 6000, r = 0.27, time = time_vec[i])\n  pop_35_vec[i] &lt;- population\n}\n\nNow, a graph of the output:\n\n# Make a little graph: \nggplot(data = pop_time_35, aes(x = time_vec, y = pop_35)) +\n  geom_line(size = 0.5)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\nBut we can imagine that we may want to ask: What does this look like as we change the initial population size? Or the growth rate? Etc.\nIn that case, we may want to apply our function over a range of growth rates (from 0.20 to 0.40, by increments of 0.01), for the time sequence we used here (0 to 35).\n\n# Create a sequence of growth rate values: \nr_seq &lt;- seq(from = 0.20, to = 0.40, by = 0.01)\n\nCreate a nested for loop!\n\n# Create a for loop that goes through each, apply the \n# logistic growth function for a range of times for each growth rate\n\n# Need to create a MATRIX to store the outputs in: \nout_matrix &lt;- matrix(nrow = length(time_vec), ncol = length(r_seq))\n\n# Now, a nested for loop:\nfor (i in seq_along(r_seq)) { # Outer loop is the growth rates\n  for (j in seq_along(time_vec)) { # Inner loop is the time sequence values\n  pop &lt;- logistic_growth(N0 = 100, K = 6000, r = r_seq[i], time = time_vec[j])\n  out_matrix[j, i] &lt;- pop # Store the value in the appropriate row & column\n  } \n}\n\nNow some wrangling so we can visualize it:\n\n# Let's wrangling it a little bit \nout_df &lt;- data.frame(out_matrix, time = time_vec) # Make it a data frame and add time\n\n# Update the column names of out_df, keeping time column name the same\ncolnames(out_df) &lt;- c(paste0(\"gr_\", r_seq), \"time\")\n\n# pivot_longer to make it tidy (you'll learn more about this next week)\nout_df_long &lt;- out_df %&gt;% \n  pivot_longer(cols = -time, names_to = \"growth_rate\", values_to = \"population\")\n\n# Then plot it: \nggplot(data = out_df_long, aes(x = time, y = population)) +\n  geom_line(aes(color = growth_rate)) +\n  theme_minimal()"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-4.html#testing-functions-with-testthat",
    "href": "course-materials/interactive-sessions/interactive-session-4.html#testing-functions-with-testthat",
    "title": "Interactive Session 4",
    "section": "8. Testing functions with {testthat}",
    "text": "8. Testing functions with {testthat}\nAs we develop algorithms, we’ll change our code. We want a way to automatically check our function to make sure it’s behaving as expected. The testthat package “tries to make testing as fun as possible.”\nUnit test: A unit test is an automated check of a piece (“unit”) of your code\nLet’s consider an example. We’re writing a function to find the mean value of each column, then return the lowest and highest mean calculated (in that order). We would expect:\n\nThe outcome to be a numeric vector of length 2\nWhere the first value in the vector is smaller than the second value in that vector\n\nLet’s write the function, then some accompanying tests to make sure they’re working.\n\nmean_range &lt;- function(df) {\n  col_means &lt;- map_df(df, .f = mean) # Returns column means as a df\n  col_mean_max &lt;- max(col_means) # Looks for the maximum value\n  col_mean_min &lt;- min(col_means) # Looks for the minimum value\n  print(c(col_mean_min, col_mean_max))\n}\n\n# Try it out:\nmean_range(df = mtcars)\n\n[1]   0.40625 230.72188\n\n\nOK great. But we’re doing some work on this code, and we don’t want to have to try a bunch of different things manually each time we change it to see how it breaks. Instead, we’ll write some automated tests for this function that help us avoid that (tomorrow!).\n\nEnd Interactive Session 4\n\n\n\n\n\n\n\nExtra examples\n\n\n\n\n\nWhat’s the output of this nested for loop?\n\napples &lt;- c(1, 2, 3, 4)\nprice &lt;- c(7, 10, 25)\n\nfruit_out &lt;- matrix(nrow = length(price), ncol = length(apples))\n\nfor (i in seq_along(apples)) {\n  for (j in seq_along(price)) {\n    total_cost &lt;- price[j] * apples[i]\n    fruit_out[j, i] &lt;- total_cost\n  }\n}\n\nfruit_out\n\n     [,1] [,2] [,3] [,4]\n[1,]    7   14   21   28\n[2,]   10   20   30   40\n[3,]   25   50   75  100\n\n\n\nfile_prefix &lt;- c(\"temp\", \"ph\", \"salinity\")\nfile_suffix &lt;- c(1, 2, 3, 4, 5)\n\n# First: printing names\nfor (i in seq_along(file_prefix)) {\n  for (j in seq_along(file_suffix)) {\n    print(paste0(file_prefix[i], \"_\", file_suffix[j]))\n  }\n}\n\n[1] \"temp_1\"\n[1] \"temp_2\"\n[1] \"temp_3\"\n[1] \"temp_4\"\n[1] \"temp_5\"\n[1] \"ph_1\"\n[1] \"ph_2\"\n[1] \"ph_3\"\n[1] \"ph_4\"\n[1] \"ph_5\"\n[1] \"salinity_1\"\n[1] \"salinity_2\"\n[1] \"salinity_3\"\n[1] \"salinity_4\"\n[1] \"salinity_5\"\n\n# Second: storing them in a matrix (populated by COLUMN)\nfilename_matrix &lt;- matrix(nrow = length(file_suffix), ncol = length(file_prefix))\n\nfor (i in seq_along(file_prefix)) {\n  for (j in seq_along(file_suffix)) {\n    file_name &lt;- paste0(file_prefix[i], \"_\", file_suffix[j])\n    filename_matrix[j, i] &lt;- file_name\n  }\n}\n\nfilename_matrix\n\n     [,1]     [,2]   [,3]        \n[1,] \"temp_1\" \"ph_1\" \"salinity_1\"\n[2,] \"temp_2\" \"ph_2\" \"salinity_2\"\n[3,] \"temp_3\" \"ph_3\" \"salinity_3\"\n[4,] \"temp_4\" \"ph_4\" \"salinity_4\"\n[5,] \"temp_5\" \"ph_5\" \"salinity_5\"\n\n\n\nAnother for loop example:\n\nquarter_splits &lt;- c(1, 1.1, 1.2, 1.1, 1.4, 1.5, 1.6, 1.4)\n\nhalf_splits &lt;- vector(mode = \"numeric\", length = length(quarter_splits) - 1)\n\n# NOTE FOR CLASS OF 2023: check seq_along here, use 1:(length(quarter_splits) - 1) instead\nfor (i in 1:(length(quarter_splits) - 1)) {\n  half_mile &lt;- quarter_splits[i] + quarter_splits[i + 1]\n  half_splits[i] &lt;- half_mile\n}\n\nhalf_splits\n\n[1] 2.1 2.3 2.3 2.5 2.9 3.1 3.0\n\n\n\ndosage &lt;- c(10, 100, 1000)\n\ndose_index &lt;- vector(mode = \"character\", length = length(dosage))\n\nfor (i in seq_along(dosage)) {\n  k &lt;- paste0(\"zinc_\", dosage[i])\n  dose_index[i] &lt;- k\n}\n\ndose_index\n\n[1] \"zinc_10\"   \"zinc_100\"  \"zinc_1000\"\n\n\n\nodds &lt;- c(1, 3, 5)\nevens &lt;- c(2, 4, 6, 8)\n\nfor (i in seq_along(odds)) {\n  for (j in seq_along(evens)) {\n    print(odds[i] * evens[j])\n  }\n}\n\n[1] 2\n[1] 4\n[1] 6\n[1] 8\n[1] 6\n[1] 12\n[1] 18\n[1] 24\n[1] 10\n[1] 20\n[1] 30\n[1] 40"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-7.html",
    "href": "course-materials/interactive-sessions/interactive-session-7.html",
    "title": "Interactive Session 7",
    "section": "",
    "text": "Create a new version-controlled R Project called eds221-m2021-day7-interactive\nCreate a new R Markdown document in the project\nAttach the following packages in the setup chunk:\n\ntidyverse\npalmerpenguins\nlubridate"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-7.html#setup",
    "href": "course-materials/interactive-sessions/interactive-session-7.html#setup",
    "title": "Interactive Session 7",
    "section": "",
    "text": "Create a new version-controlled R Project called eds221-m2021-day7-interactive\nCreate a new R Markdown document in the project\nAttach the following packages in the setup chunk:\n\ntidyverse\npalmerpenguins\nlubridate"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-7.html#data-wrangling-refresher",
    "href": "course-materials/interactive-sessions/interactive-session-7.html#data-wrangling-refresher",
    "title": "Interactive Session 7",
    "section": "2. Data wrangling refresher",
    "text": "2. Data wrangling refresher\nRefresher 1: Starting with the penguins dataset in the palmerpenguins package, write a single piped sequence in which you:\n\nOnly include penguins at Biscoe and Dream islands\nRemove the year and sex variables\nAdd a new column called body_mass_kg, with penguin mass converted from grams to kilograms\nRename the island variable to location\n\nRefresher 2: Staring with the penguins dataset in the palmerpenguins package, write a single piped sequence in which you:\n\nLimit to only Adelie penguins\nRemove any observations where flipper_length_mm is NA (hint: !is.na())\nGroup the data by sex\nFind the mean (mean()), standard deviation (sd) and sample size (n) of flipper_length_mm for male and female Adelie penguins, returned in a nice summary table"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-7.html#wrangling-continued---joins-of-different-flavors",
    "href": "course-materials/interactive-sessions/interactive-session-7.html#wrangling-continued---joins-of-different-flavors",
    "title": "Interactive Session 7",
    "section": "3. Wrangling continued - joins of different flavors",
    "text": "3. Wrangling continued - joins of different flavors\n\nMutating joins\nLet’s create some data to practice and clarify different types of joins.\n\nInstall the datapasta package in R.\nQuit & restart RStudio.\nCopy the content of the first table below.\nWith your cursor in a code chunk, go up to Addins &gt; Datapasta &gt; as tribble\nAssign the code to object name animals\nSimilarly, copy and datapasta the second table, storing as sites\n\n\n\n\n\n\n\nlocation\nspecies\nmaturity\n\n\n\n\nlagoon\nbobcat\nadult\n\n\nbluff\ncoyote\njuvenile\n\n\ncreek\nfox\nadult\n\n\noaks\nsquirrel\njuvenile\n\n\nbluff\nbobcat\nadult\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlocation\nfull_site_name\njurisdiction\n\n\n\n\nbeach\nGoleta Beach\nSB City\n\n\nlagoon\nUCSB Lagoon\nUCSB\n\n\nbluff\nEllwood Mesa\nSB City\n\n\noaks\nFremont Campground\nUSFS\n\n\n\n\n\n\n\n\n\ndplyr::full_join()\nThe dplyr::full_join() function adds columns from the second df to the first df. It is the safest join - nothing is excluded. When in doubt, full join.\n\nfull_join_example &lt;- full_join(animals, sites)\n\nJoining with `by = join_by(location)`\n\nfull_join_example\n\n# A tibble: 6 × 5\n  location species  maturity full_site_name     jurisdiction\n  &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;              &lt;chr&gt;       \n1 lagoon   bobcat   adult    UCSB Lagoon        UCSB        \n2 bluff    coyote   juvenile Ellwood Mesa       SB City     \n3 creek    fox      adult    &lt;NA&gt;               &lt;NA&gt;        \n4 oaks     squirrel juvenile Fremont Campground USFS        \n5 bluff    bobcat   adult    Ellwood Mesa       SB City     \n6 beach    &lt;NA&gt;     &lt;NA&gt;     Goleta Beach       SB City     \n\n\n\n\ndplyr::left_join()\nThe dplyr::left_join(x,y) function keeps everything in x, and only joins from y (by matching key) if they have a match in x. Otherwise they’re dropped.\n\nleft_join_example &lt;- left_join(animals, sites)\n\nJoining with `by = join_by(location)`\n\nleft_join_example\n\n# A tibble: 5 × 5\n  location species  maturity full_site_name     jurisdiction\n  &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;              &lt;chr&gt;       \n1 lagoon   bobcat   adult    UCSB Lagoon        UCSB        \n2 bluff    coyote   juvenile Ellwood Mesa       SB City     \n3 creek    fox      adult    &lt;NA&gt;               &lt;NA&gt;        \n4 oaks     squirrel juvenile Fremont Campground USFS        \n5 bluff    bobcat   adult    Ellwood Mesa       SB City     \n\n\n\n\ndplyr::right_join()\nOpposite of a left_join().\n\nright_join_example &lt;- right_join(animals, sites)\n\nJoining with `by = join_by(location)`\n\nright_join_example\n\n# A tibble: 5 × 5\n  location species  maturity full_site_name     jurisdiction\n  &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;              &lt;chr&gt;       \n1 lagoon   bobcat   adult    UCSB Lagoon        UCSB        \n2 bluff    coyote   juvenile Ellwood Mesa       SB City     \n3 oaks     squirrel juvenile Fremont Campground USFS        \n4 bluff    bobcat   adult    Ellwood Mesa       SB City     \n5 beach    &lt;NA&gt;     &lt;NA&gt;     Goleta Beach       SB City     \n\n\n\n\ndplyr::inner_join()\nRows are only kept if the key matches in both x and y (intersection).\n\ninner_join_example &lt;- inner_join(animals, sites)\n\nJoining with `by = join_by(location)`\n\ninner_join_example\n\n# A tibble: 4 × 5\n  location species  maturity full_site_name     jurisdiction\n  &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;              &lt;chr&gt;       \n1 lagoon   bobcat   adult    UCSB Lagoon        UCSB        \n2 bluff    coyote   juvenile Ellwood Mesa       SB City     \n3 oaks     squirrel juvenile Fremont Campground USFS        \n4 bluff    bobcat   adult    Ellwood Mesa       SB City     \n\n\n\n\n\nFiltering joins\nWe’ll just look at two filtering join functions (from dplyr documentation):\n\nsemi_join() “return[s] all rows from x with a match in y”\nanti_join() “return[s] all rows from x without a match in y”\n\n\nsemi_join_example &lt;- semi_join(animals, sites)\n\nJoining with `by = join_by(location)`\n\nsemi_join_example\n\n# A tibble: 4 × 3\n  location species  maturity\n  &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;   \n1 lagoon   bobcat   adult   \n2 bluff    coyote   juvenile\n3 oaks     squirrel juvenile\n4 bluff    bobcat   adult   \n\n\n\nanti_join_example &lt;- anti_join(animals, sites)\n\nJoining with `by = join_by(location)`\n\nanti_join_example\n\n# A tibble: 1 × 3\n  location species maturity\n  &lt;chr&gt;    &lt;chr&gt;   &lt;chr&gt;   \n1 creek    fox     adult"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-7.html#easier-dates-and-times-with-lubridate",
    "href": "course-materials/interactive-sessions/interactive-session-7.html#easier-dates-and-times-with-lubridate",
    "title": "Interactive Session 7",
    "section": "4. Easier dates and times with {lubridate}",
    "text": "4. Easier dates and times with {lubridate}\n\nWitness some lubridate magic:\n\nmy_date &lt;- \"03-15-1998\"\nlubridate::mdy(my_date)\n\n[1] \"1998-03-15\"\n\n\n\nmy_date &lt;- \"11/7/2003\"\nlubridate::mdy(my_date)\n\n[1] \"2003-11-07\"\n\n\n\nmy_date &lt;- \"08-Jun-1974\"\nlubridate::dmy(my_date)\n\n[1] \"1974-06-08\"\n\n\n\nmy_date &lt;- \"19610518\"\nlubridate::ymd(my_date)\n\n[1] \"1961-05-18\"\n\n\nISO 8601 for everyone!\n\n\nWait can it fail?\nYup. What happens if we give lubridate something that doesn’t make sense?\n\nlubridate::mdy(\"1942-08-30\")\n\nWarning: All formats failed to parse. No formats found.\n\n\n[1] NA\n\n# Nope.\n\n\nlubridate::dmy(\"09/12/84\")\n\n[1] \"1984-12-09\"\n\n# Wait...but couldn't that be correct? \n# Sure, you and your computer wouldn't know.\n# SO KNOW YOUR DATE FORMAT.\n\nIn other words, parsing dates can fail in multiple ways:\n\nThe parsing can fail because the values don’t make sense based on the order you gave it (e.g. “wait you’re telling me that the month is 17? Nope.”)\nThe parsing can work, but you messed up with the order - so the code runs, but the date stored is wrong. This is more dangerous.\n\nKNOW YOUR DATA.\n\n\nIt even makes it relatively easy to deal with times & time zones\nSee the Olson Names: https://en.wikipedia.org/wiki/List_of_tz_database_time_zones\nUse ymd-hm to convert this to a date time that R will understand.\nQuestion: Why am I using ymd_hm here?\n\ntime &lt;- \"2020-08-12 11:18\"\ntime &lt;- ymd_hm(time)\ntime # Note that the default is UTC\n\n[1] \"2020-08-12 11:18:00 UTC\"\n\nclass(time) # Class is POSIXct\n\n[1] \"POSIXct\" \"POSIXt\" \n\n# Convert to PDT:\nwith_tz(time, \"America/Los_Angeles\")\n\n[1] \"2020-08-12 04:18:00 PDT\"\n\n# Convert to AEST:\nwith_tz(time, \"Australia/Sydney\")\n\n[1] \"2020-08-12 21:18:00 AEST\"\n\n# pull just the time\nmy_time &lt;- lubridate::ymd_hms(time)\nweek(my_time)\n\n[1] 33\n\nday(my_time)\n\n[1] 12\n\nhour(my_time)\n\n[1] 11\n\nminute(my_time)\n\n[1] 18\n\nsecond(my_time)\n\n[1] 0\n\n\n\nMore time examples:\n\n# Get your system time\ncomp_time &lt;- Sys.time()\n\n\n# Convert comp_time to Europe/Belgrade time: \nwith_tz(comp_time, \"Europe/Belgrade\")\n\n[1] \"2024-07-13 00:16:17 CEST\"\n\n\n\n\n\nPulling pieces\nYou can also get information about your dates using nice built-in lubridate functions.\n\nteddy_bday &lt;- lubridate::ymd(\"20170615\")\n\n# Return the date \nteddy_bday\n\n[1] \"2017-06-15\"\n\n\n\n# What day of the week? \nwday(teddy_bday, label = TRUE)\n\n[1] Thu\nLevels: Sun &lt; Mon &lt; Tue &lt; Wed &lt; Thu &lt; Fri &lt; Sat\n\n# What week of the year? \nweek(teddy_bday)\n\n[1] 24\n\n# Pull the year\nyear(teddy_bday)\n\n[1] 2017\n\n# Month\nmonth(teddy_bday)\n\n[1] 6\n\n\n\n\nDate pieces as new columns\nThis can be useful if you want to group your day in different ways for analyses or exploration. Use lubridate functions, in combination with mutate(), to add new columns containing separate pieces of the date, e.g. year, month, day in three separate columns).\nFor example, let’s just make a little data frame to try this out:\n\nurchin_counts &lt;- tribble(\n  ~date, ~species, ~size_mm,\n  \"10/3/2020\", \"purple\", 55,\n  \"10/4/2020\", \"red\", 48,\n  \"11/17/2020\", \"red\", 67\n)\n\nurchin_counts_ymd &lt;- urchin_counts %&gt;% \n  mutate(date = lubridate::mdy(date)) %&gt;% \n  mutate(year = year(date),\n         month = month(date),\n         day = day(date))\n\nurchin_counts_ymd\n\n# A tibble: 3 × 6\n  date       species size_mm  year month   day\n  &lt;date&gt;     &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n1 2020-10-03 purple       55  2020    10     3\n2 2020-10-04 red          48  2020    10     4\n3 2020-11-17 red          67  2020    11    17\n\n# And then we could use group_by() to find different summary values by group, for example.\n\n\nFind durations of times\n\nday_1 &lt;- lubridate::ymd(\"2020-01-06\")\nday_2 &lt;- lubridate::ymd(\"2020-05-18\")\nday_3 &lt;- lubridate::ymd(\"2020-05-19\")\n\n# Create a time interval\ntime_interval &lt;- interval(day_1, day_2)\n\n# Check the length in weeks\ntime_length(time_interval, \"week\")\n\n[1] 19\n\n# Check the length in years\ntime_length(time_interval, \"year\")\n\n[1] 0.363388"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-7.html#wrangling-strings-with-stringr",
    "href": "course-materials/interactive-sessions/interactive-session-7.html#wrangling-strings-with-stringr",
    "title": "Interactive Session 7",
    "section": "5. Wrangling strings with stringr",
    "text": "5. Wrangling strings with stringr\n\nUse str_detect() to detect a string pattern\nReturns TRUE or FALSE based on whether the pattern is or is not detected.\n\nmy_string &lt;- \"Teddy loves eating salmon and socks.\"\n\n# Does the pattern \"love\" exist within the string?\nmy_string %&gt;% str_detect(\"love\")\n\n[1] TRUE\n\n# Does the pattern \"pup\" exist within the string?\nmy_string %&gt;% str_detect(\"pup\")\n\n[1] FALSE\n\n\nThis also works on vectors (…think ahead - data frame columns!). It is case sensitive (by default):\n\nmy_string &lt;- c(\"burrito\", \"fish taco\", \"Taco salad\")\n\n# Does the vector element contain the pattern \"fish\"?\nmy_string %&gt;% str_detect(\"fish\")\n\n[1] FALSE  TRUE FALSE\n\n\nIt is most powerful when used in combination with other functions.\nFor example, let’s look at the starwars dataset (in dplyr):\n\nhead(starwars)\n\n# A tibble: 6 × 14\n  name      height  mass hair_color skin_color eye_color birth_year sex   gender\n  &lt;chr&gt;      &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; \n1 Luke Sky…    172    77 blond      fair       blue            19   male  mascu…\n2 C-3PO        167    75 &lt;NA&gt;       gold       yellow         112   none  mascu…\n3 R2-D2         96    32 &lt;NA&gt;       white, bl… red             33   none  mascu…\n4 Darth Va…    202   136 none       white      yellow          41.9 male  mascu…\n5 Leia Org…    150    49 brown      light      brown           19   fema… femin…\n6 Owen Lars    178   120 brown, gr… light      blue            52   male  mascu…\n# ℹ 5 more variables: homeworld &lt;chr&gt;, species &lt;chr&gt;, films &lt;list&gt;,\n#   vehicles &lt;list&gt;, starships &lt;list&gt;\n\n\nI want to only keep rows where the name column contains the pattern “Skywalker.” Remember: what’s the function to keep or exclude rows based on our conditions? It’s dplyr::filter()! I can use that with str_detect() to get the Skywalker family characters for me:\n\nskywalkers &lt;- starwars %&gt;% \n  filter(str_detect(name, \"Skywalker\"))\n\nskywalkers\n\n# A tibble: 3 × 14\n  name      height  mass hair_color skin_color eye_color birth_year sex   gender\n  &lt;chr&gt;      &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; \n1 Luke Sky…    172    77 blond      fair       blue            19   male  mascu…\n2 Anakin S…    188    84 blond      fair       blue            41.9 male  mascu…\n3 Shmi Sky…    163    NA black      fair       brown           72   fema… femin…\n# ℹ 5 more variables: homeworld &lt;chr&gt;, species &lt;chr&gt;, films &lt;list&gt;,\n#   vehicles &lt;list&gt;, starships &lt;list&gt;\n\n\n\n\nUse str_replace() to replace a string pattern with something else\n\nfirewalkers &lt;- starwars %&gt;% \n  mutate(name = str_replace(name, pattern = \"Sky\", replacement = \"Fire\"))\n\nhead(firewalkers)\n\n# A tibble: 6 × 14\n  name      height  mass hair_color skin_color eye_color birth_year sex   gender\n  &lt;chr&gt;      &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; \n1 Luke Fir…    172    77 blond      fair       blue            19   male  mascu…\n2 C-3PO        167    75 &lt;NA&gt;       gold       yellow         112   none  mascu…\n3 R2-D2         96    32 &lt;NA&gt;       white, bl… red             33   none  mascu…\n4 Darth Va…    202   136 none       white      yellow          41.9 male  mascu…\n5 Leia Org…    150    49 brown      light      brown           19   fema… femin…\n6 Owen Lars    178   120 brown, gr… light      blue            52   male  mascu…\n# ℹ 5 more variables: homeworld &lt;chr&gt;, species &lt;chr&gt;, films &lt;list&gt;,\n#   vehicles &lt;list&gt;, starships &lt;list&gt;\n\n\nYou can imagine this may be really helpful if there is a repeated spelling error, annoying syntax, or otherwise that you want to update throughout your data frame.\nNote: this is very different from text mining and analysis, which involves analyzing textual information to gain insights about patterns, trends, and sentiments - look forward to that in EDS 242!\n\n\nUse str_trim() or str_squish() to remove excess white space\n\nfeedback &lt;- c(\" I ate     some   nachos\", \"Wednesday morning   \")\n\n# Removes leading, trailing & duplicate interior whitespaces\nstr_squish(feedback)\n\n[1] \"I ate some nachos\" \"Wednesday morning\"\n\n# Removes leading & trailing whitespaces\nstr_trim(feedback)\n\n[1] \"I ate     some   nachos\" \"Wednesday morning\"      \n\n\n\n\nConvert cases\n\nstr_to_lower(feedback)\n\n[1] \" i ate     some   nachos\" \"wednesday morning   \"    \n\nstr_to_upper(feedback)\n\n[1] \" I ATE     SOME   NACHOS\" \"WEDNESDAY MORNING   \"    \n\nstr_to_title(feedback)\n\n[1] \" I Ate     Some   Nachos\" \"Wednesday Morning   \"    \n\n\n\n\nCount matches in a string\n\nstr_count(feedback, pattern = \"nachos\")\n\n[1] 1 0\n\n\n\nEnd Interactive Session 7"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-9.html",
    "href": "course-materials/interactive-sessions/interactive-session-9.html",
    "title": "Interactive Session 9",
    "section": "",
    "text": "Create a new version-controlled R Project called eds221-m2021-day9-interactive\nInstall the kableExtra package\nCreate a new R Markdown document in the project\nAttach the following packages in the setup chunk:\n\ntidyverse\nkableExtra"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-9.html#setup",
    "href": "course-materials/interactive-sessions/interactive-session-9.html#setup",
    "title": "Interactive Session 9",
    "section": "",
    "text": "Create a new version-controlled R Project called eds221-m2021-day9-interactive\nInstall the kableExtra package\nCreate a new R Markdown document in the project\nAttach the following packages in the setup chunk:\n\ntidyverse\nkableExtra"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-9.html#making-a-reproducible-example-reprex",
    "href": "course-materials/interactive-sessions/interactive-session-9.html#making-a-reproducible-example-reprex",
    "title": "Interactive Session 9",
    "section": "2. Making a reproducible example: {reprex}",
    "text": "2. Making a reproducible example: {reprex}\nMaking a minimum viable example is often the best way to troubleshoot problematic code when you can’t figure out a solution quickly – and is definitely the best way to share an example of something you’re struggling with so you’re most likely to get help. If people can’t run or play with your code, it’s much less likely they’ll be able to offer a solution.\nYou probably already have {reprex} (part of the tidyverse). Copy code to clipboard and run reprex() to make one!\nSome guidelines:\n\nRuthlessly simplify\nConsider using or making a subset of data (possibly w/ datapasta, tribble)\nInclude library calls (e.g. library(janitor) in the reprex)\nMake the minimum viable example of the thing that’s not working\nCopy to clipboard\nRun reprex() to create markdown-formatted (e.g. for GitHub issues) or reprex(venue = \"slack\") if posting to Slack (click “Add formatting” or Cmd-Shift-F for formatting)\n\nSee more:\n\nhttps://community.rstudio.com/t/faq-how-to-do-a-minimal-reproducible-example-reprex-for-beginners/23061\nhttps://reprex.tidyverse.org/articles/reprex-dos-and-donts.html"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-9.html#a-few-new-wrangling-tools-dplyracross-janitorget_dupes",
    "href": "course-materials/interactive-sessions/interactive-session-9.html#a-few-new-wrangling-tools-dplyracross-janitorget_dupes",
    "title": "Interactive Session 9",
    "section": "3. A few new wrangling tools: dplyr::across() & janitor::get_dupes()",
    "text": "3. A few new wrangling tools: dplyr::across() & janitor::get_dupes()\n\njanitor::get_dupes() to check for duplicates\n\ndupes &lt;- get_dupes(starwars) # Across all variables (exact match across all columns?)\n\nNo variable names specified - using all columns.\n\n\nNo duplicate combinations found of: name, height, mass, hair_color, skin_color, eye_color, birth_year, sex, gender, ... and 5 other variables\n\n# Check for duplicate values in the `2000` column\ndupes_2 &lt;- starwars %&gt;% \n  get_dupes(homeworld)\n\n# Check for duplicates in the homeworld and species column\ndupes_3 &lt;- starwars %&gt;% \n  get_dupes(homeworld, species)\n\n\n\ndplyr::across() - operations across columns\nMutate across multiple columns:\n\nstarwars %&gt;% \n  mutate(across(where(is.character), tolower))\n\nYou can use it within group_by() + summarize():\n\nstarwars %&gt;% \n  group_by(homeworld) %&gt;% \n  summarise(across(where(is.numeric), mean, na.rm = TRUE), count = n())\n\nWarning: There was 1 warning in `summarise()`.\nℹ In argument: `across(where(is.numeric), mean, na.rm = TRUE)`.\nℹ In group 1: `homeworld = \"Alderaan\"`.\nCaused by warning:\n! The `...` argument of `across()` is deprecated as of dplyr 1.1.0.\nSupply arguments directly to `.fns` through an anonymous function instead.\n\n  # Previously\n  across(a:b, mean, na.rm = TRUE)\n\n  # Now\n  across(a:b, \\(x) mean(x, na.rm = TRUE))\n\n\nAnother example:\n\nmtcars %&gt;% \n  group_by(cyl) %&gt;% \n  summarize(across(drat:qsec, mean))"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-9.html#tables-with-kable-and-kableextra",
    "href": "course-materials/interactive-sessions/interactive-session-9.html#tables-with-kable-and-kableextra",
    "title": "Interactive Session 9",
    "section": "4. Tables with {kable} and {kableExtra}",
    "text": "4. Tables with {kable} and {kableExtra}\nWe can produce finalized tables in R Markdown in a number of ways - see a bunch of them in David Keyes’ post How to make beautiful tables in R.\nWe’ll just use one tool: kable + kableExtra to make nice html tables.\nTry it out of the box (knit to see the table):\n\npenguins %&gt;% \n  group_by(species, island) %&gt;% \n  summarize(mean_mass = mean(body_mass_g, na.rm = TRUE)) %&gt;% \n  kable(col.names = c(\"Species\", \"Island\", \"Body mass (g)\")) %&gt;% \n  kable_styling(bootstrap_options = \"striped\", full_width = FALSE)\n\n`summarise()` has grouped output by 'species'. You can override using the\n`.groups` argument.\n\n\n\n\n\nSpecies\nIsland\nBody mass (g)\n\n\n\n\nAdelie\nBiscoe\n3709.659\n\n\nAdelie\nDream\n3688.393\n\n\nAdelie\nTorgersen\n3706.373\n\n\nChinstrap\nDream\n3733.088\n\n\nGentoo\nBiscoe\n5076.016"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-9.html#a-package-for-your-ggplot-theme",
    "href": "course-materials/interactive-sessions/interactive-session-9.html#a-package-for-your-ggplot-theme",
    "title": "Interactive Session 9",
    "section": "5. A package for your ggplot theme",
    "text": "5. A package for your ggplot theme\n\nCreating a package\n\nIn RStudio, create a new R Project that is an R Package (New Project &gt; New directory &gt; R Package). Make your package name something specific to you, e.g. themes_yourname (like themes_teddy). Make it a version controlled repo by running usethis::use_git() and usethis::use_github() (or w/ CLI).\nCheck out the existing infrastructure for your R package, which currently contains a single function hello(), which prints “Hello, world!” Check out the R/hello.R file to see where that function is created.\nIn the Build tab, click Install and Restart. You should see that the package is automatically attached in the Console.\nRun the hello() function in the Console, to see that it works.\nCreate a new R script (.R). Copy and paste the following placeholder code into your R script. Then update the colors (in quotations) to colors that R will recognize (or hexidecimals) and change the function name to theme_yourname (e.g. theme_allison). You can also add other options within theme() to further customize your theme.\n\nmy_theme &lt;- function() {\n  theme(\n    panel.background = element_rect(fill = \"yellow\"),\n    panel.grid.major.x = element_line(colour = \"purple\", linetype = 3, size = 0.5),\n    panel.grid.minor.x = element_blank(),\n    panel.grid.major.y =  element_line(colour = \"cyan4\", linetype = 3, size = 0.5),\n    axis.text = element_text(colour = \"red\"),\n    axis.title = element_text(colour = \"orange\")\n  )\n}\nSave the R script in to the R/ folder (with the file name matching the function name).\n\nPut your cursor anywhere in the function code within your R script. In the top menu of RStudio, select Code &gt; Insert Roxygen skeleton. The information added is important - it specifies the params (arguments of the function) and more that will appear in the documentation, which we’ll create next. Save the .R file, which now contains your function and the Roxygen information.\nDocument the function by running devtools::document() in the Console. This will create a new .Rd file in the man/ folder, containing important documentation information about your function.\nPress Build &gt; Install and Restart. In the Console, run ?function_name, replacing function_name there instead. It will bring up the documentation, and let you know your function exists! Now go ahead and try to use your function by making a graph in the Console.\n\nlibrary(tidyverse)\n\nggplot(data = msleep, aes(x = sleep_total, y = sleep_rem)) +\n  geom_point() \n  + THEME_NAME()\n\nOnce you confirm it’s working, push your changes back to your repo on GitHub. Share your repo “username/reponame” with your neighbor so they can install your package from GitHub (recall: using remotes::install_github(\"username/reponame\")). Install your neighbor’s theming package, check which functions exist by running help(package = \"packagename\") in the Console, then make a ggplot graph that uses your neighbor’s ggplot theme. Done!\n\n\nEnd Interactive Session 9"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-2a.html",
    "href": "course-materials/interactive-sessions/interactive-session-2a.html",
    "title": "Interactive Session 2A",
    "section": "",
    "text": "Create a repo on GitHub called eds221-day2-comp\nClone to make a version-controlled R Project\nCreate a new Quarto Document, saved in the root as r-py-data-types"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-2a.html#vectors",
    "href": "course-materials/interactive-sessions/interactive-session-2a.html#vectors",
    "title": "Interactive Session 2A",
    "section": "Vectors!",
    "text": "Vectors!\n\nMaking vectors\n\nA character vector\n\ndogs &lt;- c(\"teddy\", \"khora\", \"waffle\", \"banjo\")\n\ntypeof(dogs)\n\n[1] \"character\"\n\nclass(dogs)\n\n[1] \"character\"\n\n\n\n\nA numeric vector\n\nweights &lt;- c(50, 55, 25, 35)\n\ntypeof(weights) # Hmmm what is different about this and the line below?\n\n[1] \"double\"\n\nclass(weights)\n\n[1] \"numeric\"\n\n\n\n\nAn integer vector\n\ndog_age &lt;- c(5L, 6L, 1L, 7L)\n\ntypeof(dog_age)\n\n[1] \"integer\"\n\nclass(dog_age)\n\n[1] \"integer\"\n\n# Check with a logical: \nis.numeric(dog_age)\n\n[1] TRUE\n\n\n\n\nWhat if we combine classes?\nThere is a hierarchy of classes. The broadest of all in a vector wins (if there are characters, then character will be the class of the entire vector).\n\ndog_info &lt;- c(\"teddy\", 50, 5L)\ndog_info\n\n[1] \"teddy\" \"50\"    \"5\"    \n\ntypeof(dog_info)\n\n[1] \"character\"\n\nclass(dog_info)\n\n[1] \"character\"\n\nis.character(dog_info)\n\n[1] TRUE\n\n\n\n\nNamed elements\n\ndog_food &lt;- c(teddy = \"purina\", khora = \"alpo\", waffle = \"fancy feast\", banjo = \"blue diamond\")\ndog_food\n\n         teddy          khora         waffle          banjo \n      \"purina\"         \"alpo\"  \"fancy feast\" \"blue diamond\" \n\nclass(dog_food)\n\n[1] \"character\"\n\ntypeof(dog_food)\n\n[1] \"character\"\n\n\n\n\n\nAccessing bits of vectors\nUse [] with the position or name to access elements of a vector.\n\ndog_food[2]\n\n khora \n\"alpo\" \n\ndog_food[\"khora\"]\n\n khora \n\"alpo\" \n\n\nOr we can specify a range of values within a vector using [:]. The first element in R vectors is assigned element = 1. This is an important distinction. In Python, the first element is assigned 0 (zero-index).\n\n# Create a vector of car colors observed\ncars &lt;- c(\"red\", \"orange\", \"white\", \"blue\", \"green\", \"silver\", \"black\")\n\n# Access just the 5th element\ncars[5]\n\n[1] \"green\"\n\n# Access elements 2 through 4\ncars[2:4]\n\n[1] \"orange\" \"white\"  \"blue\"  \n\n\n\n\nA warm-up for for loops:\n\ni &lt;- 4\ncars[i]\n\n[1] \"blue\"\n\ni &lt;- seq(1:3)\ncars[i]\n\n[1] \"red\"    \"orange\" \"white\" \n\n\n\n\nAnd we can update elements of a vector directly (mutable):\n\ncars[3] &lt;- \"BURRITOS!\"\ncars\n\n[1] \"red\"       \"orange\"    \"BURRITOS!\" \"blue\"      \"green\"     \"silver\"   \n[7] \"black\""
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-2a.html#matrices",
    "href": "course-materials/interactive-sessions/interactive-session-2a.html#matrices",
    "title": "Interactive Session 2A",
    "section": "Matrices!",
    "text": "Matrices!\n\nCreating matrices\n(…we did some of this in EDS 212 too!)\n\nfish_size &lt;- matrix(c(0.8, 1.2, 0.4, 0.9), ncol = 2, nrow = 2, byrow = FALSE)\n\nfish_size\n\n     [,1] [,2]\n[1,]  0.8  0.4\n[2,]  1.2  0.9\n\ntypeof(fish_size) # Returns the class of values\n\n[1] \"double\"\n\nclass(fish_size) # Returns matrix / array\n\n[1] \"matrix\" \"array\" \n\n\nWhat happens if we try to combine multiple data types into a matrix?\n\ndog_walk &lt;- matrix(c(\"teddy\", 5, \"khora\", 10), ncol = 2, nrow = 2, byrow = FALSE)\n\ndog_walk\n\n     [,1]    [,2]   \n[1,] \"teddy\" \"khora\"\n[2,] \"5\"     \"10\"   \n\nclass(dog_walk)\n\n[1] \"matrix\" \"array\" \n\ntypeof(dog_walk)\n\n[1] \"character\"\n\n# Hmmmmmm once again back to the broadest category of data type in the hierarchy\n\n\n\nAccessing pieces of matrices\nIndex using [row, column].\n\nwhale_travel &lt;- matrix(data = c(31.8, 1348, 46.9, 1587), nrow = 2, ncol = 2, byrow = TRUE)\n\n# Take a look\nwhale_travel\n\n     [,1] [,2]\n[1,] 31.8 1348\n[2,] 46.9 1587\n\n# Access the value 1348\nwhale_travel[1,2] # Row 1, column 2\n\n[1] 1348\n\n# Access the value 46.9\nwhale_travel[2,1]\n\n[1] 46.9\n\n\nIf you leave any element blank (keeping the comma), it will return all values from the other element. For example, to get everything in row 2:\n\nwhale_travel[2,]\n\n[1]   46.9 1587.0\n\n\nOr, to access everything in column 1:\n\nwhale_travel[, 1]\n\n[1] 31.8 46.9\n\n\nWhat happens if I only give a matrix one element? That’s the position in the matrix as if populated by column. Check out a few:\n\nwhale_travel[3]\n\n[1] 1348"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-2a.html#lists",
    "href": "course-materials/interactive-sessions/interactive-session-2a.html#lists",
    "title": "Interactive Session 2A",
    "section": "Lists",
    "text": "Lists\n\nurchins &lt;- list(\"blue\", c(1, 2, 3), c(\"a cat\", \"a dog\"), 5L)\n\nurchins\n\n[[1]]\n[1] \"blue\"\n\n[[2]]\n[1] 1 2 3\n\n[[3]]\n[1] \"a cat\" \"a dog\"\n\n[[4]]\n[1] 5\n\n\n\nAccessing pieces of a list\nImportant: a single [] returns a list. [[]] returns the item STORED in the list.\n\nurchins[[2]]\n\n[1] 1 2 3\n\n# Compare that to: \nurchins[2]\n\n[[1]]\n[1] 1 2 3\n\n\n\n\nNaming list items? Sure thing!\n\ntacos &lt;- list(topping = c(\"onion\", \"cilantro\", \"guacamole\"), filling = c(\"beans\", \"meat\", \"veggie\"), price = c(6.75, 8.25, 9.50))\n\n# The whole thing\ntacos\n\n$topping\n[1] \"onion\"     \"cilantro\"  \"guacamole\"\n\n$filling\n[1] \"beans\"  \"meat\"   \"veggie\"\n\n$price\n[1] 6.75 8.25 9.50\n\n# Just get one piece of it: \ntacos[[2]]\n\n[1] \"beans\"  \"meat\"   \"veggie\"\n\n#...or, the same thing:\ntacos$filling\n\n[1] \"beans\"  \"meat\"   \"veggie\""
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-2a.html#data-frames",
    "href": "course-materials/interactive-sessions/interactive-session-2a.html#data-frames",
    "title": "Interactive Session 2A",
    "section": "Data frames",
    "text": "Data frames\nA data frame is a list containing vectors of the same length, where each column is a variable stored in a vector. Let’s make one:\n\nfruit &lt;- data.frame(type = c(\"apple\", \"banana\", \"peach\"), \n                    mass = c(130, 195, 150))\n\n# Look at it\nfruit\n\n    type mass\n1  apple  130\n2 banana  195\n3  peach  150\n\n# Check the class\nclass(fruit)\n\n[1] \"data.frame\"\n\n\n\nAccess elements from a data frame\nUse [row#, col#], or name the column (then element number).\n\nfruit[1,2]\n\n[1] 130\n\nfruit[3,1]\n\n[1] \"peach\"\n\n\n\nfruit[2,1] &lt;- \"pineapple\"\nfruit\n\n       type mass\n1     apple  130\n2 pineapple  195\n3     peach  150"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-2a.html#vectors-and-matrices-in-python",
    "href": "course-materials/interactive-sessions/interactive-session-2a.html#vectors-and-matrices-in-python",
    "title": "Interactive Session 2A",
    "section": "Vectors and matrices in Python",
    "text": "Vectors and matrices in Python\n\nteddy = [1,2,8]\nteddy_vec = np.array(teddy)\n\nteddy_vec\n\narray([1, 2, 8])\n\ntype(teddy_vec)\n\n&lt;class 'numpy.ndarray'&gt;\n\n\nA list is mutable - you can change it directly!\n\nteddy[1] = 1000\n\n# See that element 1 is updated directly! \nteddy\n\n[1, 1000, 8]\n\n\nA tuple is immutable - you’ll get yelled at if you try to change it!\n\nkhora = (1, 5, 12)\ntype(khora)\n\n&lt;class 'tuple'&gt;\n\n\n# khora[1] = 16 # Nope. \n\nA more involved list (note: you can also use list() to create lists in python).\n\nwaffle = [[\"cat\", \"dog\", \"penguin\"], 2, \"a burrito\", [1,2,5]]\n\nwaffle\n\n[['cat', 'dog', 'penguin'], 2, 'a burrito', [1, 2, 5]]\n\n# Access an element from the list waffle:\nwaffle[0] # Default just returns that piece (not as a list)\n\n['cat', 'dog', 'penguin']\n\n\nWe can reassign pieces of a list:\n\nwaffle[1] = \"AN EXTRAVAGANZA\"\n\nwaffle\n\n[['cat', 'dog', 'penguin'], 'AN EXTRAVAGANZA', 'a burrito', [1, 2, 5]]"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-2a.html#make-a-pandas-dataframe-in-python",
    "href": "course-materials/interactive-sessions/interactive-session-2a.html#make-a-pandas-dataframe-in-python",
    "title": "Interactive Session 2A",
    "section": "Make a pandas DataFrame in python",
    "text": "Make a pandas DataFrame in python\n\nFirst, a dictionary example:\n\nfox = {'sound': [\"screech\", \"squeal\", \"bark\"], 'age': [2, 6, 10]}\n\nfox['sound']\n\n['screech', 'squeal', 'bark']\n\nfox['age']\n\n[2, 6, 10]\n\n\n\ncows = {'name': [\"moo\", \"spots\", \"happy\"], 'location': [\"pasture\", \"prairie\", \"barn\"], 'height': [5.7, 5.4, 4.9]}\n\ncows_df = pd.DataFrame(cows)\n\n# Take a look\ncows_df\n\n    name location  height\n0    moo  pasture     5.7\n1  spots  prairie     5.4\n2  happy     barn     4.9\n\n# Get a column\ncows_df['name']\n\n0      moo\n1    spots\n2    happy\nName: name, dtype: object\n\n# Get an element using df.at[]\ncows_df.at[1, 'name']\n\n'spots'\n\n\n\n\nSide-by-side: R data frame & Pandas DataFrame\nIn R:\n\nhome_sales &lt;- data.frame(\n  state = c(\"CA\", \"NV\", \"OR\"),\n  sales = c(38000, 4670, 2750)\n)\n\nhome_sales\n\n  state sales\n1    CA 38000\n2    NV  4670\n3    OR  2750\n\n\nIn Python:\n\nhome_sales = {'state': [\"CA\", \"NV\", \"OR\"], 'sales': [38000, 4670, 2750]}\n\nhome_sales = pd.DataFrame(home_sales)\n\nhome_sales\n\n  state  sales\n0    CA  38000\n1    NV   4670\n2    OR   2750\n\n\n\nEnd Interactive Session 2A"
  },
  {
    "objectID": "course-materials/day2.html#class-materials",
    "href": "course-materials/day2.html#class-materials",
    "title": "Data representations",
    "section": "Class materials",
    "text": "Class materials\n\n\n\n\n\n\n\n\n Session\n Lecture slides\n Interactive session\n\n\n\n\nday 2 / morning\nData representations and types\nCreating and indexing with different data types in R and Python\n\n\nday 2 / afternoon\nCommon data types and structures in EDS\nData in R: accessing / updating elements & casting continued"
  },
  {
    "objectID": "course-materials/day2.html#end-of-day-practice",
    "href": "course-materials/day2.html#end-of-day-practice",
    "title": "Data representations",
    "section": "End-of-day practice",
    "text": "End-of-day practice\nComplete the following tasks / activities before heading home for the day!\n\n Day 2 Practice: Exploring data types, indexing, importing, and plotting"
  },
  {
    "objectID": "course-materials/day2.html#additional-resources",
    "href": "course-materials/day2.html#additional-resources",
    "title": "Data representations",
    "section": "Additional Resources",
    "text": "Additional Resources\nTBD"
  },
  {
    "objectID": "course-materials/day7.html#class-materials",
    "href": "course-materials/day7.html#class-materials",
    "title": "Data wrangling",
    "section": "Class materials",
    "text": "Class materials\n\n\n\n\n\n\n\n\n Session\n Lecture slides\n Interactive session\n\n\n\n\nday 7 / morning\nData wrangling continued - more tidying, relational data & types of joins\nData wrangling continued: joins\n\n\nday 7 / afternoon\nData wrangling continued - working with dates & times, wrangling strings\nData wrangling continued: dates, times, strings"
  },
  {
    "objectID": "course-materials/day7.html#end-of-day-practice",
    "href": "course-materials/day7.html#end-of-day-practice",
    "title": "Data wrangling",
    "section": "End-of-day practice",
    "text": "End-of-day practice\nComplete the following tasks / activities before heading home for the day!\n\n Day 7 Practice: Wrangling continued: joins, strings, dates"
  },
  {
    "objectID": "course-materials/day7.html#additional-resources",
    "href": "course-materials/day7.html#additional-resources",
    "title": "Data wrangling",
    "section": "Additional Resources",
    "text": "Additional Resources\nTBD"
  },
  {
    "objectID": "course-materials/day4.html#class-materials",
    "href": "course-materials/day4.html#class-materials",
    "title": "Introduction to functions",
    "section": "Class materials",
    "text": "Class materials\n\n\n\n\n\n\n\n\n Session\n Lecture slides\n Interactive session\n\n\n\n\nday 4 / morning\nIntroduction to writing functions in R & Python\nFunctions 101: basics\n\n\nday 4 / afternoon\nFunctions continued: planning, adding useful messages, more advanced functions and outputs\nFunctions 102: beyond basics"
  },
  {
    "objectID": "course-materials/day4.html#end-of-day-practice",
    "href": "course-materials/day4.html#end-of-day-practice",
    "title": "Introduction to functions",
    "section": "End-of-day practice",
    "text": "End-of-day practice\nComplete the following tasks / activities before heading home for the day!\n\n Day 4 Practice: Intro to functions"
  },
  {
    "objectID": "course-materials/day4.html#additional-resources",
    "href": "course-materials/day4.html#additional-resources",
    "title": "Introduction to functions",
    "section": "Additional Resources",
    "text": "Additional Resources\nTBD"
  },
  {
    "objectID": "course-materials/eod-practice/eod-day5.html",
    "href": "course-materials/eod-practice/eod-day5.html",
    "title": "Day 5: Task & Activities",
    "section": "",
    "text": "Create a new repo on GitHub called eds221-day5-activities\nClone to create a version-controlled R Project\nCreate subfolders: docs, src, data, figs"
  },
  {
    "objectID": "course-materials/eod-practice/eod-day5.html#setup",
    "href": "course-materials/eod-practice/eod-day5.html#setup",
    "title": "Day 5: Task & Activities",
    "section": "",
    "text": "Create a new repo on GitHub called eds221-day5-activities\nClone to create a version-controlled R Project\nCreate subfolders: docs, src, data, figs"
  },
  {
    "objectID": "course-materials/eod-practice/eod-day5.html#make-a-function-source-in-an-r-markdown-doc",
    "href": "course-materials/eod-practice/eod-day5.html#make-a-function-source-in-an-r-markdown-doc",
    "title": "Day 5: Task & Activities",
    "section": "2. Make a function, source in an R Markdown doc",
    "text": "2. Make a function, source in an R Markdown doc\n\nTask 1\n\n\n\n\n\n\nCitation\n\n\n\nNCDENR Stormwater BMP Manual\n\n\nOne established way to calculate the volume of stormwater expected for a watershed (necessary to design best management practices & systems) is the Simple Method, which involves two steps. First, the runoff coefficient \\(R_v\\) (storm runoff / storm rainfall) is calculated from: \\[R_v = 0.05 + 0.9 * I_A\\]\nWhere \\(R_v\\) is the runoff coefficient (unitless), and \\(I_A\\) is the fraction of the watershed that is considered “impervious” (unitless). The volume of stormwater that needs to be handled, \\(V\\) in cubic feet, is then calculated by: \\[V=3630 * R_D * R_v * A\\] where \\(R_D\\) is the “design storm rainfall depth” in inches, usually set to 1.0 or 1.5, \\(R_v\\) is the runoff coefficient calculated above, and \\(A\\) is the watershed area in acres.\nYOUR TASK:\n\nCreate a new R script in src, saved as storm_runoff.R\nIn the script, create a function called predict_runoff that estimates the storm runoff volume using inputs for the impervious fraction and watershed area (you can use a constant value of 1 for \\(R_D\\) here). In other words, your function should only require two arguments\nAdd documentation to your function using Roxygen comments for practice\nTry out your function in the Console to ensure that it works\nCreate a new R Markdown document in docs, saved as runoff_volumes.Rmd\nAttach the tidyverse and here packages\nSource your storm_runoff.R script so you are able to use the predict_runoff function in your .Rmd\nIn a code chunk in your runoff_volumes.Rmd, use your predict_runoff function to estimate stormwater volume for a watershed of 182 acres, over a range of estimates for the impervious fraction (from 0.6 to 0.8, by increments of 0.01). Note: you do not need to write a for loop here.\nBind your sequence of impervious fractions together with the resulting runoff volume calculated into a data frame\nCreate a ggplot graph that has both dots and connecting lines (i.e., you’ll layer geom_point() and geom_line(). Update axis labels. Export a png of your graph to the figs folder using ggsave.\n\nDone with Task 1"
  },
  {
    "objectID": "course-materials/eod-practice/eod-day5.html#wild-data",
    "href": "course-materials/eod-practice/eod-day5.html#wild-data",
    "title": "Day 5: Task & Activities",
    "section": "3. Wild data",
    "text": "3. Wild data\nFor your next task, you will work with the us_tilapia_imports.csv. It exists in your eds221-day5-comp project - copy that file into your data folder for your day 5 activities project. The data are from the USDA Economic Research Service, and contain annual total volumes (in thousands of pounds) of tilapia imports to the United States from different countries.\nYou can decide if you want to do this all in separate steps, or piped together in sequence, or some combination. Make sure if you pipe things together, you check the output at every step.\n\nCreate a new .Rmd in your docs folder called us_tilapia_imports.Rmd\nAttach the tidyverse, here and janitor packages\nRead in the data as us_tilapia_imports\nExplore the data. What are the classes of the columns? Remember some tools we’ve used: summary, names, dim, skim, etc.\nUse pivot_longer() to reshape the data into long format (currently, the variable “year” is spread across multiple columns). Remember to store the output so you will be able to use the reshaped data this creates.\nCheck the class of the year column. What is it, and why do you think that’s the case? Then, coerce the year column to numeric (e.g. using mutate() and as.numeric() in combination)\nUse dplyr::group_by() %&gt;% summarize() to find the total US tilapia imports by year, store as yearly_tilapia_tot\nCreate a ggplot line graph of total US tilapia imports for all years in yearly_tilapia_tot. Update axis labels (include units as necessary), then export your graph as a .png to figs.\nCreate a subset that only retains imports from Ecuador, Honduras, Costa Rica, and Mexico (you decide what to name this)\nCreate a ggplot graph of total US tilapia imports over time, for those four countries in the subset you created above, separated by country. Update axis labels, add a title, customize your color scheme, update the theme. Export a .jpg of your graph to figs."
  },
  {
    "objectID": "course-materials/eod-practice/eod-day5.html#add-to-your-r-package",
    "href": "course-materials/eod-practice/eod-day5.html#add-to-your-r-package",
    "title": "Day 5: Task & Activities",
    "section": "4. Add to your R package",
    "text": "4. Add to your R package\nFor your final task, reopen your R package you started today, and add two new functions. They can do whatever you want as long as:\n\nThey have at least two required arguments\nYou add documentation for each function with a Roxygen skeleton\n\nOnce you’ve added your functions, make sure to devtools::document(), install and restart, and check to make sure your functions are working, and that you can see your documentation. Then:\n\nPush your changes back to your repo on GitHub\nShare the link with someone (they’ll need to re-install your package from GitHub using install_github(\"username/reponame\"))\n\n\nEnd Activity Session (Day 5)"
  },
  {
    "objectID": "course-materials/eod-practice/eod-day6.html",
    "href": "course-materials/eod-practice/eod-day6.html",
    "title": "Day 6: Tasks & Activities",
    "section": "",
    "text": "Take ~15 minutes to read Broman & Woo’s evergreen paper Data organization in spreadsheets. As you read, think about data that you have created or had to work with that did not follow these guidelines. Make notes of examples to share from several - how did you input data previously? How would you change the way you input data?\nQuestions:\n\nWhat are major / most common ways you have seen these guidelines ignored?\nWhat is your experience working with or creating data in spreadsheets that don’t follow these guidelines?"
  },
  {
    "objectID": "course-materials/eod-practice/eod-day6.html#data-organization",
    "href": "course-materials/eod-practice/eod-day6.html#data-organization",
    "title": "Day 6: Tasks & Activities",
    "section": "",
    "text": "Take ~15 minutes to read Broman & Woo’s evergreen paper Data organization in spreadsheets. As you read, think about data that you have created or had to work with that did not follow these guidelines. Make notes of examples to share from several - how did you input data previously? How would you change the way you input data?\nQuestions:\n\nWhat are major / most common ways you have seen these guidelines ignored?\nWhat is your experience working with or creating data in spreadsheets that don’t follow these guidelines?"
  },
  {
    "objectID": "course-materials/eod-practice/eod-day6.html#data-tidying-subsetting",
    "href": "course-materials/eod-practice/eod-day6.html#data-tidying-subsetting",
    "title": "Day 6: Tasks & Activities",
    "section": "Data tidying & subsetting",
    "text": "Data tidying & subsetting\n\nTask 2: SBC Lobsters\n\n\n\n\n\n\nData source\n\n\n\nSanta Barbara Coastal LTER, D. Reed, and R. Miller. 2021. SBC LTER: Reef: Abundance, size and fishing effort for California Spiny Lobster (Panulirus interruptus), ongoing since 2012 ver 6. Environmental Data Initiative. https://doi.org/10.6073/pasta/0bcdc7e8b22b8f2c1801085e8ca24d59\n\n\n\n\nGetting started\n\nCreate a new GitHub repo called eds221-day6-activities\nClone to create a version controlled R project\nAdd subfolders data and docs\nDownload the California Spiny lobster abundance data from this SBC LTER data package. Familiarize yourself with the metadata. Save the CSV containing lobster abundance data in your data subfolder.\nIn docs, create a new .Rmd or .qmd saved with file prefix lobster_exploration\nWithin your notebook, write organized and well-annotated code to do the following:\n\nRead in and take a look at the data in the data/Lobster_Abundance_All_Years_20210412.csv file. Take note of values that can be considered NA (see metadata) and update your import line to convert those to NA values\nConvert column names to lower snake case\nConvert the data from frequency to case format using dplyr::uncount() on the existing count column. What did this do? Add annotation in your code explaining dplyr::uncount()\n\n\nHere’s code to read in your data, just to get your started:\n\nlobsters &lt;- read_csv(here(\"data\",\"Lobster_Abundance_All_Years_20210412.csv\"), na = c(\"-99999\", \"\")) %&gt;% \n  clean_names() %&gt;% \n  uncount(count)\n\n\n\nFind counts and mean sizes by site & year\n\nCreate a summary table that finds the total counts (see: n()), and mean carapace lengths of lobsters observed in the dataset by site and year.\nCreate a ggplot graph of the number of total lobsters observed (y-axis) by year (x-axis) in the study, grouped (either aesthetically or by faceting) by site\n\n\n\nFind the proportion of legal lobsters at each site for 2020\nThe legal lobster size (carapace length) in California is 79.76 mm.\n\nCreate a subset that only contains lobster data from 2020 (note: this should be from the original data you read in, not the summary table you created above)\nWrite code (you can decide how to do this - there are a number of ways) to find the counts of lobsters observed at each site (only using site as the grouping factor) that are above and below the legal limit. Hint: You may want to add a new column legal that contains “yes” or “no” based on the size of the observed lobster (see dplyr::case_when() for a really nice way to do this), then use group_by() %&gt;% summarize(n()) or dplyr::count() to get counts by group within variables\nCreate a stacked column graph that shows the proportion of legal and non-legal lobsters at each site. **Hint: create a stacked column graph with geom_col(), then add the argument position = \"fill\" to convert from a graph of absolute counts to proportions.\n\nWhich two sites had the largest proportion of legal lobsters in 2020? Explore the metadata to come up with a hypothesis about why that might be."
  },
  {
    "objectID": "course-materials/eod-practice/eod-day6.html#task-3-random-lobster-wrangling",
    "href": "course-materials/eod-practice/eod-day6.html#task-3-random-lobster-wrangling",
    "title": "Day 6: Tasks & Activities",
    "section": "Task 3: Random lobster wrangling",
    "text": "Task 3: Random lobster wrangling\nStarting with the original lobsters data that you read in as lobsters, complete the following (separately - these are not expected to be done in sequence or anything). You can store each of the outputs as ex_a, ex_b, etc. for the purposes of this task.\n\nfilter() practice\n\nCreate and store a subset that only contains lobsters from sites “IVEE”, “CARP” and “NAPL”. Check your output data frame to ensure that only those three sites exist.\nCreate a subset that only contains lobsters observed in August.\nCreate a subset with lobsters at Arroyo Quemado (AQUE) OR with a carapace length greater than 70 mm.\nCreate a subset that does NOT include observations from Naples Reef (NAPL)\n\n\n\ngroup_by() %&gt;% summarize() practice\n\nFind the mean and standard deviation of lobster carapace length, grouped by site.\nFind the maximum carapace length by site and month.\n\n\n\nmutate() practice\n\nAdd a new column that contains lobster carapace length converted to centimeters. Check output.\nUpdate the site column to all lowercase. Check output.\nConvert the area column to a character (not sure why you’d want to do this, but try it anyway). Check output.\n\n\n\ncase_when() practice\n\nUse case_when() to add a new column called size_bin that contains “small” if carapace size is &lt;= 70 mm, or “large” if it is greater than 70 mm. Check output.\nUse case_when() to add a new column called designation that contains “MPA” if the site is “IVEE” or “NAPL”, and “not MPA” for all other outcomes.\n\n\nEnd Activity Session (Day 6)"
  },
  {
    "objectID": "course-materials/eod-practice/eod-day10a.html",
    "href": "course-materials/eod-practice/eod-day10a.html",
    "title": "Day 10: Morning Tasks & Activities",
    "section": "",
    "text": "Yellow fiddler crab waving it’s large claw. From Wikipedia."
  },
  {
    "objectID": "course-materials/eod-practice/eod-day10a.html#setup",
    "href": "course-materials/eod-practice/eod-day10a.html#setup",
    "title": "Day 10: Morning Tasks & Activities",
    "section": "1.Setup:",
    "text": "1.Setup:\n\nPartner up, then decide who is Partner 1 & who is Partner 2 for this activity\nYou should be working together on all of this activity, even though it is split up into “Partner 1” and “Partner 2” sections\n\n\nPartner 1:\n\nCreate a new version-controlled R Project named fiddler-crab-sizes\nIn a new Quarto document, attach the lterdatasampler package\nRead through the documentation for the pie_crab data sample, and spend ~5 minutes talking with your partner about the data contains, the shape, variables, and why it was collected. See more information and examples with the data here.\nSave your document\nPush your changes back to GitHub (you don’t need to work in a branch for this step – push straight to main)\nAdd your partner as a collaborator to the repo\n\n\n\nPartner 2:\n\nAccept the invitation to collaborate (check your email) & clone the repo\nCreate a NEW BRANCH to work in\nIn the Quarto doc, create an exploratory (unfinalized) plot of fiddler crab carapace widths observed at the different latitudes\nPush your updates\nSubmit a Pull Request through GitHub\n\n\n\nPartner 1:\n\nMerge in the Pull Request\nPull changes into main\nSwitch over into a NEW BRANCH\nFinalize the figure. Add a figure caption using #| fig-cap: \"this is my caption\" in the code chunk where the graph is created. Update code chunk options (hint: execute: in YAML) so that only your finalized graph and figure caption show up in your knitted report (i.e., no code should show up)\nTo your document, add an unfinalized summary table containing the mean, standard deviation, and sample size of fiddler crab carapace widths by site (tip: use round(mean(), 2) to round a value to 2 decimal places)\nPush your changes\nSubmit a Pull Request in GitHub\n\n\n\nPartner 2:\n\nMerge in the Pull Request\nGo back to your main branch locally, and pull down changes\nCreate and checkout a NEW BRANCH\nFinalize the summary table a bit so that it looks more polished when rendered, including with updated column names (including units as relevant).\nPush your updates, submit a PR on GitHub\n\n\n\nPartner 1:\n\nMerge in the PR\nSwitch over to your main branch locally, pull in changes\nCreate and checkout a NEW BRANCH\nWork with your partner to write a short introduction to the figures in your knitted document (e.g. so that if it were shared as a short blog post, someone would understand what they were looking at)\nAdd any necessary citations for the data at the end of the document\nPush your changes and submit a PR on GitHub\n\n\n\nPartner 2:\n\nMerge in the PR\n\n\n\nBoth partners:\n\nMove back over into your main local branch\nPull down changes\n\n\nEnd Activity Session (Day 10 Morning)"
  },
  {
    "objectID": "course-materials/eod-practice/eod-day1.html",
    "href": "course-materials/eod-practice/eod-day1.html",
    "title": "Day 1: Tasks & Activities",
    "section": "",
    "text": "Fork, add your name to end of the repo name, and clone this repo\nBefore you move on, read more about the data here\nAdd two subfolders to your R project: docs and figs\nCreate and save a new Quarto document as stl_lead_inequity.qmd in the docs folder"
  },
  {
    "objectID": "course-materials/eod-practice/eod-day1.html#setup",
    "href": "course-materials/eod-practice/eod-day1.html#setup",
    "title": "Day 1: Tasks & Activities",
    "section": "",
    "text": "Fork, add your name to end of the repo name, and clone this repo\nBefore you move on, read more about the data here\nAdd two subfolders to your R project: docs and figs\nCreate and save a new Quarto document as stl_lead_inequity.qmd in the docs folder"
  },
  {
    "objectID": "course-materials/eod-practice/eod-day1.html#data-import-and-exploration",
    "href": "course-materials/eod-practice/eod-day1.html#data-import-and-exploration",
    "title": "Day 1: Tasks & Activities",
    "section": "2. Data import and exploration",
    "text": "2. Data import and exploration\n\nRead in & explore the data\nIn your .qmd:\n\nAttach the tidyverse and janitor packages in a new code chunk\nRead in the stl_blood_lead.csv data as stl_lead and use janitor::clean_names to convert all variable names to lower snake case\nDo some basic exploration of the dataset (e.g. using summary, data visualizations and summary statistics).\nIn a new code chunk, from stl_blood_lead create a new data frame called stl_lead_prop that has one additional column called prop_white that returns the percent of each census tract identifying as white (variable white in the dataset divided by variable totalPop, times 100). You may need to do some Googling. Hint: dplyr::mutate(new_col = col_a / col_b) will create a new column new_col that contains the value of col_a / col_b"
  },
  {
    "objectID": "course-materials/eod-practice/eod-day1.html#visualize-data",
    "href": "course-materials/eod-practice/eod-day1.html#visualize-data",
    "title": "Day 1: Tasks & Activities",
    "section": "3. Visualize data",
    "text": "3. Visualize data\n\nCreate a scatterplot\n\nIn a new code chunk, create a scatterplot graph of the percentage of children in each census tract with elevated blood lead levels (pctElevated) versus the percent of each census tract identifying as white.\nCustomize by updating several aesthetics (e.g. size, opacity (see alpha =), color, etc.)\nStore the scatterplot as stl_lead_plot\nHave the scatterplot returned in the rendered html - customize the size that it appears when knitted\nAlso save a .png of the scatterplot to figs, with dimensions of (6” x 5”) (width x height)\nIn text above or below the scatterplot, write 1 - 2 sentences describing the overall trend that you observe from your graph\n\n\n\nCreate a histogram\n\nCreate a histogram of only the pctElevated column in the data frame (remember, this will only take one variable - the frequency is calculated for you by geom_histogram)\nCustomize the fill, color, and size aesthetics - test some stuff! Feel free to make it awful.\nOnce you’ve played around with customization, export the histogram as a .jpg to the figs folder\nMake sure the histogram also shows up in your rendered html"
  },
  {
    "objectID": "course-materials/eod-practice/eod-day1.html#collaborate",
    "href": "course-materials/eod-practice/eod-day1.html#collaborate",
    "title": "Day 1: Tasks & Activities",
    "section": "4. Collaborate!",
    "text": "4. Collaborate!\n\nRender & push\n\nRender your .qmd\nStage, commit, pull then push changes using the command line\n\n\n\nShare & test\n\nShare the link to your public GitHub repo with a neighbor\nFork the repo your neighbor shared, then clone to get set up locally in RStudio\nNavigate to their .qmd\nRender - does everything work? Cool, your neighbor made a reproducible project with file paths you can use too!\n\n\nEnd Activity Session (Day 1)"
  },
  {
    "objectID": "course-materials/eod-practice/eod-day8.html",
    "href": "course-materials/eod-practice/eod-day8.html",
    "title": "Day 8: Tasks & Activities",
    "section": "",
    "text": "Fork and clone this repo\nClone to make a version controlled R Project\nAdd folders docs and figs"
  },
  {
    "objectID": "course-materials/eod-practice/eod-day8.html#setup",
    "href": "course-materials/eod-practice/eod-day8.html#setup",
    "title": "Day 8: Tasks & Activities",
    "section": "",
    "text": "Fork and clone this repo\nClone to make a version controlled R Project\nAdd folders docs and figs"
  },
  {
    "objectID": "course-materials/eod-practice/eod-day8.html#task-1-do-your-data-viz-worst",
    "href": "course-materials/eod-practice/eod-day8.html#task-1-do-your-data-viz-worst",
    "title": "Day 8: Tasks & Activities",
    "section": "Task 1: Do your data viz worst",
    "text": "Task 1: Do your data viz worst\nJust like it takes a lot of work to make a really wonderful graph, it takes effort to make a graph really awful. Put effort and creativity into this - you will learn a lot in the process if you do.\nUsing the ‘space_launches.csv’ data, create a new .qmd and create your worst possible graph by customizing (from the ggplot default) in at least 8 ways - more encouraged - to make it as terrible as possible. The data were previously shared for #TidyTuesday, and descriptions of dataset & variables can be found here. You can plot whatever variable(s) you choose, and make whatever graph type you want.\nOnce you’re done, drop your worst graph (as a .png or .jpg) into the course Slack channel.\nSome ideas:\n\nfonts\nbackground images\ncoord_*\npanel / plot / geom / text colors\npoint / line patterns and shapes\ngridline updates\ntickmark frequency\nangles\n\nHere’s some inspiration from a few Bren MESM students.\nBy Yani Pohl:\n\n\n\n\n\n\n\n\n\nBy Keene Morrow:"
  },
  {
    "objectID": "course-materials/eod-practice/eod-day8.html#task-2-wrangling-practice-with-the-sf-greenhouse-gas-data",
    "href": "course-materials/eod-practice/eod-day8.html#task-2-wrangling-practice-with-the-sf-greenhouse-gas-data",
    "title": "Day 8: Tasks & Activities",
    "section": "Task 2: Wrangling practice with the SF Greenhouse Gas data",
    "text": "Task 2: Wrangling practice with the SF Greenhouse Gas data\n\nDownload the San_Francisco_Communitywide_Greenhouse_Gas_Inventory.csv file. Information about the data is available here.\nRead in the SF emissions dataset, then complete the following:\n\n\nCreate a summary table of total annual greenhouse gas emissions (only from Emissions_mtCO2e column) by sector_general\nCreate a summary table of total annual greenhouse gas emissions (only from Emissions_mtCO2e column) by year and commodity type\nCreate a subset of the data that only contains observations from 2005 on, only for observations where Sector_Detail2 contains the pattern “PG&E”, then limit to columns Calendar_Year, Sector_Detail2 and Emissions_mtCO2e."
  },
  {
    "objectID": "course-materials/eod-practice/eod-day8.html#task-3-do-your-data-viz-best",
    "href": "course-materials/eod-practice/eod-day8.html#task-3-do-your-data-viz-best",
    "title": "Day 8: Tasks & Activities",
    "section": "Task 3: Do your data viz best",
    "text": "Task 3: Do your data viz best\nCreate a finalized graph (as perfect as you can make it) using the San Francisco GHG emissions dataset. You get to choose what you want to visualize. You can pick which variables & observations you’re interested in. You may want to do some wrangling / summarizing first.\nOnce you’ve decided on what to plot, create the best graph that you can to communicate what’s going on with the data.\nOnce you’re done, drop your best graph (as a .png or .jpg) into the course Slack channel.\n\nEnd Activity Session (Day 8)"
  },
  {
    "objectID": "course-materials/day9.html#class-materials",
    "href": "course-materials/day9.html#class-materials",
    "title": "Troubleshooting",
    "section": "Class materials",
    "text": "Class materials\n\n\n\n\n\n\n\n\n Session\n Lecture slides\n Interactive session\n\n\n\n\nday 9 / morning\nTroubleshooting 101\n\n\n\nday 9 / afternoon\nkable tables & alt-text\nMore wrangling tools and practice, kable tables"
  },
  {
    "objectID": "course-materials/day9.html#end-of-day-practice",
    "href": "course-materials/day9.html#end-of-day-practice",
    "title": "Troubleshooting",
    "section": "End-of-day practice",
    "text": "End-of-day practice\nComplete the following tasks / activities before heading home for the day!\n\n Day 9 Practice: Troubleshooting, reprex, & working with data continued"
  },
  {
    "objectID": "course-materials/day9.html#additional-resources",
    "href": "course-materials/day9.html#additional-resources",
    "title": "Troubleshooting",
    "section": "Additional Resources",
    "text": "Additional Resources\nTBD"
  },
  {
    "objectID": "course-materials/day10.html#class-materials",
    "href": "course-materials/day10.html#class-materials",
    "title": "Collaboration tools",
    "section": "Class materials",
    "text": "Class materials\n\n\n\n\n\n\n\n\n Session\n Lecture slides\n Interactive session\n\n\n\n\nday 10 / morning\n\nR packages revisited, tables in R, a taste of git collaboration\n\n\nday 10 / afternoon\nCourse wrap-up"
  },
  {
    "objectID": "course-materials/day10.html#end-of-day-practice",
    "href": "course-materials/day10.html#end-of-day-practice",
    "title": "Collaboration tools",
    "section": "End-of-day practice",
    "text": "End-of-day practice\nComplete the following tasks / activities before heading home for the day!\n\n Day 10 Morning Practice: GitHub collaboration\n Day 10 Afternoon Practice: Data import, exploration, & visualization"
  },
  {
    "objectID": "course-materials/day10.html#additional-resources",
    "href": "course-materials/day10.html#additional-resources",
    "title": "Collaboration tools",
    "section": "Additional Resources",
    "text": "Additional Resources\nTBD"
  },
  {
    "objectID": "index.html#course-description",
    "href": "index.html#course-description",
    "title": "Scientific Programming Essentials",
    "section": "Course Description",
    "text": "Course Description\nThis course teaches key scientific programming skills and demonstrates the application of these techniques to environmental data analysis and problem solving. Topics include structured programming and algorithm development, flow control, simple and advanced data input-output and representation, functions and objects, documentation, testing and debugging. The course will be taught using a combination of the R and Python programming languages.\nBy the end of EDS 221, students should be able to:\n\nUnderstand, create, and work with different data structures (e.g. vectors, data frames, lists) and types (e.g. numeric, character, factor, logical, date-times)\nDesign, implement, test, and document functions, including functions with iteration, conditionals, messages, and warnings in R\nUse basic (non-collaborative) project-oriented workflos with reproducible code (R scripts, Quarto documents, Jupyter notebooks) and version control (git/GitHub basics)\nPerform basic data wrangling and visualization with real world environmental data and tidyverse packages (in R)\nEmploy troubleshooting and debugging strategies including tools, mindsets, strategies, and resources"
  },
  {
    "objectID": "index.html#teaching-team",
    "href": "index.html#teaching-team",
    "title": "Scientific Programming Essentials",
    "section": "Teaching Team",
    "text": "Teaching Team\n\n\n\n\nInstructor\n\n\n\n\n\n\n\n\n\n\n\nRuth Oliver\nEmail: rutholiver@ucsb.edu\nLearn more: oliverlab.org\n\n\n\n\nTA\n\n\n\n\n\n\n\n\n\n\n\nAlessandra Vidal Meza\nEmail: avidalmeza@bren.ucsb.edu\nLearn more: avidalmeza.github.io"
  },
  {
    "objectID": "index.html#acknowledgements",
    "href": "index.html#acknowledgements",
    "title": "Scientific Programming Essentials",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nEDS 221 was originally developed and taught by Allison Horst. This new website houses materials which are heavily reused, adapted from, and inspired by Allison’s original work."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "course-materials/day8.html#class-materials",
    "href": "course-materials/day8.html#class-materials",
    "title": "Grammar of graphics",
    "section": "Class materials",
    "text": "Class materials\n\n\n\n\n\n\n\n\n Session\n Lecture slides\n Interactive session\n\n\n\n\nday 8 / morning\nThe grammar of graphics & basic graph considerations\nData visualization in ggplot2\n\n\nday 8 / afternoon\nData visualization basics - responsible, clear, awesome\nData viz continued"
  },
  {
    "objectID": "course-materials/day8.html#end-of-day-practice",
    "href": "course-materials/day8.html#end-of-day-practice",
    "title": "Grammar of graphics",
    "section": "End-of-day practice",
    "text": "End-of-day practice\nComplete the following tasks / activities before heading home for the day!\n\n Day 8 Practice: Data visualization"
  },
  {
    "objectID": "course-materials/day8.html#additional-resources",
    "href": "course-materials/day8.html#additional-resources",
    "title": "Grammar of graphics",
    "section": "Additional Resources",
    "text": "Additional Resources\n\nCed Scherer’s ggplot2 tutorial\nYan Holtz’ From Data to Viz\nR Graph Gallery"
  },
  {
    "objectID": "course-materials/eod-practice/eod-day9.html",
    "href": "course-materials/eod-practice/eod-day9.html",
    "title": "Day 9: Tasks & Activities",
    "section": "",
    "text": "Fork this repo\nIn your fork, under ‘Settings’, check the box next to Issues (this is so you’ll be able to submit issues to yourself containing reprex)\nClone to create a version-controlled R Project\nExplore the contents a bit to familiarize yourself with the structure"
  },
  {
    "objectID": "course-materials/eod-practice/eod-day9.html#setup",
    "href": "course-materials/eod-practice/eod-day9.html#setup",
    "title": "Day 9: Tasks & Activities",
    "section": "",
    "text": "Fork this repo\nIn your fork, under ‘Settings’, check the box next to Issues (this is so you’ll be able to submit issues to yourself containing reprex)\nClone to create a version-controlled R Project\nExplore the contents a bit to familiarize yourself with the structure"
  },
  {
    "objectID": "course-materials/eod-practice/eod-day9.html#task-1-sos---save-this-script",
    "href": "course-materials/eod-practice/eod-day9.html#task-1-sos---save-this-script",
    "title": "Day 9: Tasks & Activities",
    "section": "Task 1: SOS - Save this script",
    "text": "Task 1: SOS - Save this script\n\nOpen the busted_birds.Rmd file\nTry to knit it (R Markdown’s version of rendering). Not happening.\nMake a copy of the file (in the project root) called fixed_birds.Rmd\nWork through the code from the top line down, fixing errors where indicated and using the hints for what the code is actually trying to do.\n\n\n\n\n\n\n\nNote\n\n\n\nIt’s not enough to just get the code to run. You need to actually make sure it’s doing what you expect it to do by checking and understanding the outputs of each line."
  },
  {
    "objectID": "course-materials/eod-practice/eod-day9.html#task-2-help-a-friend-by-making-some-reprex",
    "href": "course-materials/eod-practice/eod-day9.html#task-2-help-a-friend-by-making-some-reprex",
    "title": "Day 9: Tasks & Activities",
    "section": "Task 2: Help a friend by making some reprex",
    "text": "Task 2: Help a friend by making some reprex\n\nOpen the reprex_practice.Rmd file\nThere are two separate code chunks in the .Rmd, neither run.\nFirst, try to figure out what the code in each chunk is trying to do.\nThen, determine where the code breaks (there is only one breaking point for each chunk)\nThen, for each create a reprex that provides a minimal out-of-the-box reproducible working example of the thing in the code that isn’t working. Create your reprex in a separate code chunk below each broken example. Use {reprex} to render your reproducible example for sharing on GitHub. Add your reprexes as issues to one of your neighbor’s GitHub repo for the day 9 activities to help them out! (you’ll need to ask what they’re username is so you can find their repo on GitHub at username/eds221-day9-activities)\n\n\nEnd Activity Session (Day 8)"
  },
  {
    "objectID": "course-materials/eod-practice/eod-day10b.html",
    "href": "course-materials/eod-practice/eod-day10b.html",
    "title": "Day 10: Afternoon Tasks & Activities",
    "section": "",
    "text": "In this activity, you’ll explore ice cover duration for lakes in the Madison Lake Area (long term data, 1853 - present), then further explore trends in mean air temperature from a second dataset.\nThe datasets are here to download:"
  },
  {
    "objectID": "course-materials/eod-practice/eod-day10b.html#your-task",
    "href": "course-materials/eod-practice/eod-day10b.html#your-task",
    "title": "Day 10: Afternoon Tasks & Activities",
    "section": "Your task",
    "text": "Your task\n\nDownload both datasets\nExplore the metadata for each to ensure you know what they contain, variables, units, etc. NOTE: How are missing values stored in the ice duration variable?\nCreate a new version-controlled R Project\nIn a single R Markdown (or Quarto) document:\n\nRead in both files (ice cover duration and meteorological data). Note that the ice cover data has some NA values stored as -999.\nCreate a visualization that compares ice duration across different lakes in the Madison Lake Area. Include both the actual ice duration values and some representation of summary statistics for each lake. Careful if you use a boxplot over a jitter or beeswarm - what values might be doubly represented? Can you find an argument that would help you remove those from the boxplot?\nFind the mean ice cover duration in Madison Lake Area by year (i.e., you’ll only be grouping by the year variable here). Understanding check: what are you finding the mean of here? Why are there multiple observations for each year?)\nCreate an exploratory visualization of mean ice cover duration by year for the Madison Lake Area. Add a sentence or two below this exploratory graph describing the overall trend(s) you observe.\nFind the mean air temperature (using the daily average air temperature - adjusted) in Madison Lake Area by year using only observations from winter months (December, January, February)\nCreate an exploratory visualization of mean winter temperatures for the Madison Lake Area. Add a sentence or two below this exploratory graph describing the overall trend(s) you observe.\nJoin the mean winter air temperatures to the mean ice cover duration data you found above\nCreate an exploratory scatterplot of mean winter temperatures versus mean ice duration. Add a sentence or two below this exploratory graph describing the overall trend(s) you observe.\nExplore thaw dates since 1970. Create a subset of the ice cover duration data since 1970 (ok to include 1970), then convert the ice_off column to a Date. Use lubridate::yday() to pull the numeric day of the year from that Date. Create an exploratory plot of the ice off day (numeric day-of-the-year) from 1970 - present. Add a sentence or two below this exploratory graph describing the overall trend(s) you observe.\n\n\n\nEnd Activity Session (Day 10 Morning)"
  },
  {
    "objectID": "course-materials/eod-practice/eod-day3.html",
    "href": "course-materials/eod-practice/eod-day3.html",
    "title": "Day 3: Task & Activities",
    "section": "",
    "text": "Create a repo on GitHub named eds212-day3-activities\nClone to create a version-controlled R Project\nCreate some subfolder infrastructure (docs, data)"
  },
  {
    "objectID": "course-materials/eod-practice/eod-day3.html#setup",
    "href": "course-materials/eod-practice/eod-day3.html#setup",
    "title": "Day 3: Task & Activities",
    "section": "",
    "text": "Create a repo on GitHub named eds212-day3-activities\nClone to create a version-controlled R Project\nCreate some subfolder infrastructure (docs, data)"
  },
  {
    "objectID": "course-materials/eod-practice/eod-day3.html#conditional-statements-for-loops",
    "href": "course-materials/eod-practice/eod-day3.html#conditional-statements-for-loops",
    "title": "Day 3: Task & Activities",
    "section": "2. Conditional statements & for loops",
    "text": "2. Conditional statements & for loops\nCreate a new Quarto document in your docs folder, saved as conditionals_loops.qmd. Complete all tasks for Part 2 in this .qmd.\nComplete each of the following in a separate code chunk.\n\nConditional statements\n\nTask 1\nCreate an object called pm2_5 with a value of 48 (representing Particulate Matter 2.5, an indicator for air quality, in \\(\\frac{\\mu g}{m^3}\\) (see more about PM2.5 here).\nWrite an if - else if - else statement that returns “Low to moderate risk” if pm2_5 (for Particulate Matter 2.5) is less than 100, “Unhealthy for sensitive groups” if PM 2.5 is 100 &lt;= pm2_5 &lt; 150, and “Health risk present” if PM 2.5 is &gt;= 150.\nTest by changing the value of your pm2_5 object and re-running your statement to check.\n\n\nTask 2\nStore the string “blue whale” as an object called species. Write an if statement that returns “You found a whale!” if the string “whale” is detected in species, otherwise return nothing. Test by changing the species string & re-running to see output.\n\n\n\nTask 3\nStore the base price of a burrito as base_burrito with a value of 6.50. Store main_ingredient with a starting string of “veggie.” Write a statement that will return the price of a burrito based on what a user specifies as “main_ingredient” (either “veggie”, “chicken” or “steak”) given the following:\n\nA veggie burrito is the cost of a base burrito\nA chicken burrito costs 3.00 more than a base burrito\nA steak burrito costs 3.25 more than a base burrito\n\n\n\n\nFor loops\nComplete each of the following in a separate code chunk.\n\nTask 4\nCreate a new vector called fish that contains the values 8, 10, 12, 23 representing counts of different fish types in a fish tank (goldfish, tetras, guppies, and mollies, respectively). Write a for loop that iterates through fish, and returns what proportion of total fish in the tank are that species. Assume that these counts represent all fish in the tank.\n\n\nTask 5\nThere is an existing vector in R called month.name that contains all month names (just try running month.name in the Console to check it out). Write a for loop that iterates over all months in month.name and prints “January is month 1,” “February is month 2”, etc.\nHint: you can index values in the month.name vector just like you would any other vector (e.g., try running month.name[5])."
  },
  {
    "objectID": "course-materials/eod-practice/eod-day3.html#real-data",
    "href": "course-materials/eod-practice/eod-day3.html#real-data",
    "title": "Day 3: Task & Activities",
    "section": "3. Real data",
    "text": "3. Real data\nYou will complete Part 3 in a separate .qmd.\nExplore this data package from EDI, which contains a “Data file describing the biogeochemistry of samples collected at various sites near Toolik Lake, North Slope of Alaska”. Familiarize yourself with the metadata (particularly, View full metadata &gt; expand ‘Data entities’ to learn more about the variables in the dataset).\n\n\n\n\n\n\nCitation\n\n\n\nKling, G. 2016. Biogeochemistry data set for soil waters, streams, and lakes near Toolik on the North Slope of Alaska, 2011. ver 5. Environmental Data Initiative. https://doi.org/10.6073/pasta/362c8eeac5cad9a45288cf1b0d617ba7\n\n\n\nDownload the CSV containing the Toolik biogeochemistry data\nTake a look at it - how are missing values stored? Keep that in mind.\nDrop the CSV into your data folder of your project\nCreate a new Quarto document, save in docs as toolik_chem.qmd\nAttach the tidyverse, here, and janitor packages in your setup code chunk\nRead in the data as toolik_biochem. Remember, you’ll want to specify here how NA values are stored. Pipe directly into janitor::clean_names() following your import code to get all column names into lower snake case.\nCreate a subset of the data that contains only observations from the “Toolik Inlet” site, and that only contains the variables (columns) for pH, dissolved organic carbon (DOC), and total dissolved nitrogen (TDN) (hint: see dplyr::select()). Store this subset as inlet_biochem. Make sure to look at the subset you’ve created.\nFind the mean value of each column in inlet_biochem 3 different ways:\n\n\nWrite a for loop from scratch to calculate the mean for each\nUse one other method (e.g. apply, across, or purrr::map_df) to find the mean for each column.\n\n\nSave, stage, commit, pull, push!\n\nEnd Activity Session (Day 3)"
  },
  {
    "objectID": "course-materials/eod-practice/eod-day2.html",
    "href": "course-materials/eod-practice/eod-day2.html",
    "title": "Day 2: Tasks & Activities",
    "section": "",
    "text": "Create a new repo on GitHub for today’s activities\nClone to create a version controlled R Project\nCreate subfolders called docs, data, and figs\nCreate a Quarto Document, save in the docs subfolder as r_data_types.qmd\n\n\n\n\n\n\nIn your Quarto document:\n\nCreate a vector called vec_1containing the following:\n\n\n2, 5, 9, 10, 8, 12, 1, 0\n\nCheck the following for that vector:\n\nWhat is the class of the vector? class()\nWhat type of variable does it store? typeof()\nAccess the 3rd element and store as vec_1_e3\nAccess the 1st element and store as vec_1_e1\nAccess the 5th through 7th elements and store as vec_1_e5to7\nReassign vec_1 as a character using as.character, stored as vec_1_char. What does the output look like?\n\n\nCreate a vector called vec_2\n\nvec_2 should contained named elements, where town = \"Santa Barbara, location = \"Rincon\", swell = \"south\"\n\nTake a look at what you’ve made\nWhat is the class of vector elements? class()\nWhat is the length of vec_2?\nAccess the 2nd element by name and store as vec_2_e2\n\n\nCreate a data frame in R\n\nWrite code to create a data frame called df_1 that looks like this:\n\n\n  region     species count\n1      A       otter    12\n2      B great white     2\n3      A    sea lion    36\n4      D  gray whale     6\n\n\n\nReturn the class of the entire data frame\nReturn the class of the species column\nFind the maximum value of the count() column, store as max_count"
  },
  {
    "objectID": "course-materials/eod-practice/eod-day2.html#checking-data-types",
    "href": "course-materials/eod-practice/eod-day2.html#checking-data-types",
    "title": "Day 2: Tasks & Activities",
    "section": "",
    "text": "Create a new repo on GitHub for today’s activities\nClone to create a version controlled R Project\nCreate subfolders called docs, data, and figs\nCreate a Quarto Document, save in the docs subfolder as r_data_types.qmd\n\n\n\n\n\n\nIn your Quarto document:\n\nCreate a vector called vec_1containing the following:\n\n\n2, 5, 9, 10, 8, 12, 1, 0\n\nCheck the following for that vector:\n\nWhat is the class of the vector? class()\nWhat type of variable does it store? typeof()\nAccess the 3rd element and store as vec_1_e3\nAccess the 1st element and store as vec_1_e1\nAccess the 5th through 7th elements and store as vec_1_e5to7\nReassign vec_1 as a character using as.character, stored as vec_1_char. What does the output look like?\n\n\nCreate a vector called vec_2\n\nvec_2 should contained named elements, where town = \"Santa Barbara, location = \"Rincon\", swell = \"south\"\n\nTake a look at what you’ve made\nWhat is the class of vector elements? class()\nWhat is the length of vec_2?\nAccess the 2nd element by name and store as vec_2_e2\n\n\nCreate a data frame in R\n\nWrite code to create a data frame called df_1 that looks like this:\n\n\n  region     species count\n1      A       otter    12\n2      B great white     2\n3      A    sea lion    36\n4      D  gray whale     6\n\n\n\nReturn the class of the entire data frame\nReturn the class of the species column\nFind the maximum value of the count() column, store as max_count"
  },
  {
    "objectID": "course-materials/eod-practice/eod-day2.html#wild-data",
    "href": "course-materials/eod-practice/eod-day2.html#wild-data",
    "title": "Day 2: Tasks & Activities",
    "section": "2. Wild data",
    "text": "2. Wild data\n\nSet-up\n\nVisit the EDI site to learn about Mack Creek salamander & cutthroat trout data you’ll be using here: data package\nDownload the first CSV listed (AS00601.csv), and take a look at it (outside of R is fine as a first step, e.g. you can open the CSV in Excel)\nExplore the metadata (see View Full Metadata in the Resources section of the data website)\nWhat does each column contain? What are the units of each? What is the study overall about?\nCreate a new Quarto Document and save it in your docs folder. Attach the tidyverse, here and janitor packages in the setup chunk (you choose the file name)\nSet global options in the YAML so that messages and warnings do NOT show up in the rendered document\nSave the AS00601.csv in your data folder of your project\n\n\n\nRead in the data\n\nRead in the data using read_csv() with here(), store as mack_verts\nLook at what you’ve read in (e.g. with view())\n\n\n\nA bit of wrangling & exploring\n\nUpdate the variable names in mack_verts to lower snake case\nIn a new code chunk, practice accessing individual pieces of the data frame (there is no real functionality to this right now, but just to reinforce stuff we learned in our interactive session):\n\nStore the 5th value in column “WEIGHT” as mc_wt_5. Check by looking at your data frame to confirm.\nStore the 8th - 20th value in the “LENGTH1” column as mc_length_8_20. Check by looking at your data frame to confirm.\nStore everything in column SAMPLEDATE as a vector called mc_dates\n\n\n\n\nMake a salamander subset\n\nCreate a subset that only contains observations for Pacific Giant Salamanders (species Dicamptodon tenebrosus, stored in species as DITE). Store the subset as mc_salamanders. Hint: see dplyr::filter()!\n\n\n\nMake a scatterplot of salamander length x weight\n\nCreate a scatterplot of length1 (snout-vent length in millimeters) versus weight (grams) for all salamanders in the subset you created above, mc_salamanders. Update axis labels, title, subtitle, and add a caption with the data source. Customize point color and size, possibly opacity, and theme.\nExport your scatterplot as salamander_size.png to your figs folder.\n\n\n\nMake a cutthroat plot\n\nSimilar to above, make a subset called mc_trout that only contains observations for cutthroat trout (species “ONCL”)\nCreate a scatterplot of length1 by weight for all trout in the dataset\nCustomize so that the point color depends on reach\nCustomize your color scheme (e.g. scale_color_manual())\nFacet your plot by creek reach (hint: facet_wrap(~...))\nUpdate graph axis labels and title\nExport your graph as cutthroat_size.png to the figs folder\n\n\n\nStage, commit, pull, push\n\nMake sure your changes are safely stored by pushing to GitHub\nClose your project locally\nReopen your project locally\nReopen your .qmd files for the activities you did today.\nRender. Does it work? Done.\n\n\nEnd Activity Session (Day 2)"
  },
  {
    "objectID": "course-materials/eod-practice/eod-day7.html",
    "href": "course-materials/eod-practice/eod-day7.html",
    "title": "Day 7: Tasks & Activities",
    "section": "",
    "text": "Create a new repo on GitHub called eds221-day7-activities\nClone to make a version controlled R Project\nAdd subfolders data, R and figs\nFamiliarize yourself with the contents, data files, and variables from this data package on EDI\nDownload the entire Zip Archive for the package\nCopy all 4 files to your data folder"
  },
  {
    "objectID": "course-materials/eod-practice/eod-day7.html#setup",
    "href": "course-materials/eod-practice/eod-day7.html#setup",
    "title": "Day 7: Tasks & Activities",
    "section": "",
    "text": "Create a new repo on GitHub called eds221-day7-activities\nClone to make a version controlled R Project\nAdd subfolders data, R and figs\nFamiliarize yourself with the contents, data files, and variables from this data package on EDI\nDownload the entire Zip Archive for the package\nCopy all 4 files to your data folder"
  },
  {
    "objectID": "course-materials/eod-practice/eod-day7.html#task-1-joins-on-birds",
    "href": "course-materials/eod-practice/eod-day7.html#task-1-joins-on-birds",
    "title": "Day 7: Tasks & Activities",
    "section": "Task 1: Joins on birds",
    "text": "Task 1: Joins on birds\nIn this section, you’ll test and explore a number of different joins.\n\nCreate a new .qmd in your R folder saved as bird_joins.qmd\nRead in the data sets and store the data frames as bird_observations, sites, surveys, and taxalist (it should be clear from the raw file names which is which)\nCreate a subset of bird_observations called birds_subset that only contains observations for birds with species id “BHCO” and “RWBL”, and from sites with site ID “LI-W” and “NU-C”\n\n\nLeft join practice\n\nUse left join(s) to update birds_subset so that it also includes sites and taxalist information. For each join, include an explicit argument saying which variable you are joining by (even if it will just assume the correct one for you). Store the updated data frame as birds_left. Make sure to look at the output - is what it contains consistent with what you expected it to contain?\n\n\n\nFull join practice\n\nFirst, answer: what do you expect a full_join() between birds_subset and sites to contain?\nWrite code to full_join the birds_subset and sites data into a new object called birds_full. Explicitly include the variable you’re joining by. Look at the output. Is it what you expected?"
  },
  {
    "objectID": "course-materials/eod-practice/eod-day7.html#task-2-data-wrangling-and-visualization-with-birds",
    "href": "course-materials/eod-practice/eod-day7.html#task-2-data-wrangling-and-visualization-with-birds",
    "title": "Day 7: Tasks & Activities",
    "section": "Task 2: Data wrangling and visualization with birds",
    "text": "Task 2: Data wrangling and visualization with birds\nContinue in your same .qmd that you created for Task 1\n\nStarting with your birds object, rename the notes column to bird_obs_notes (so this doesn’t conflict with notes in the surveys dataset\nThen, create a subset that contains all observations in the birds dataset, joins the taxonomic, site and survey information to it, and is finally limited to only columns survey_date, common_name, park_name, and bird_count. You can decide the order that you want to create this in (e.g. limit the columns first, then join, or the other way around).\nUse lubridate::month() to add a new column called survey_month, containing only the month number. Then, convert the month number to a factor (again within mutate())\nLearn a new function on your own! Use dplyr::relocate() to move the new survey_month column to immediately after the survey_date column. You can do this in a separate code chunk, or pipe straight into it from your existing code.\nFind the total number of birds observed by park and month (i.e., you’ll group_by(park_name, survey_month))\nFilter to only include parks “Lindo”, “Orme”, “Palomino” and “Sonrisa”"
  },
  {
    "objectID": "course-materials/eod-practice/eod-day7.html#task-3-practice-with-strings",
    "href": "course-materials/eod-practice/eod-day7.html#task-3-practice-with-strings",
    "title": "Day 7: Tasks & Activities",
    "section": "Task 3: Practice with strings",
    "text": "Task 3: Practice with strings\n\nCreate a new .qmd in your R folder called string_practice.qmd\nCopy all contents of the html table below to your clipboard:\n\n\n\n\n\n\ndate\nbuilding\nalarm_message\n\n\n\n\n2020-03-14\nEngineering-North\n10:02am -- HVAC system down, facilities management alerted\n\n\n2020-03-15\nBren Hall\n8:24am -- Elevator North out of service\n\n\n2020-04-10\nEngineering-South\n12:41am -- Fire alarm, UCSB fire responded and cleared\n\n\n2020-04-18\nEngr-North\n9:58pm -- Campus point emergency siren, UCPD responded\n\n\n\n\n\n\n\n\nBack in your string_practice.Rmd, create a new code chunk\nWith your cursor in your code chunk, go up to Addins in the top bar of RStudio. From the drop-down menu, choose ‘Paste as data frame’. Make sure to add code to store the data frame as alarm_report\nPractice working with strings by writing code to update alarm_report as follows (these can be separate, or all as part of a piped sequence):\n\nReplace the “Engr” with “Engineering” in the building column\nSeparate the building column into two separate columns, building and wing, separated at the dash\nOnly keep observations with the word “responded” in the alarm_message column\nSeparate the message time from the rest of the message by separating at --\nConvert the date column to a Date class using lubridate\n\n\n\nEnd Activity Session (Day 7)"
  },
  {
    "objectID": "course-materials/eod-practice/eod-day4.html",
    "href": "course-materials/eod-practice/eod-day4.html",
    "title": "Day 4: Task & Activities",
    "section": "",
    "text": "Create a repo on GitHub named eds221-day4-activities\nClone to create a version-controlled R Project\nCreate some subfolder infrastructure (docs, data)\nAdd a new Quarto file, save as loops_and_functions.qmd in docs"
  },
  {
    "objectID": "course-materials/eod-practice/eod-day4.html#setup",
    "href": "course-materials/eod-practice/eod-day4.html#setup",
    "title": "Day 4: Task & Activities",
    "section": "",
    "text": "Create a repo on GitHub named eds221-day4-activities\nClone to create a version-controlled R Project\nCreate some subfolder infrastructure (docs, data)\nAdd a new Quarto file, save as loops_and_functions.qmd in docs"
  },
  {
    "objectID": "course-materials/eod-practice/eod-day4.html#for-loops-revisited",
    "href": "course-materials/eod-practice/eod-day4.html#for-loops-revisited",
    "title": "Day 4: Task & Activities",
    "section": "2. For loops revisited",
    "text": "2. For loops revisited\n\nTask 1\nCreate two sequences, one called weekdays that contains days of the week (“Monday”, “Tuesday”, “Wednesday”, etc.) and one called transects that contains the series of transect names “Transect A”, “Transect B,”Transect C”. Write a nested for loop that creates a matrix containing the following:\n\n\n\n\n\n\n\n\n\n\n\n\nMonday - Transect A\nMonday - Transect B\nMonday - Transect C\n\n\nTuesday - Transect A\nTuesday - Transect B\nTuesday - Transect C\n\n\nWednesday - Transect A\nWednesday - Transect B\nWednesday - Transect C\n\n\nThursday - Transect A\nThursday - Transect B\nThursday - Transect C\n\n\nFriday - Transect A\nFriday - Transect B\nFriday - Transect C\n\n\nSaturday - Transect A\nSaturday - Transect B\nSaturday - Transect C\n\n\nSunday - Transect A\nSunday - Transect B\nSunday - Transect C"
  },
  {
    "objectID": "course-materials/eod-practice/eod-day4.html#functions-introduced",
    "href": "course-materials/eod-practice/eod-day4.html#functions-introduced",
    "title": "Day 4: Task & Activities",
    "section": "3. Functions introduced",
    "text": "3. Functions introduced\n\nTask 2\nWrite a function called force that calculates a force (in Newtons), given inputs of mass (in kg) and acceleration (in \\(\\frac{m}{s^2}\\) (recall: \\(F = ma\\)), and returns a statement “The resulting force is ___ Newtons.”\n\n\n\nTask 3\nThe length:weight relationship for fish is: \\(W=aL^b\\), where where L is total fish length (centimeters), W is the expected fish weight (grams), and a and b are species-dependent parameter values (shown below for several fish from Peyton et al. 2016).\n\n\n\n\n\nsci_name\ncommon_name\na_est\nb_est\n\n\n\n\nChanos chanos\nMilkfish\n0.0905\n2.52\n\n\nSphyraena barracuda\nGreat barracuda\n0.0181\n3.27\n\n\nCaranx ignobilis\nGiant trevally\n0.0353\n3.05\n\n\n\n\n\n\n\nRecreate the table above as a data frame stored as fish_parms. Then, write a function called fish_weight that allows a user to only enter the common name (argument fish_name) and total length (argument tot_length) (in centimeters) of a fish, to return the expected fish weight in grams. Test it out for different species and lengths.\nNow, try creating a vector of lengths (e.g. 0 to 100, by increments of 1) and ensuring that your function will calculate the fish weight over a range of lengths for the given species (try this for milkfish, storing the output weights as milkfish_weights.\n\n\nTask 4\nWave power (more accurately wave energy flux) in deep water is approximated by:\n\\[P_{deep}=0.5 H^2 T\\] where \\(P\\) is power in \\(\\frac{kW}{m}\\) (potential power per wave meter), \\(H\\) is wave height in meters (more specifically, the significant wave height), and \\(T\\) is the wave period in seconds. Learn more here.\nWrite a function called wave_power that calculates potential ocean wave power given inputs of wave height and period.\nUse your wave_power function to approximate wave power for a period of 8 seconds, over a range of wave heights from 0 to 3 meters by increments of 0.2 meters.\n\n\nTask 5 (OPTIONAL)\nThe wave energy equation changes based on ocean depth. Along the coast of Brenville, which has a very sharp shelf as the wave approaches the coast, wave energy is approximated using the deep ocean equation (the one you used above) for depths &gt; 12 meters, and a shallow equation for depths &lt;= 12 meters. The Brenville team estimates shallow wave power by:\n\\[P_{shallow}=0.81 H^2 T\\]\nCreate a function that requires inputs of water depth, wave height and period, then returns the approximated wave power using the correct equation for the depth entered. It should also include a message (hint: use message() just like you would use warning!) that lets the user know if the shallow or deep water equation was used.\n\n\n\n\n\n\n\nCitation\n\n\n\nPeyton, K. A., T. S. Sakihara, L. K. Nishiura, T. T. Shindo, T. E. Shimoda, S. Hau, A. Akiona, and K. Lorance. 2016. “Length–Weight Relationships for Common Juvenile Fishes and Prey Species in Hawaiian Estuaries.” Journal of Applied Ichthyology 32 (3): 499–502. https://doi.org/10.1111/jai.12957.\n\n\n\nEnd Activity Session (Day 4)"
  },
  {
    "objectID": "course-materials/day5.html#class-materials",
    "href": "course-materials/day5.html#class-materials",
    "title": "Testing, documentation, and sharing",
    "section": "Class materials",
    "text": "Class materials\n\n\n\n\n\n\n\n\n Session\n Lecture slides\n Interactive session\n\n\n\n\nday 5 / morning\nFunctions continued: testing, documentation, sharing\nFunctions 103: testing & documenting, making your first package\n\n\nday 5 / afternoon\nFinding & using external packages\nFind & explore packages, documentation, accessing from repos"
  },
  {
    "objectID": "course-materials/day5.html#end-of-day-practice",
    "href": "course-materials/day5.html#end-of-day-practice",
    "title": "Testing, documentation, and sharing",
    "section": "End-of-day practice",
    "text": "End-of-day practice\nComplete the following tasks / activities before heading home for the day!\n\n Day 5 Practice: Loops revisited, functions continued, testing & sourcing scripts, working on your R package"
  },
  {
    "objectID": "course-materials/day5.html#additional-resources",
    "href": "course-materials/day5.html#additional-resources",
    "title": "Testing, documentation, and sharing",
    "section": "Additional Resources",
    "text": "Additional Resources\nTBD"
  },
  {
    "objectID": "course-materials/day6.html#class-materials",
    "href": "course-materials/day6.html#class-materials",
    "title": "Tidy data",
    "section": "Class materials",
    "text": "Class materials\n\n\n\n\n\n\n\n\n Session\n Lecture slides\n Interactive session\n\n\n\n\nday 6 / morning\nTidy data: what, why, how?\nTidying data (pivot, separate) basics with tidyr and pandas\n\n\nday 6 / afternoon\nData tidying and wrangling continued: dplyr and pandas\nData wrangling continued - dplyr and pandas"
  },
  {
    "objectID": "course-materials/day6.html#end-of-day-practice",
    "href": "course-materials/day6.html#end-of-day-practice",
    "title": "Tidy data",
    "section": "End-of-day practice",
    "text": "End-of-day practice\nComplete the following tasks / activities before heading home for the day!\n\n Day 6 Practice: Tidying & subsetting with tidyr and dplyr"
  },
  {
    "objectID": "course-materials/day6.html#additional-resources",
    "href": "course-materials/day6.html#additional-resources",
    "title": "Tidy data",
    "section": "Additional Resources",
    "text": "Additional Resources\nTBD"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-2b.html",
    "href": "course-materials/interactive-sessions/interactive-session-2b.html",
    "title": "Interactive Session 2B",
    "section": "",
    "text": "Source materials\n\n\n\nThese materials are modified from the following source:\nWickham, Hadley. Advanced R.\nhttp://adv-r.had.co.nz/Subsetting.html"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-2b.html#selecting-multiple-elements",
    "href": "course-materials/interactive-sessions/interactive-session-2b.html#selecting-multiple-elements",
    "title": "Interactive Session 2B",
    "section": "1. Selecting multiple elements",
    "text": "1. Selecting multiple elements\n\nAtomic vectors\nLet’s explore the different types of subsetting with a simple vector, x using [.\n\nx &lt;- c(2.1, 4.2, 3.3, 5.4)\n\nNote that the number after the decimal point represents the original position in the vector.\nThere are six things that you can use to subset a vector:\n\nPositive integers return elements at the specified positions:\n\nx[c(3, 1)]\n\n[1] 3.3 2.1\n\nx[order(x)]\n\n[1] 2.1 3.3 4.2 5.4\n\n# Duplicate indices will duplicate values\nx[c(1, 1)]\n\n[1] 2.1 2.1\n\n# Real numbers are silently truncated to integers\nx[c(2.1, 2.9)]\n\n[1] 4.2 4.2\n\n\nNegative integers exclude elements at the specified positions:\n\nx[-c(3, 1)]\n\n[1] 4.2 5.4\n\n\nNote that you can’t mix positive and negative integers in a single subset:\n\nx[c(-1, 2)]\n\nError in x[c(-1, 2)]: only 0's may be mixed with negative subscripts\n\n\nLogical vectors select elements where the corresponding logical value is TRUE. This is probably the most useful type of subsetting because you can write an expression that uses a logical vector:\n\nx[c(TRUE, TRUE, FALSE, FALSE)]\n\n[1] 2.1 4.2\n\nx[x &gt; 3]\n\n[1] 4.2 3.3 5.4\n\n\n In x[y], what happens if x and y are different lengths? The behaviour is controlled by the recycling rules where the shorter of the two is recycled to the length of the longer. This is convenient and easy to understand when one of x and y is length one, but I recommend avoiding recycling for other lengths because the rules are inconsistently applied throughout base R.\n\nx[c(TRUE, FALSE)]\n\n[1] 2.1 3.3\n\n# Equivalent to\nx[c(TRUE, FALSE, TRUE, FALSE)]\n\n[1] 2.1 3.3\n\n\nNote that a missing value in the index always yields a missing value in the output:\n\nx[c(TRUE, TRUE, NA, FALSE)]\n\n[1] 2.1 4.2  NA\n\n\nNothing returns the original vector. This is not useful for 1D vectors, but, as you’ll see shortly, is very useful for matrices, data frames, and arrays. It can also be useful in conjunction with assignment.\n\nx[]\n\n[1] 2.1 4.2 3.3 5.4\n\n\nZero returns a zero-length vector. This is not something you usually do on purpose, but it can be helpful for generating test data.\n\nx[0]\n\nnumeric(0)\n\n\n\n\n\n\n\n\n\nSubsetting with factors\n\n\n\nFactors are not treated specially when subsetting. This means that subsetting will use the underlying integer vector, not the character levels. This is typically unexpected, so you should avoid subsetting with factors:\n\nx[factor(\"b\")]\n\n[1] 2.1"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-2b.html#subsetting-and-assignment",
    "href": "course-materials/interactive-sessions/interactive-session-2b.html#subsetting-and-assignment",
    "title": "Interactive Session 2B",
    "section": "2. Subsetting and assignment",
    "text": "2. Subsetting and assignment\nAll subsetting operators can be combined with assignment to modify selected values of the input vector.\n\nx &lt;- 1:5\nx[c(1, 2)] &lt;- 2:3\nx\n\n[1] 2 3 3 4 5\n\n\nYou just need to make sure that the lengths of left and right hand side of the assignments match.\n\nx[-1] &lt;- 4:1\nx\n\n[1] 2 4 3 2 1\n\n\nYou can’t combine integer indices with NA\n\nx[c(1, NA)] &lt;- c(1, 2)\n\nBut you can combine logical indices and NAs! (The NAs will be treated as false.)\n\nx[c(T, F, NA)] &lt;- 1\nx\n\n[1] 1 4 3 1 1\n\n\nThis becomes really useful because you can conditionally modify vectors.\n\ndf &lt;- data.frame(a = c(1, 10, NA))\ndf$a[df$a &lt; 5] &lt;- 0\ndf$a\n\n[1]  0 10 NA"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-2b.html#subsetting-rows-based-on-conditions-logical-subsetting",
    "href": "course-materials/interactive-sessions/interactive-session-2b.html#subsetting-rows-based-on-conditions-logical-subsetting",
    "title": "Interactive Session 2B",
    "section": "3. Subsetting rows based on conditions (logical subsetting)",
    "text": "3. Subsetting rows based on conditions (logical subsetting)\nWe can use the same operations to subset data based on conditions.\nFor example, if we wanted to find all the cars with 5 gears.\n\nmtcars[mtcars$gear == 5, ]\n\n                mpg cyl  disp  hp drat    wt qsec vs am gear carb\nPorsche 914-2  26.0   4 120.3  91 4.43 2.140 16.7  0  1    5    2\nLotus Europa   30.4   4  95.1 113 3.77 1.513 16.9  1  1    5    2\nFord Pantera L 15.8   8 351.0 264 4.22 3.170 14.5  0  1    5    4\nFerrari Dino   19.7   6 145.0 175 3.62 2.770 15.5  0  1    5    6\nMaserati Bora  15.0   8 301.0 335 3.54 3.570 14.6  0  1    5    8\n\n\nOr, we could subset based on conditions for multiple columns.\n\nmtcars[mtcars$gear == 5 & mtcars$cyl == 4, ]\n\n               mpg cyl  disp  hp drat    wt qsec vs am gear carb\nPorsche 914-2 26.0   4 120.3  91 4.43 2.140 16.7  0  1    5    2\nLotus Europa  30.4   4  95.1 113 3.77 1.513 16.9  1  1    5    2\n\n\nThe subset() function is a specialized shorthand function for subsetting data frames.\n\nsubset(mtcars, gear == 5)\n\n                mpg cyl  disp  hp drat    wt qsec vs am gear carb\nPorsche 914-2  26.0   4 120.3  91 4.43 2.140 16.7  0  1    5    2\nLotus Europa   30.4   4  95.1 113 3.77 1.513 16.9  1  1    5    2\nFord Pantera L 15.8   8 351.0 264 4.22 3.170 14.5  0  1    5    4\nFerrari Dino   19.7   6 145.0 175 3.62 2.770 15.5  0  1    5    6\nMaserati Bora  15.0   8 301.0 335 3.54 3.570 14.6  0  1    5    8\n\nsubset(mtcars, gear == 5 & cyl == 4)\n\n               mpg cyl  disp  hp drat    wt qsec vs am gear carb\nPorsche 914-2 26.0   4 120.3  91 4.43 2.140 16.7  0  1    5    2\nLotus Europa  30.4   4  95.1 113 3.77 1.513 16.9  1  1    5    2"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-2b.html#removing-columns-from-data-frames-character-subsetting",
    "href": "course-materials/interactive-sessions/interactive-session-2b.html#removing-columns-from-data-frames-character-subsetting",
    "title": "Interactive Session 2B",
    "section": "4. Removing columns from data frames (character subsetting)",
    "text": "4. Removing columns from data frames (character subsetting)\nTo remove columns from a data frame, you can…\n\nset individual columns to NULL\n\n\ndf &lt;- data.frame(x = 1:3, y = 3:1, z = letters[1:3])\ndf$z &lt;- NULL\ndf\n\n  x y\n1 1 3\n2 2 2\n3 3 1\n\n\n\nsubset to return only the columns you want, based on their names\n\n\ndf &lt;- data.frame(x = 1:3, y = 3:1, z = letters[1:3])\ndf[c(\"x\", \"y\")]\n\n  x y\n1 1 3\n2 2 2\n3 3 1\n\n\n\nor, if you know the columns you don’t want, use set operations to work which columns to keep\n\n\ndf[setdiff(names(df), \"z\")]\n\n  x y\n1 1 3\n2 2 2\n3 3 1\n\n\n\nEnd Interactive Session 2A"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-8.html",
    "href": "course-materials/interactive-sessions/interactive-session-8.html",
    "title": "Interactive Session 8",
    "section": "",
    "text": "Fork then clone this repo to create a version-controlled R Project for Day 8\nCreate a new Quarto document\nAttach R packages\n\n\n# General use packages:\nlibrary(tidyverse)\nlibrary(here)\nlibrary(janitor)\n\n# Specifically for plots:\nlibrary(patchwork)\nlibrary(ggrepel)\nlibrary(gghighlight)\nlibrary(paletteer)\nlibrary(ggExtra)\nlibrary(ggbeeswarm)\n\n# And for another dataset we'll explore:\nlibrary(gapminder)\n\n# Spatial\nlibrary(sf)"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-8.html#setup",
    "href": "course-materials/interactive-sessions/interactive-session-8.html#setup",
    "title": "Interactive Session 8",
    "section": "",
    "text": "Fork then clone this repo to create a version-controlled R Project for Day 8\nCreate a new Quarto document\nAttach R packages\n\n\n# General use packages:\nlibrary(tidyverse)\nlibrary(here)\nlibrary(janitor)\n\n# Specifically for plots:\nlibrary(patchwork)\nlibrary(ggrepel)\nlibrary(gghighlight)\nlibrary(paletteer)\nlibrary(ggExtra)\nlibrary(ggbeeswarm)\n\n# And for another dataset we'll explore:\nlibrary(gapminder)\n\n# Spatial\nlibrary(sf)"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-8.html#data",
    "href": "course-materials/interactive-sessions/interactive-session-8.html#data",
    "title": "Interactive Session 8",
    "section": "2. Data",
    "text": "2. Data\n\nLizard size measurement data\nOur data are a curated subset from Jornada Basin Long Term Ecological Research site in New Mexico, part of the US Long Term Ecological Research (LTER) network:\n\n\n\n\n\n\nCitation\n\n\n\nLightfoot, D. and W.G. Whitford. 2020. Lizard pitfall trap data from 11 NPP study locations at the Jornada Basin LTER site, 1989-2006 ver 37. Environmental Data Initiative. https://doi.org/10.6073/pasta/4a6e258fb49c31e222ecbbcfd128967f\n\n\nFrom the data package:\n\n“This data package contains data on lizards sampled by pitfall traps located at 11 consumer plots at Jornada Basin LTER site from 1989-2006. The objective of this study is to observe how shifts in vegetation resulting from desertification processes in the Chihuahaun desert have changed the spatial and temporal availability of resources for consumers. Desertification changes in the Jornada Basin include changes from grass to shrub dominated communities and major soil changes. If grassland systems respond to rainfall without significant lags, but shrub systems do not, then consumer species should reflect these differences. In addition, shifts from grassland to shrubland results in greater structural heterogeneity of the habitats. We hypothesized that consumer populations, diversity, and densities of some consumers will be higher in grasslands than in shrublands and will be related to the NPP of the sites. Lizards were captured in pitfall traps at the 11 LTER II/III consumer plots (a subset of NPP plots) quarterly for 2 weeks per quarter. Variables measured include species, sex, recapture status, snout-vent length, total length, weight, and whether tail is broken or whole. This study is complete.”\n\nThere are 16 total variables in the lizards.csv data we’ll read in. The ones we’ll use in this workshop are:\n\ndate: data collection date\nscientific_name: lizard scientific name\ncommon_name: lizard common name\nsite: research site code\nsex: lizard sex (m = male; f = female; j = juvenile)\nsv_length: snout-vent length (millimeters)\ntotal_length: body length (millimeters)\ntoe_num: toe mark number\nweight: body weight (grams)\ntail: tail condition (b = broken; w = whole)\n\n\n\nJornada vegetation spatial data\n\n\n\n\n\n\nCitation\n\n\n\nJornada Basin LTER Spatial Data: Dominant Vegetation of the JER and CDRRC in 1998 (Download KMZ 3972 KB) Dominant and subdominant vegetation on the Jornada Experimental Range and Chihuahuan Desert Rangeland Research Center in 1998. Published in Gibbens, R. P., McNeely, R. P., Havstad, K. M., Beck, R. F., & Nolen, B. (2005). Vegetation changes in the Jornada Basin from 1858 to 1998. Journal of Arid Environments, 61(4), 651-668."
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-8.html#ggplot2-basics-review",
    "href": "course-materials/interactive-sessions/interactive-session-8.html#ggplot2-basics-review",
    "title": "Interactive Session 8",
    "section": "3. {ggplot2} basics review",
    "text": "3. {ggplot2} basics review\nRead in the lizard data\n\nlizards &lt;- read_csv(here(\"data_tidy\", \"lizards.csv\"))\n\n\n\nRows: 1628 Columns: 16\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (10): date, scientific_name, common_name, zone, site, plot, spp, sex, rc...\ndbl  (6): pit, toe_num, sv_length, total_length, weight, pc\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nThe essentials\nWhen we start creating a ggplot graph, we need three basic building blocks:\n\nWe’re using ggplot\nWhat data we want to use in our graph\nWhat type of graph we’re creating\n\nFor example:\n\n# ggplot essential pieces, 3 ways (that do the same thing):\n\n# Like this: \nggplot(data = lizards, aes(x = total_length, y = weight)) + # That's 1 & 2\n  geom_point() # That's 3\n\n# Or, alternatively:\nggplot(data = lizards) +\n  geom_point(aes(x = total_length, y = weight))\n\n# Or another way:\nggplot() +\n  geom_point(data = lizards, aes(x = total_length, y = weight))\n\nWhich all produce the same thing:\n\n\n\n\n\n\n\n\n\nWhich makes changing graph types straightforward by updating the geom_:\n\nggplot(data = lizards, aes(x = total_length, y = weight)) +\n  geom_line() # Bad idea, just demonstrating a geom switch.\n\n\n\n\n\n\n\n\nKeep in mind that some graph types only require one variable - for example, geom_histogram:\n\nggplot(data = lizards, aes(x = total_length)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nAnd remember to carefully consider the type of data you’re trying to visualize, which will help to direct the graph type. For example, a jitterplot usually has one categorical variable and one continuous variable:\n\nggplot(data = lizards, aes(y = common_name, x = weight)) +\n  geom_jitter()\n\n\n\n\n\n\n\n\nNot sure which type of graph is appropriate for your data? My favorite resource is Yan Holtz’ From Data to Viz - check it out, it is fun and amazing, and links to code examples from the R Graph Gallery.\n\n\nAesthetic mapping\n\nUpdating based on a constant? NO aes()!\nTo change aesthetics of a graph based on a constant (e.g. “Make all the points BLUE”), we can add the information directly to the relevant geom_ layer. Some things to keep in mind:\n\nfill: updates fill colors (e.g. column, density, violin, & boxplot interior fill color)\ncolor: updates point & border line colors (generally)\nshape: update point style\nalpha: update transparency (0 = transparent, 1 = opaque)\nsize: point size or line width\nlinetype: update the line type (e.g. “dotted”, “dashed”, “dotdash”, etc.)\n\nIf you are updating these by referring to a constant value, they should not be within an aes().\nFor example, let’s make some nightmares:\n\nggplot(data = lizards, aes(x = weight)) +\n  geom_histogram(color = \"orange\", \n                 fill = \"purple\", \n                 size = 2, \n                 linetype = \"dotted\")\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nSome shapes have both a fill and color aesthetic:\n\nggplot(data = lizards, aes(x = total_length, y = weight)) +\n  geom_point(color = \"cyan4\", \n             fill = \"yellow\",\n             shape = 22, \n             size = 3, \n             alpha = 0.4)\n\n\n\n\n\n\n\n\n\n\n\nUpdating an aesthetic based on a variable? YES aes()!\nIf you want to map a variable onto a graph aesthetic (e.g., point color should be based on lizard species), put it within aes().\n\nggplot(data = lizards, aes(x = total_length, y = weight)) +\n  geom_point(aes(color = common_name, size = total_length))\n\n\n\n\n\n\n\n\nThese can be used in combination. For example, if we want the color to be based on species, but the transparency for all points is 0.3:\n\nggplot(data = lizards, aes(x = total_length, y = weight)) +\n  geom_point(aes(color = common_name), alpha = 0.3)\n\n\n\n\n\n\n\n\n\n\nThemes\nQuick reminder: yeah there are some built-in themes you can add with + theme_*().\nA few useful baselines are:\n\ntheme_minimal(): minimal theme\ntheme_bw(): also pretty good for some stuff\ntheme_light(): a nice light one\n\n\nggplot(data = lizards, aes(x = site, y = weight)) +\n  geom_jitter(aes(color = common_name)) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nAxis labels\nFor basic axis labels, I recommend labs():\n\nggplot(data = lizards, aes(x = total_length, y = weight)) +\n  geom_point() +\n  labs(x = \"Total length (mm)\",\n       y = \"Weight (grams)\",\n       title = \"Lizard size\")\n\n\n\n\n\n\n\n\nWe’ll learn a few more advanced label skills later on.\n\n\nFacetting\nSometimes it’s useful to split up information in a graph into separate panels. For example, maybe we want to have a separate graph of total length versus weight for each lizard species. That would be really tedious to create them all manually from subsets. Instead, we’ll facet by distinct groups within a variable.\nWe’ll learn two ways to do this:\n\nfacet_wrap(): the one where you give it one faceting variable and the panels get wrapped into a grid\nfacet_grid(): the one where you make a grid based on row & column faceting variables\n\nFor example, let’s say we just want each species to have its own panel. Then we can use facet_wrap():\n\nggplot(data = lizards, aes(x = total_length, y = weight)) +\n  geom_point() +\n  facet_wrap(~common_name, ncol = 3, scales = \"free\")\n\n\n\n\n\n\n\n\nBut what if we want to make a grid where the panels are split across groups by lizard sex and if it has a broken tail or not? Since we have two variables being used to create our grid, we’ll use facet_grid():\n\nggplot(data = lizards, aes(x = total_length, y = weight)) +\n  geom_point() +\n  facet_grid(sex ~ tail)\n\n\n\n\n\n\n\n\n\n\nGetting things in order\nggplot loves putting things in alphabetical order - but that’s rarely the order you actually want things in if you have categorical groups. Let’s find some total counts of lizards in the dataset by common name, then make a column graph:\n\nlizard_counts &lt;- lizards %&gt;% \n  count(common_name)\n\nggplot(data = lizard_counts, aes(y = fct_reorder(common_name, n), x = n)) +\n  geom_col()\n\n\n\n\n\n\n\n\n\n\nggplot basics: synthesis examples\nExample 1: A quick review of basics, including:\n\nggplot essentials\naesthetic mapping\nthemes\nfacet_wrap & facet_grid\nlabels with labs\n\n\nggplot(data = lizards, aes(x = total_length, y = weight)) +\n  geom_point(aes(color = common_name, shape = common_name), \n             fill = \"black\",\n             size = 2) +\n  theme_minimal() +\n  labs(x = \"Total length (mm)\",\n       y = \"Weight (g)\",\n       color = \"Lizard species\") +\n  facet_wrap(~common_name, scales = \"free\")\n\nWarning: The shape palette can deal with a maximum of 6 discrete values because more\nthan 6 becomes difficult to discriminate\nℹ you have requested 7 values. Consider specifying shapes manually if you need\n  that many have them.\n\n\nWarning: Removed 176 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nExample 2: Reminders of position, facet_grid, and factor reordering\nLet’s make a stacked column graph of lizard species by site:\n\nggplot(data = lizards, aes(y = fct_infreq(common_name))) +\n  geom_bar(aes(fill = site)) +\n  theme_bw() +\n  labs(x = \"Lizard counts\",\n       y = \"Species (common name)\") +\n  facet_grid(sex ~ tail)\n\n\n\n\n\n\n\n# That annoying space below zero? Let's keep that in mind..."
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-8.html#advanced-ggplot2-customization",
    "href": "course-materials/interactive-sessions/interactive-session-8.html#advanced-ggplot2-customization",
    "title": "Interactive Session 8",
    "section": "4. Advanced ggplot2 customization",
    "text": "4. Advanced ggplot2 customization\n\nAn unsung hero: scales\nThe scales package in R is truly an unsung hero of finalizing ggplot graphs. To hear more, I strongly recommend watching Dana Seidel’s 20 minute talk on The little package that could: Taking visualizations to the next level with the scales package from rstudio::conf(2020).\nWhy does that matter to us? Because a whole lot of the subtle things that make a graph way better are updating using the scales suite of helpful functions.\nFor a complete list of scales functions & usage, see: https://scales.r-lib.org/index.html\n\n\nThoughtful breaks, limits & labels\nLittle things make a big difference in data visualization. Just like we should take great care to make axis labels useful and complete, we also need to think about how values are communicated for our different variables.\nIn 2-D data visualization, that means customizing your breaks, limits, & tick mark labels & formatting. From Hadley Wickham & Dana Seidel: “The most common use of the scales package is to control the appearance of axis and legend labels. Use a break_ function to control how breaks are generated from the limits, and a label_ function to control how breaks are turned in to labels.”\nLet’s explore some different ways to update breaks and labels.\n\nUpdating breaks & labels\nThe important thing: know what type of variable you have on each axis so that you know what scale_ version to call. For example:\n\nFor dates: scale_*_date()\nFor continuous variables: scale_*_continuous()\nFor discrete variables: scale_*_discrete()\n\nWithin those layers added to your plot, you can update the breaks =, limits =, labels = and expand =options.\n\nggplot(data = lizards, aes(x = total_length, y = weight)) +\n  geom_point()\n\n\n\n\n\n\n\nggplot(data = lizards, aes(x = total_length, y = weight)) +\n  geom_point() +\n  scale_x_continuous(breaks = c(0, 250, 500), \n                     limits = c(0, 500)) +\n  scale_y_continuous(breaks = seq(from = 0, to = 70, by = 10), \n                     limits = c(0, 70)) +\n  theme_light()\n\n\n\n\n\n\n\n\nBut you can also do so much more! For example, you can convert to a log scale:\n\nggplot(data = lizards, aes(x = total_length, y = weight)) +\n  geom_point() +\n  scale_x_log10()\n\n\n\n\n\n\n\n\nAnd it is really nice for formatting axis dates. Let’s make a version of the data with lizard counts by date to try a few things:\n\nlizard_counts &lt;- lizards %&gt;% \n  mutate(date = lubridate::mdy(date)) %&gt;% \n  count(date)\n\nggplot(data = lizard_counts, aes(x = date, y = n)) +\n  geom_line() +\n  scale_x_date(breaks = scales::breaks_width(\"3 years\"), # See date_breaks for next year!\n               labels = scales::label_date(\"'%y\")) + # See date_labels for next year!\n  scale_y_log10(labels = scales::label_scientific())\n\n\n\n\n\n\n\nggplot(data = lizard_counts, aes(x = date, y = n)) +\n  geom_line() +\n  scale_x_date(breaks = scales::breaks_pretty())\n\n\n\n\n\n\n\n\nExplore the different options for label_* that appear once you start typing it in…you’ll see a bunch of different options. Make your tick marks currencies, scientific notation, or more - just by updating the labels within the correct scale_! Go ahead & try it out, it’s pretty amazing (and see the many different label options here: https://scales.r-lib.org/reference/index.html).\n\n\n\nCustomized aesthetics with scale_ functions\nWe’ve learned to use scales functions to update breaks and labels. It is also useful for updating aesthetics, for example to customize color gradients, set size bins, and more.\nAgain, it is very important to know what aesthetic you are trying to update.\nFor example, is it a fill aesthetic you’re hoping to customize? Then you might use scale_fill_*(). But if it is a color aesthetic, you’d use scale_color_*() functions. If it is the transparency, then scale_alpha_*(). If it is the shape, then scale_shape_*(). So make sure you know which aesthetic you are hoping to change with scales!\n\nggplot(data = lizards, aes(x = total_length, y = weight)) +\n  geom_point(aes(color = weight)) +\n  scale_color_gradient(low = \"red\", high = \"navy\")\n\n\n\n\n\n\n\n# Or have more than 2 colors in your gradient: \nggplot(data = lizards, aes(x = total_length, y = weight)) +\n  geom_point(aes(color = weight)) +\n  scale_color_gradientn(colors = c(\"orange\", \"red\", \"purple\", \"navy\", \"black\"))\n\n\n\n\n\n\n\n# Or use a palette from paletteer! \n# Check out options: https://emilhvitfeldt.github.io/paletteer/\n\n# ggplot(data = lizards, aes(x = total_length, y = weight)) +\n#   geom_point(aes(color = weight)) +\n#   scale_color_paletteer_c(\"scico::oslo\")\n\n# See more continuous palettes with View(palettes_c_names)\n\nThere are also great options for binning colors for a continuous variable, including with the scale_*_steps() functions (see more: https://ggplot2.tidyverse.org/reference/scale_steps.html). For example, maybe in the graph above we want binned (instead of continuous gradient) color values:\n\nggplot(data = lizards, aes(x = total_length, y = weight)) +\n  geom_point(aes(color = weight)) +\n  scale_color_steps(low = \"red\", high = \"black\")\n\n\n\n\n\n\n\n# Notice the binned legend - within bins all points are the same value. \n# Use n.breaks =  or breaks = c() to manually set the break number or value.\n\nYou can create a divergent binned scheme with scale_*_steps2():\n\nggplot(data = lizards, aes(x = total_length, y = weight)) +\n  geom_point(aes(color = total_length)) +\n  scale_color_steps2(low = \"green\",\n                     mid = \"black\",\n                     high = \"red\",\n                     midpoint = 150,\n                     breaks = c(50, 75, 150, 180, 220, 280))\n\n\n\n\n\n\n\n\nOr, to make your own bins, try scale_*_stepsn():\n\nggplot(data = lizards, aes(x = total_length, y = weight)) +\n  geom_point(aes(color = weight)) +\n  scale_color_stepsn(colors = c(\"orange\",\"red\",\"purple\"),\n                     breaks = seq(from = 10, to = 60, by = 10))\n\n\n\n\n\n\n\n\nWhat if we have a discrete variable? Let’s make a boxplot of lizard lengths by species, then customize the fill color with a palette in paletteer:\n\nggplot(data = lizards, aes(x = common_name, y = total_length)) +\n  geom_boxplot(aes(fill = common_name), color = \"black\", show.legend = FALSE) +\n  theme_minimal() +\n  coord_flip()\n\n\n\n\n\n\n\n# But **order matters**, so let's make an ordered version: \n\nlizards_mean &lt;- lizards %&gt;% \n  mutate(common_name = fct_reorder(common_name, total_length, .fun = median))\n\n# Then make a graph (use View(palettes_d_names) to see other discrete palettes in {paletteer})\n\nggplot(data = lizards_mean, aes(y = common_name, x = total_length)) +\n  geom_boxplot(aes(fill = common_name), show.legend = FALSE) +\n  scale_x_continuous(limits = c(0, 500)) +\n  scale_fill_paletteer_d(palette = \"ggsci::default_gsea\") +\n  labs(y = \"Lizard species\",\n       x = \"Total length (mm)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nCool let’s try another one: Find counts of lizard by species, reorder factor levels by count, update aesthetic by color (removing redundant legend), customize color using something from paletteer:\n\nlizard_n &lt;- lizards %&gt;% \n  count(common_name) %&gt;% \n  mutate(common_name = fct_reorder(common_name, n))\n\nggplot(data = lizard_n, aes(y = common_name, x = n)) +\n  geom_col(aes(fill = common_name), show.legend = FALSE) +\n  scale_fill_paletteer_d(\"tidyquant::tq_dark\") +\n  scale_x_continuous(expand = c(0,0), limits = c(0, 1200)) +\n  theme_bw() +\n  labs(x = \"Common name\", \n       y = \"Total count\") +\n  theme(axis.title.y = element_text(angle = 0, vjust = 0.5))\n\n\n\n\n\n\n\n\n\n\nIn the weeds of themes (gridlines, panel colors)\nAsk yourself: do you need those gridlines? Only if your audience needs to know whether values are above or below meaningful values - which can be useful, but oftentimes gridlines are really overused and make an entire plot feel more cluttered.\nWe can update gridline frequency by changing breaks, but we may want to customize them in other ways, too.\n\np &lt;- ggplot(data = lizards, aes(x = total_length, y = weight)) +\n  geom_point()\n\np + \n  theme(panel.grid = element_blank()) # removes all gridlines (major & minor)\n\n\n\n\n\n\n\np + \n  theme(panel.grid.minor = element_blank(),\n        panel.grid.major = element_line(color = \"red\"))\n\n\n\n\n\n\n\n# Now let's just go bananas with some theme stuff: \n\np + \n  theme(panel.background = element_rect(color = \"purple\", size = 3, fill = \"yellow\"),\n        panel.grid.major.y = element_line(color = \"orange\"),\n        panel.grid.major.x = element_blank(),\n        axis.text.x = element_text(color = \"blue\"),\n        axis.text.y = element_text(color = \"cyan\"),\n        axis.title.x = element_text(color = \"green\"),\n        axis.title.y = element_text(color = \"gray70\"),\n        text = element_text(size = 12, family=\"serif\"),\n        plot.background = element_rect(fill = \"pink\"))\n\nWarning: The `size` argument of `element_rect()` is deprecated as of ggplot2 3.4.0.\nℹ Please use the `linewidth` argument instead.\n\n\n\n\n\n\n\n\n# Watch Kara Woo's talk from RStudio Conference 2021!\n\n\n\nDirect annotation and thresholds\nLegends are hard for audiences. Aligning values with important thresholds described in a figure captions is hard for audiences. It’s not always possible, but depending on your presentation and the audience, consider adding direct annotation and thresholds to plots.\nWe’ll do that with a few little tools:\n\nannotate(): add annotation manually by location\ngeom_hline(): add a horizontal line\ngeom_vline(): add a vertical line\n\n\np +\n  annotate(\"text\", x = 100, y = 50, label = \"COOL!\", color = \"purple\") +\n  annotate(\"text\", x = 400, y = 25, label = \"WHOA.\", color = \"red\") +\n  geom_hline(yintercept = 40, linetype = \"dotted\", color = \"blue\") +\n  geom_vline(xintercept = 20, linetype = \"dashed\", color = \"green\") +\n  theme_minimal()\n\n\n\n\n\n\n\n# Or, have the value be determined based on a variable: \np +\n  geom_hline(yintercept = mean(lizards$weight), linetype = \"dashed\", color = \"red\") +\n  annotate(\"text\", x = 350, y = mean(lizards$weight) + 2, label = \"Mean weight\", color = \"red\")\n\n\n\n\n\n\n\n\n\n\nApply what we’ve learned to something new!\nThis data is from the Mono Basin Clearinghouse, and contains lake level (feet above sea level) for Mono Lake - a terminal saline lake in eastern California.\nHere are some important things to know when considering how to make our data viz:\n\nLA Department of Water & Power took water unrestricted from streams feeding into Mono Lake starting in 1941\nUnrestricted water diversions continued until the landmark 1983 California Supreme Court decision, led by the Mono Lake Committee, that “The public trust … is an affirmation of the duty of the state to protect the people’s common heritage of streams, lakes, marshlands and tidelands…”\nFrom The Mono Basin Ecosystem: Effects of Changing Lake Level, published in 1987 by the Mono Basin Ecosystem Study Committee, Board on Environmental Studies and Toxicology: “If the lake fell to levels at which the birds’ food sources were adversely affected, the bird populations would be reduced. The decrease in availability of brine shrimp for food would begin to affect those birds relying on them – eared grebes and California gulls – at a salinity of 120 g/L (lake level of 6360 ft).”\n\nRead in the data\n\nmono &lt;- read_csv(here(\"data_tidy\", \"mono.csv\"))\n\n\n\nRows: 168 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (2): year, lake_level\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nggplot(data = mono, aes(x = year, y = lake_level)) +\n  geom_rect(aes(xmin = 1941, \n                xmax = 1983, \n                ymin = 6350, \n                ymax = 6440), \n            fill = \"gray90\") +\n  geom_line() +\n  labs(x = \"\\nYear\",\n       y = \"Lake surface level\\n(feet above sea level)\\n\",\n       title = \"Mono Lake levels (1850 - 2017)\\n\",\n       caption = \"Data: Mono Basin Clearinghouse\") +\n  scale_x_continuous(limits = c(1850, 2020), \n                     expand = c(0,0),\n                     breaks = seq(1850, 2010, by = 20)) +\n  scale_y_continuous(limits = c(6350, 6440), \n                     breaks = c(6370, 6400, 6430),\n                     expand = c(0,0), \n                     labels = scales::label_comma()) +\n  annotate(\"text\", x = 1962, y = 6425, \n           label = \"unrestricted diversions\\n(1941 - 1983)\",\n           size = 3) +\n  theme_light() +\n  theme(plot.title.position = \"plot\",\n        axis.text.y = element_text(face = \"italic\")) +\n  geom_hline(yintercept = 6360, linetype = \"dashed\") +\n  annotate(\"text\", \n           x = 1910, \n           y = 6367, \n           label = \"Decreased shrimp abundance expected\\n(6,360 feet above sea level)\",\n           size = 3)\n\n\n\n\n\n\n\n\n\n\nAside: better legends\n\ntwo_lizards &lt;- lizards %&gt;% \n  filter(common_name %in% c(\"eastern fence\", \"western whiptail\"))\n\nggplot(data = two_lizards, aes(x = total_length, y = weight)) +\n  geom_point(aes(color = common_name,\n                 shape = common_name),\n             size = 2) +\n  scale_color_manual(name = \"Lizard species:\",\n                       values = c(\"orange\", \"navy\"),\n                     labels = c(\"Eastern fence lizard\", \"Western whiptail\")) +\n  scale_shape_discrete(name = \"Lizard species:\",\n                       labels = c(\"Eastern fence lizard\", \"Western whiptail\")) +\n  theme_minimal() +\n  theme(legend.position = c(0.2, 0.8),\n        legend.background = element_blank()) # And check out other legend.* options...it's a lot.\n\nWarning: A numeric `legend.position` argument in `theme()` was deprecated in ggplot2\n3.5.0.\nℹ Please use the `legend.position.inside` argument of `theme()` instead.\n\n\n\n\n\n\n\n\n\n\n\nRepulsive labels (e.g. ggrepel)\nDirect labeling with a bunch of groups is challenging - ggrepel is here to help! It makes automatic repulsive labels. Let’s make a subset of Western Whiptails at the “sand” site, then add repulsive labels by toe number.\n\nwwc_lizards &lt;- lizards %&gt;% \n  filter(common_name ==\"western whiptail\", site == \"sand\")\n\nggplot(data = wwc_lizards, aes(x = total_length, y = weight)) +\n  geom_point() +\n  geom_text_repel(aes(label = toe_num), size = 3, max.overlaps = 20, show.legend = FALSE) \n\n\n\n\n\n\n\n\nLet’s try it with a different dataset, gapminder (“Excerpt of the Gapminder data on life expectancy, GDP per capita, and population by country.”)\n\ngapminder %&gt;% \n  filter(year == 2002, continent == \"Europe\") %&gt;% \n  ggplot(aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() + \n  geom_text_repel(aes(label = country), size = 3)\n\n\n\n\n\n\n\n\n\n\nHighlighting for clarity (e.g. with gghighlight)\nThis can be particularly useful if you have made a bunch of observations or series, and you want to highlight some to make your audience’s life easier.\nAdd gghighlight() to your ggplot to specify highlighting conditions.\n\np +\n  gghighlight(toe_num == 250, label_key = toe_num)\n\n\n\n\n\n\n\np + \n  aes(color = site) + # Best to include this in geom_ line instead of here...\n  gghighlight(site %in% c(\"cali\", \"grav\"))\n\nWarning: Tried to calculate with group_by(), but the calculation failed.\nFalling back to ungrouped filter operation...\n\n\nlabel_key: site\n\n\nToo many data points, skip labeling\n\n\n\n\n\n\n\n\n# One more example: \nq &lt;- ggplot(data = lizards, aes(x = total_length, y = weight, group = common_name)) +\n  geom_line(aes(color = common_name)) +\n  gghighlight(max(weight, na.rm = TRUE) &gt; 30)\n\nlabel_key: common_name\n\nq"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-8.html#compound-figures-with-patchwork",
    "href": "course-materials/interactive-sessions/interactive-session-8.html#compound-figures-with-patchwork",
    "title": "Interactive Session 8",
    "section": "4. Compound figures with patchwork",
    "text": "4. Compound figures with patchwork\nPatchwork makes it easier to put multiple figures together into a single graphic – and to do some efficient theming while you’re at it.\nLet’s store a couple of different graphs (we already have p and q stored):\n\n(p | q) & # & means it's applied to both plots! \n  theme_minimal()\n\n\n\n\n\n\n\nz &lt;- ggplot(data = lizards, aes(y = site, x = weight)) +\n  geom_boxplot(aes(fill = site), show.legend = FALSE)\n\n# Put them all together using PEMDAS structure\n((p | q) / z) & theme_dark()"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-8.html#explore-some-new-graph-types",
    "href": "course-materials/interactive-sessions/interactive-session-8.html#explore-some-new-graph-types",
    "title": "Interactive Session 8",
    "section": "5. Explore some new graph types",
    "text": "5. Explore some new graph types\n\nMarginal plots\n\nwhiptails &lt;- lizards %&gt;% \n  filter(common_name == \"western whiptail\") %&gt;% \n  drop_na(total_length, weight)\n\n# An issue with rug plots: \nggplot(data = whiptails, aes(x = total_length, y = weight)) +\n  geom_point() +\n  geom_rug()\n\n\n\n\n\n\n\n\n\np &lt;- ggplot(data = whiptails, aes(x = total_length, y = weight)) +\n  geom_point(aes(color = sex), size = 2) +\n  theme_minimal() +\n  scale_color_manual(values = c(\"cyan4\", \"black\", \"goldenrod\"),\n                     name = \"Sex:\", \n                     labels = c(\"female\", \"juvenile\", \"male\")\n  ) +\n  theme(legend.position = \"bottom\") + \n  labs(x = \"Total length (mm)\", \n       y = \"Weight (grams)\")\n\n# Example 1: A histogram\n# ggMarginal(p, type = \"histogram\", fill = \"gray60\", color = NA)\n\n# Example 2: A boxplot, grouped by sex (as in the plot)\nggMarginal(p, type = \"boxplot\", groupColour = TRUE)\n\n\n\n\n\n\n\n\n\n\nA beeswarm plot with ggbeeswarm\n\nggplot(data = whiptails, aes(x = sex, y = weight)) +\n  geom_beeswarm(size = 1) +\n  geom_boxplot(fill = NA) +\n  scale_x_discrete(labels = c(\"female\",\"juvenile\",\"male\")) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nA heatmap with geom_tile()\nHeatmaps are a great way to see trends across groups. Here, we’ll create one to visualize lizard counts by species and site.\n\n# Get the counts: \nlizard_counts &lt;- lizards %&gt;% \n  mutate(date = lubridate::mdy(date)) %&gt;% \n  count(year = lubridate::year(date), common_name) %&gt;% \n  drop_na()\n\n# Make a heatmap of counts:\nggplot(data = lizard_counts, aes(x = year, y = common_name)) +\n  geom_tile(aes(fill = n), show.legend = FALSE) +\n  geom_text(aes(label = n), color = \"white\", size = 3) +\n  scale_fill_gradientn(colors = c(\"navy\",\"red\",\"orange\")) +\n  theme_minimal() +\n  labs(x = \"Year\", y = \"Lizard common name\")\n\n\n\n\n\n\n\n\n\n\nMake a map!\nLet’s make a map using some of the skills we’ve learned to customize our ggplots:\n\n# First, read in the Jornada Basin vegetation data: \njornada_veg &lt;- read_sf(here(\"data_raw\",\"spatial_vegetation\",\"doc.kml\")) %&gt;% dplyr::select(Name) %&gt;% \n  clean_names()\n\n\n# Initial exploratory plot (one plot per attribute)\n# plot(jornada_veg)\n\n# Remember, you can see the paletteer palettes with: \n# View(palettes_c_names)\n# View(palettes_d_names)\n\nggplot() +\n  geom_sf(data = jornada_veg, \n          aes(fill = name),\n          color = NA) +\n  theme_minimal() +\n  scale_fill_paletteer_d(palette = \"ggthemes::manyeys\") +\n  labs(x = \"Longitude\",\n       y = \"Latitude\",\n       fill = \"Dominant vegetation:\",\n       title = \"Jornada Basin vegetation\",\n       caption = \"Data source: Jornada Basin LTER\") +\n  theme(legend.position = \"right\",\n        plot.title.position = \"plot\",\n        plot.caption.position = \"plot\",\n        plot.caption = element_text(face = \"italic\", color = \"gray30\"),\n        axis.text = element_text(size = 5))\n\n\n\n\n\n\n\n\n\nEnd Interactive Session 8"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-10.html",
    "href": "course-materials/interactive-sessions/interactive-session-10.html",
    "title": "Interactive Sessions 10",
    "section": "",
    "text": "Create new repo on GitHub named eds221-day10-comp\nClone to make a local version-controlled R Project"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-10.html#setup",
    "href": "course-materials/interactive-sessions/interactive-session-10.html#setup",
    "title": "Interactive Sessions 10",
    "section": "",
    "text": "Create new repo on GitHub named eds221-day10-comp\nClone to make a local version-controlled R Project"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-10.html#make-a-ggplot-theme",
    "href": "course-materials/interactive-sessions/interactive-session-10.html#make-a-ggplot-theme",
    "title": "Interactive Sessions 10",
    "section": "2. Make a ggplot theme",
    "text": "2. Make a ggplot theme\n\nAdd a new Quarto document, saved in your project root as my_ggplot_theme.qmd\nAttach the tidyverse and palmerpenguins packages\nCreate a plot from the data (whatever type you want)\nHighly customize the theme() component (you can make it as bright / awful as you want - this is going to become a ggplot theme you can share with the world, so it’s up to you)\nKeep this project OPEN (you’ll copy your custom theme in the next step…)\n\nHere’s something awful just to remind you of what this can look like:\n\nggplot(data = penguins, aes(x = flipper_length_mm, y = body_mass_g)) +\n  geom_point() +\n  theme(title = element_text(size = 16, color = \"purple\"),\n        plot.background = element_rect(fill = \"black\"),\n        panel.background = element_rect(fill = \"gray20\"),\n        axis.text = element_text(color = \"yellow\"),\n        panel.grid.major = element_line(color = \"blue\"),\n        panel.grid.minor = element_line(color = \"cyan\")\n        )"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-10.html#updating-our-r-package",
    "href": "course-materials/interactive-sessions/interactive-session-10.html#updating-our-r-package",
    "title": "Interactive Sessions 10",
    "section": "3. Updating our R package",
    "text": "3. Updating our R package\n\nIn a new session (so your existing project stays open), reopen the R Project for your R package you created last week\nInstall and Restart your package (this should also attach your package)\nRemind yourself of what functions exist in the package (one way: in the Packages tab, click on your package name to see a list)\nCreate a new R script (.R )\nCopy and paste just the theme() component of your customized ggplot graph that you just made into your empty R script. For the example above, that would just be:\n\n\ntheme(title = element_text(size = 16, color = \"purple\"),\n        plot.background = element_rect(fill = \"black\"),\n        panel.background = element_rect(fill = \"gray20\"),\n        axis.text = element_text(color = \"yellow\"),\n        panel.grid.major = element_line(color = \"blue\"),\n        panel.grid.minor = element_line(color = \"cyan\")\n        )\n\n\nPut that theme inside of a function, and assign it a name. For example:\n\n\ntheme_eighties &lt;- function() {theme(title = element_text(size = 16, color = \"purple\"),\n      plot.background = element_rect(fill = \"black\"),\n      panel.background = element_rect(fill = \"gray20\"),\n      axis.text = element_text(color = \"yellow\"),\n      panel.grid.major = element_line(color = \"blue\"),\n      panel.grid.minor = element_line(color = \"cyan\")\n)\n}\n\n\nSave your script using the same name as the function in the R folder (e.g. this one would be theme_eighties.R)\nAdd a Roxygen skeleton (recall: click within your function &gt; Code &gt; Insert Roxygen skeleton), and update the title (note that there aren’t any arguments / params)\ndevtools::document() to produce the R documentation for your new function\nInstall & restart\nTry it out! Back in your other project, attach your package (which you just reinstalled), then make a plot that uses your custom theme from your package!\n\nFor example, if mine is called tacopika:\n\nlibrary(tacopika)\n\nggplot(data = penguins, aes(x = flipper_length_mm, y = body_mass_g)) +\n  geom_point() +\n  theme_eighties()\n\n\nStage, commit, & push changes back to your GitHub repo\nShare your repo information (username/reponame) with your neighbor so they can install your package from GitHub! Recall: devtools::install_github(\"username/reponame\")\nTest your neighbors new & improved R package and try out their custom theme!"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-10.html#making-some-nice-tables-in-r",
    "href": "course-materials/interactive-sessions/interactive-session-10.html#making-some-nice-tables-in-r",
    "title": "Interactive Sessions 10",
    "section": "3. Making some nice tables in R",
    "text": "3. Making some nice tables in R\nWe’ve made a number of ggplot graphs, but we haven’t made any tables. Let’s learn one way!\n\nBack in your eds221-day10-comp R Project, create a new Quarto document\nIn the setup chunk, attach the tidyverse & kableExtra (note: there are a bunch of ways to make nice tables in R - see David Keyes’ post on How to make beautiful tables in R for more options)\nCopy the contents of the table below to the clipboard, the use the datapasta Add-in to create a tibble stored as whale_sightings\n\n\n\n\n\n\ndate\nsite\nspp\ndist_m\nbehavior\n\n\n\n\n8/12/2014\nchannel\nunknown\n400\nbreach\n\n\n8/13/2014\nchannel\ngray\n200\nspout\n\n\n8/15/2014\nharbor\ngray\n60\nspout\n\n\n8/16/2014\nchannel\nhumpback\n300\nfeeding\n\n\n8/16/2014\nchannel\ngray\n150\nfeeding\n\n\n\n\n\n\n\n\nLet’s make some nice looking tables\nWith kableExtra:\n\n# Bootstrap theme\ndt %&gt;% \n  kable(col.names = c(\"Date\", \"Site\", \"Species\", \"Distance (m)\", \"Behavior\")) %&gt;% \n  kable_styling(full_width = FALSE, bootstrap_options = \"striped\")\n\n\n\n\nDate\nSite\nSpecies\nDistance (m)\nBehavior\n\n\n\n\n8/12/2014\nchannel\nunknown\n400\nbreach\n\n\n8/13/2014\nchannel\ngray\n200\nspout\n\n\n8/15/2014\nharbor\ngray\n60\nspout\n\n\n8/16/2014\nchannel\nhumpback\n300\nfeeding\n\n\n8/16/2014\nchannel\ngray\n150\nfeeding\n\n\n\n\n\n\n# Paper theme\ndt %&gt;% \n  kable() %&gt;% \n  kable_classic()\n\n\n\n\ndate\nsite\nspp\ndist_m\nbehavior\n\n\n\n\n8/12/2014\nchannel\nunknown\n400\nbreach\n\n\n8/13/2014\nchannel\ngray\n200\nspout\n\n\n8/15/2014\nharbor\ngray\n60\nspout\n\n\n8/16/2014\nchannel\nhumpback\n300\nfeeding\n\n\n8/16/2014\nchannel\ngray\n150\nfeeding\n\n\n\n\n\n\n\nCheck out some other themes and try them out! https://cran.r-project.org/web/packages/kableExtra/vignettes/awesome_table_in_html.html\nA bit more customization:\n\ndt %&gt;% \n  kable(col.names = c(\"Date\", \"Site\", \"Species\", \"Distance (m)\", \"Behavior\")) %&gt;% \n  kable_classic() %&gt;% \n  column_spec(1, bold = TRUE, background = \"yellow\") %&gt;% \n  column_spec(2, italic = TRUE, background = \"orange\") %&gt;% \n  add_header_above(c(\" \" = 1, \"One header\" = 2, \"Another header\" = 2)) %&gt;% \n  scroll_box(height = \"100px\", width = \"500px\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOne header\n\n\nAnother header\n\n\n\nDate\nSite\nSpecies\nDistance (m)\nBehavior\n\n\n\n\n8/12/2014\nchannel\nunknown\n400\nbreach\n\n\n8/13/2014\nchannel\ngray\n200\nspout\n\n\n8/15/2014\nharbor\ngray\n60\nspout\n\n\n8/16/2014\nchannel\nhumpback\n300\nfeeding\n\n\n8/16/2014\nchannel\ngray\n150\nfeeding\n\n\n\n\n\n\n\nSee also: DT, reactable, gt, and more!"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-10.html#git-collaboration-both-pushing-to-main",
    "href": "course-materials/interactive-sessions/interactive-session-10.html#git-collaboration-both-pushing-to-main",
    "title": "Interactive Sessions 10",
    "section": "4. Git collaboration: both pushing to main",
    "text": "4. Git collaboration: both pushing to main\n\nFind a partner. Designate who is “Starter” and who is “Collaborator”.\n\n\nStarter: Create a new version controlled R Project, make & push an update\n\nCreate a new repo called eds221-day10-collab (with a ReadMe)\nClone, create a new version-controlled R Project\nCreate a new .Rmd in the root (git_test.Rmd), delete everything below the first code chunk\nAdd a line of text in your .Rmd like “Hi partner!”\nStage, commit & push all changes back to your GitHub repo\n\n\n\nStarter: Add a contributor\n\nGo back to your eds221-day10-collab repo on GitHub\nGo to Settings &gt; Manage access &gt; (Enter password if requested) &gt; Invite collaborator &gt; Enter Collaborator’s username or email\n\n\n\nCollaborator: Accept invitation & clone repo, make an update\n\nCheck your email. You should receive the invitation to join the repo. Accept.\nClone (do NOT fork first) and create your own local R project\nPull just in case (this should say already up to date)\nOpen the git_test.Rmd\nAdd a new line to the .Rmd with a nice note below the line your partner added\nSave the .Rmd, then stage, commit, pull & push\nCheck that the updates show up on GitHub\n\n\n\nStarter: Pull & add something new to the .Rmd\n\nPULL to get remote updates locally in RStudio\nOpen git_test.Rmd and see updated text from your partner\nAdd a new line of text to the .Rmd\nStage, commit, pull, then push\n\n\n\nCollaborator: Pull & add something new to the .Rmd\n\nPULL to get remote updates\nOpen git_test.Rmd and see updated text\nAdd a new line of text to the .Rmd\nStage, commit, pull, then push\n\n\n\nWhere goes what now on GitHub?\n\nBoth partners, go back to the repo on github for your collaboration\nGo exploring (especially History & Blame)\n\n\n\nSubmit a new issue that references specific line(s) in your files\n\nStill in GitHub, click on the git_test.Rmd file\nFind a line that your partner wrote\nClick the row number to the left of the line (or hold shift to select a range a lines) - the selected lines will turn yellow, and you should see a three dot menu button appear to the left of the code. Click on it, and choose “Reference in new issue”\nAdd a title and some text for your issue, and submit\nOnce you both have submitted an issue to your shared repo, check your partner’s issue, respond and close (resolve) the issue\n\n\nEnd Interactive Session 10"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-6.html",
    "href": "course-materials/interactive-sessions/interactive-session-6.html",
    "title": "Interactive Session 6",
    "section": "",
    "text": "Fork and clone this repo containing the Day 6 materials\nOpen the project in RStudio\n\nFamiliarize yourself with the package structure\nCreate a new .Rmd, save as ‘day6-wrangling-tidyverse.Rmd’\nIn the setup chunk, attach the tidyverse, here, and janitor packages\n\n\n\n\n\n\n\nknitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)\n\nlibrary(tidyverse)\nlibrary(here)\nlibrary(janitor)\n\n\n\n\n\n\nuse_python(\"/opt/anaconda3/bin/python\")\n\n\n# Don't forget pandas\n# Note: if ModuleNotFoundError: No module named 'pandas', install pandas! \n# Install in Terminal: pip install pandas\nimport pandas as pd\n\n\n\n\nData for these examples are from:\n\nThe World Bank World Development Indicators"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-6.html#setup",
    "href": "course-materials/interactive-sessions/interactive-session-6.html#setup",
    "title": "Interactive Session 6",
    "section": "",
    "text": "Fork and clone this repo containing the Day 6 materials\nOpen the project in RStudio\n\nFamiliarize yourself with the package structure\nCreate a new .Rmd, save as ‘day6-wrangling-tidyverse.Rmd’\nIn the setup chunk, attach the tidyverse, here, and janitor packages\n\n\n\n\n\n\n\nknitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)\n\nlibrary(tidyverse)\nlibrary(here)\nlibrary(janitor)\n\n\n\n\n\n\nuse_python(\"/opt/anaconda3/bin/python\")\n\n\n# Don't forget pandas\n# Note: if ModuleNotFoundError: No module named 'pandas', install pandas! \n# Install in Terminal: pip install pandas\nimport pandas as pd\n\n\n\n\nData for these examples are from:\n\nThe World Bank World Development Indicators"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-6.html#part-1.-read-in-the-two-data-files",
    "href": "course-materials/interactive-sessions/interactive-session-6.html#part-1.-read-in-the-two-data-files",
    "title": "Interactive Session 6",
    "section": "Part 1. Read in the two data files",
    "text": "Part 1. Read in the two data files\nThe data files we’ll use today are in the data subfolder of the project. They are:\n\nwb_indicators.csv: a CSV containing data for select development indicators for countries in the World Bank database, from 2001 - 2020\nwb_indicators_metadata.csv: a CSV containing metadata information for the development indicators\n\n\nIn R:\n\nwb_indicators &lt;- read_csv(here(\"data\", \"wb_indicators.csv\"), na = c(\"..\", \"\"))\nwb_metadata &lt;- read_csv(here(\"data\", \"wb_indicators_metadata.csv\"))\n\n\n\nIn Python:\n\nwb_indicators = pd.read_csv('data/wb_indicators.csv', na_values = c(\"..\", \"\"))\nwb_metadata = pd.read_csv('data/wb_indicators_metadata.csv')\n\n\n\nTake a look\nALWAYS ALWAYS ALWAYS look at what you’ve done."
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-6.html#reshaping-and-tidying-basics",
    "href": "course-materials/interactive-sessions/interactive-session-6.html#reshaping-and-tidying-basics",
    "title": "Interactive Session 6",
    "section": "2. Reshaping and tidying basics",
    "text": "2. Reshaping and tidying basics\n\nWide-to-long\nWe see that years - a single variable - is spread out over multiple columns. We’ll want to reshape this data frame from wide-to-long format so that year is only in a single column to make it Tidy.\n\nIn R: tidyr::pivot_longer()\n\nwb_indicators_long &lt;- wb_indicators %&gt;% \n  pivot_longer(cols = '2001 [YR2001]':'2020 [YR2020]', # Which columns to squish\n               names_to = \"year\", # The original column names are squished into this column\n               values_to = \"indicator_value\") # The values are correctly aligned in this column\n\n# Check it out (always):\n# View(wb_indicators_long) # Why do I comment this out or run it in the Console? \n\n\n\nIn Python (pandas): melt()\n\nwb_indicators_long = wb_indicators.melt(id_vars = ['Country Name', 'Country Code', 'Series Name', 'Series Code'],\n                                       var_name = 'year',\n                                       value_name = 'indicator_value')\n\n# Check it out: \nwb_indicators_long.head\n\n&lt;bound method NDFrame.head of                                            Country Name  ... indicator_value\n0                                           Afghanistan  ...            9.51\n1                                           Afghanistan  ...             NaN\n2                                           Afghanistan  ...          810.00\n3                                           Afghanistan  ...             NaN\n4                                           Afghanistan  ...             NaN\n...                                                 ...  ...             ...\n26695                                               NaN  ...             NaN\n26696                                               NaN  ...             NaN\n26697                                               NaN  ...             NaN\n26698  Data from database: World Development Indicators  ...             NaN\n26699                          Last Updated: 07/21/2021  ...             NaN\n\n[26700 rows x 6 columns]&gt;\n\n# Check the dimensions: \nwb_indicators_long.shape\n\n(26700, 6)\n\n\n\n\n\nCleaning that year column up…\nWe can see that the year is stored in a weird format (e.g. 2018 [YR2018]) that’s going to make our life difficult if we want to, for example, use year as a number to plot changes in the indicator values over time.\nLet’s separate the information in the year column so that we can just keep the nice 4-digit year as a number.\n\nIn R: tidyr::separate()\n\nwb_data_clean &lt;- wb_indicators_long %&gt;% \n  tidyr::separate(col = year, into = c(\"year\", \"year_chr\"), sep = \" \") %&gt;% \n  dplyr::select(-year_chr, -'Country Code', -'Series Code') # This drops a few redundant columns (caution here...best to leave things if you're not sure)\n\nhead(wb_data_clean)\n\n# A tibble: 6 × 4\n  `Country Name` `Series Name`                             year  indicator_value\n  &lt;chr&gt;          &lt;chr&gt;                                     &lt;chr&gt;           &lt;dbl&gt;\n1 Afghanistan    Access to clean fuels and technologies f… 2001             9.51\n2 Afghanistan    Access to clean fuels and technologies f… 2002            10.4 \n3 Afghanistan    Access to clean fuels and technologies f… 2003            11.5 \n4 Afghanistan    Access to clean fuels and technologies f… 2004            12.4 \n5 Afghanistan    Access to clean fuels and technologies f… 2005            13.5 \n6 Afghanistan    Access to clean fuels and technologies f… 2006            14.8 \n\n\n\n\nIn pandas: str.split()\n\nwb_indicators_long[['year','year_chr']] = wb_indicators_long.year.str.split(expand=True)\n\nlist(wb_indicators_long) # Cool, now there's year and year_chr\n\n['Country Name', 'Country Code', 'Series Name', 'Series Code', 'year', 'indicator_value', 'year_chr']\n\n# Let's also drop some variables we won't use:\nwb_data_clean = wb_indicators_long.drop(['Country Code', 'Series Code', 'year_chr'], axis = 1)\n\nlist(wb_data_clean)\n\n['Country Name', 'Series Name', 'year', 'indicator_value']\n\n\n\n\n\nConvert indicators to variables (long to wide)\nOur data still aren’t quite tidy! Why?\nNotice that we have multiple variables that were measured (our different indicators) all in a single column. This is a scenario where there are multiple variables in a single column. To be Tidy, we want each variable to live in just one column.\n\nIn R: tidyr::pivot_wider()\nThat means we’re going to need to widen this data. We’ll do that using tidyr::pivot_wider().\n\nwb_data_tidy &lt;- wb_data_clean %&gt;% \n  tidyr::drop_na('Series Name') %&gt;% \n  tidyr::pivot_wider(names_from = 'Series Name', values_from = indicator_value) # Pivot to wide format\n\nhead(wb_data_tidy)\n\n# A tibble: 6 × 7\n  `Country Name` year  Access to clean fuels and techno…¹ Access to electricit…²\n  &lt;chr&gt;          &lt;chr&gt;                              &lt;dbl&gt;                  &lt;dbl&gt;\n1 Afghanistan    2001                                9.51                   NA  \n2 Afghanistan    2002                               10.4                    NA  \n3 Afghanistan    2003                               11.5                    NA  \n4 Afghanistan    2004                               12.4                    NA  \n5 Afghanistan    2005                               13.5                    22.3\n6 Afghanistan    2006                               14.8                    28.1\n# ℹ abbreviated names:\n#   ¹​`Access to clean fuels and technologies for cooking (% of population)`,\n#   ²​`Access to electricity (% of population)`\n# ℹ 3 more variables: `CO2 emissions (kt)` &lt;dbl&gt;,\n#   `Fossil fuel energy consumption (% of total)` &lt;dbl&gt;,\n#   `Level of water stress: freshwater withdrawal as a proportion of available freshwater resources` &lt;dbl&gt;\n\n\n\n\nIn Python:\n\nwb_data_tidy = wb_data_clean.pivot_table(index = ['Country Name', 'year'],\n                                        columns = 'Series Name',\n                                        values = 'indicator_value')\n                                        \n# Indexes back to normal column entries:                                         \nwb_data_tidy = wb_data_tidy.reset_index()\n\n# Check the data frame now:\nwb_data_tidy.head() # I feel better.\n\nSeries Name Country Name  ... Level of water stress: freshwater withdrawal as a proportion of available freshwater resources\n0            Afghanistan  ...                                                NaN                                            \n1            Afghanistan  ...                                          54.757019                                            \n2            Afghanistan  ...                                                NaN                                            \n3            Afghanistan  ...                                                NaN                                            \n4            Afghanistan  ...                                                NaN                                            \n\n[5 rows x 7 columns]\n\n                                        \nwb_data_tidy.head()\n\nSeries Name Country Name  ... Level of water stress: freshwater withdrawal as a proportion of available freshwater resources\n0            Afghanistan  ...                                                NaN                                            \n1            Afghanistan  ...                                          54.757019                                            \n2            Afghanistan  ...                                                NaN                                            \n3            Afghanistan  ...                                                NaN                                            \n4            Afghanistan  ...                                                NaN                                            \n\n[5 rows x 7 columns]\n\n\n\n\n\nRenaming columns\nOur column names are now a nightmare. We can reassign all names as follows (in this order):\n\nnames(wb_data_tidy) &lt;- c(\"country\", \"year\", \"access_clean_fuels_pp\", \"access_electricity_pp\", \"co2_emissions_kt\", \"fossil_fuel_cons_pt\", \"water_stress\")\n\nhead(wb_data_tidy)\n\n# A tibble: 6 × 7\n  country     year  access_clean_fuels_pp access_electricity_pp co2_emissions_kt\n  &lt;chr&gt;       &lt;chr&gt;                 &lt;dbl&gt;                 &lt;dbl&gt;            &lt;dbl&gt;\n1 Afghanistan 2001                   9.51                  NA                810\n2 Afghanistan 2002                  10.4                   NA               1100\n3 Afghanistan 2003                  11.5                   NA               1350\n4 Afghanistan 2004                  12.4                   NA               1130\n5 Afghanistan 2005                  13.5                   22.3             1640\n6 Afghanistan 2006                  14.8                   28.1             1940\n# ℹ 2 more variables: fossil_fuel_cons_pt &lt;dbl&gt;, water_stress &lt;dbl&gt;\n\n\nOr, we’ll learn how to use dplyr::rename() soon…\n\nRenaming in Python with df.rename():\n\nwb_data_tidy = wb_data_tidy.rename(columns = {'Country Name': 'country', 'Access to clean fuels and technologies for cooking (% of population)': 'access_fuels_pp',\n 'Access to electricity (% of population)': 'access_electricity_pp',\n 'CO2 emissions (kt)': 'co2_emissions_kt',\n 'Fossil fuel energy consumption (% of total)': 'fossil_fuel_consumption_pt',\n 'Level of water stress: freshwater withdrawal as a proportion of available freshwater resources': 'water_stress'})\n \nwb_data_tidy.head()\n\nSeries Name      country  year  ...  fossil_fuel_consumption_pt  water_stress\n0            Afghanistan  2001  ...                         NaN           NaN\n1            Afghanistan  2002  ...                         NaN     54.757019\n2            Afghanistan  2003  ...                         NaN           NaN\n3            Afghanistan  2004  ...                         NaN           NaN\n4            Afghanistan  2005  ...                         NaN           NaN\n\n[5 rows x 7 columns]"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-6.html#more-data-wrangling-with-dplyr",
    "href": "course-materials/interactive-sessions/interactive-session-6.html#more-data-wrangling-with-dplyr",
    "title": "Interactive Session 6",
    "section": "3. More data wrangling with dplyr",
    "text": "3. More data wrangling with dplyr\n\ndplyr::filter()\nUse dplyr::filter() to keep or exclude rows based on your conditions.\nSome examples:\nI only want to keep observations from the dataset above for “United States”:\n\nus_wb &lt;- wb_data_tidy %&gt;% \n  filter(country == \"United States\")\n\nhead(us_wb)\n\n# A tibble: 6 × 7\n  country     year  access_clean_fuels_pp access_electricity_pp co2_emissions_kt\n  &lt;chr&gt;       &lt;chr&gt;                 &lt;dbl&gt;                 &lt;dbl&gt;            &lt;dbl&gt;\n1 United Sta… 2001                    100                   100          5749250\n2 United Sta… 2002                    100                   100          5594160\n3 United Sta… 2003                    100                   100          5659630\n4 United Sta… 2004                    100                   100          5740030\n5 United Sta… 2005                    100                   100          5756080\n6 United Sta… 2006                    100                   100          5656580\n# ℹ 2 more variables: fossil_fuel_cons_pt &lt;dbl&gt;, water_stress &lt;dbl&gt;\n\n\n\n\nThis example in Python:\n\nwb_data_tidy[(wb_data_tidy['country'] == \"United States\")]\n\nI want to keep observations if the country is “United States” OR “Mexico” OR “Brazil”:\n\nus_mx_bz &lt;- wb_data_tidy %&gt;% \n  filter(country %in% c(\"United States\", \"Mexico\", \"Brazil\"))\n\nunique(us_mx_bz$country)\n\n[1] \"Brazil\"        \"Mexico\"        \"United States\"\n\n\n\n\nThis example in Python:\n\nwb_data_tidy[(wb_data_tidy['country'] == \"United States\") | (wb_data_tidy['country'] == \"Mexico\") | (wb_data_tidy['country'] == \"Brazil\")]\n\nI want to keep observations if the country is “Guatemala” OR the year is 2020:\n\nguatemala_or_2020 &lt;- wb_data_tidy %&gt;% \n  filter(country == \"Guatemala\" | year == 2020)\n\nI want to keep observations in the year is 2010 and CO2 emissions is greater than 10,000kt:\n\nco2_2010_over10k &lt;- wb_data_tidy %&gt;% \n  filter(year == 2010, co2_emissions_kt &gt; 10000)\n\n\n\ndplyr::select()\nSelect (or exclude) columns using dplyr::select(). Put a minus sign (-) in front of a column name or position to exclude it.\n\nnicaragua_co2 &lt;- wb_data_tidy %&gt;% \n  filter(country == \"Nicaragua\") %&gt;% \n  select(year, co2_emissions_kt)\n\nExclude the water_stress and access_electricity_pp columns:\n\nwb_subset &lt;- wb_data_tidy %&gt;% \n  select(-c(water_stress, access_electricity_pp))\n\n\nSome examples of selecting / excluding columns in python:\n\n# Keep columns country, year, and co2_emissions_kt\nwb_data_tidy[['country','year','co2_emissions_kt']]\n\n# Exclude column access_fuels_pp\nwb_data_tidy.drop('access_fuels_pp', axis = 1) # axis = 1 here indicates drop COLUMN (0 = rows)\n\n\n\n\ndplyr::rename()\nUse dplyr::rename() to rename one or more columns, in the order new_name = old_name.\n\nwb_newnames &lt;- wb_data_tidy %&gt;% \n  rename(elec = access_electricity_pp, co2 = co2_emissions_kt)\n\n\n\ndplyr::mutate()\nUse dplyr::mutate() to add a new column, or transform an existing one.\nExample: to change the class of a variable (careful - this overwrites the existing column!)\n\n# Check the class of year:\nclass(wb_data_tidy$year) # Character! Let's change it. \n\n[1] \"character\"\n\nwb_data_tidy &lt;- wb_data_tidy %&gt;% \n  mutate(year = as.numeric(year))\n\n# Check again: \nclass(wb_data_tidy$year)\n\n[1] \"numeric\"\n\n\nExample: Add a new column that has co2 in TONS (instead of kilotons):\n\nwb_co2_tons &lt;- wb_data_tidy %&gt;% \n  mutate(co2_tons = co2_emissions_kt * 1000)\n\nhead(wb_co2_tons)\n\n# A tibble: 6 × 8\n  country      year access_clean_fuels_pp access_electricity_pp co2_emissions_kt\n  &lt;chr&gt;       &lt;dbl&gt;                 &lt;dbl&gt;                 &lt;dbl&gt;            &lt;dbl&gt;\n1 Afghanistan  2001                  9.51                  NA                810\n2 Afghanistan  2002                 10.4                   NA               1100\n3 Afghanistan  2003                 11.5                   NA               1350\n4 Afghanistan  2004                 12.4                   NA               1130\n5 Afghanistan  2005                 13.5                   22.3             1640\n6 Afghanistan  2006                 14.8                   28.1             1940\n# ℹ 3 more variables: fossil_fuel_cons_pt &lt;dbl&gt;, water_stress &lt;dbl&gt;,\n#   co2_tons &lt;dbl&gt;\n\n\n\nThis example with df.assign() in Python:\n\nco2_tons = wb_data_tidy.assign(co2_t = wb_data_tidy['co2_emissions_kt'] * 1000)\n\n\n\n\ndplyr::group_by() %&gt;% summarize()\nTo perform one or more functions on data by group, returning a nice summary table, use group_by + summarize().\nExample: find the total reported co2 emissions (kt) for 2001 - 2020 from each country:\n\nco2_total &lt;- wb_data_tidy %&gt;% \n  group_by(country) %&gt;% \n  summarize(total_co2_kt = sum(co2_emissions_kt, na.rm = TRUE))\n\n\nThis example (group_by() summarize()) in python with df.groupby.agg:\n\nco2_sum = wb_data_tidy.groupby('country')['co2_emissions_kt'].agg(['sum'])\n\nExample: find the total co2 emissions (kt) across all country for each year from 2001 - 2020:\n\nco2_annual &lt;- wb_data_tidy %&gt;% \n  group_by(year) %&gt;% \n  summarize(annual_total_co2_kt = sum(co2_emissions_kt, na.rm = TRUE))\n\n# Let's plot this for fun: \nggplot(data = co2_annual, aes(x = year, y = annual_total_co2_kt)) +\n  geom_line()\n\n\n\n\n\n\n\n# Always look. What is happening here? Always always always look at your data."
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-6.html#putting-things-together",
    "href": "course-materials/interactive-sessions/interactive-session-6.html#putting-things-together",
    "title": "Interactive Session 6",
    "section": "4. Putting things together",
    "text": "4. Putting things together\nWe’ve learned a bunch of different useful functions for data wrangling in the {tidyverse}. But this may still feel a bit tedious.\nOften, for readability and efficiency, we may want to string together different steps into a sequence. We can do that using the pipe operator (%&gt;% in the tidyverse, or |&gt; is the sparkly new native pipe in R).\nLet’s take our raw data that we initially read in:\n\nhead(wb_indicators)\n\n# A tibble: 6 × 24\n  `Country Name` `Country Code` `Series Name`      `Series Code` `2001 [YR2001]`\n  &lt;chr&gt;          &lt;chr&gt;          &lt;chr&gt;              &lt;chr&gt;                   &lt;dbl&gt;\n1 Afghanistan    AFG            Access to clean f… EG.CFT.ACCS.…            9.51\n2 Afghanistan    AFG            Access to electri… EG.ELC.ACCS.…           NA   \n3 Afghanistan    AFG            CO2 emissions (kt) EN.ATM.CO2E.…          810   \n4 Afghanistan    AFG            Fossil fuel energ… EG.USE.COMM.…           NA   \n5 Afghanistan    AFG            Level of water st… ER.H2O.FWST.…           NA   \n6 Albania        ALB            Access to clean f… EG.CFT.ACCS.…           42.7 \n# ℹ 19 more variables: `2002 [YR2002]` &lt;dbl&gt;, `2003 [YR2003]` &lt;dbl&gt;,\n#   `2004 [YR2004]` &lt;dbl&gt;, `2005 [YR2005]` &lt;dbl&gt;, `2006 [YR2006]` &lt;dbl&gt;,\n#   `2007 [YR2007]` &lt;dbl&gt;, `2008 [YR2008]` &lt;dbl&gt;, `2009 [YR2009]` &lt;dbl&gt;,\n#   `2010 [YR2010]` &lt;dbl&gt;, `2011 [YR2011]` &lt;dbl&gt;, `2012 [YR2012]` &lt;dbl&gt;,\n#   `2013 [YR2013]` &lt;dbl&gt;, `2014 [YR2014]` &lt;dbl&gt;, `2015 [YR2015]` &lt;dbl&gt;,\n#   `2016 [YR2016]` &lt;dbl&gt;, `2017 [YR2017]` &lt;dbl&gt;, `2018 [YR2018]` &lt;dbl&gt;,\n#   `2019 [YR2019]` &lt;dbl&gt;, `2020 [YR2020]` &lt;lgl&gt;\n\n\nLet’s tidy this up in a single sequence, with the pipe operator between.\nREMEMBER: Look at what you’ve done after every step in a sequence.\n\nwb_tidy &lt;- wb_indicators %&gt;% \n  tidyr::pivot_longer(cols = `2001 [YR2001]`:`2020 [YR2020]`,\n               names_to = \"year\",\n               values_to = \"indicator_value\") %&gt;% \n  tidyr::separate(col = year, into = c(\"year\", \"year_chr\"), sep = \" \") %&gt;% \n  dplyr::select(-'Country Code', -'Series Code', -year_chr) %&gt;% \n  tidyr::drop_na('Series Name') %&gt;% \n  tidyr::pivot_wider(names_from = 'Series Name', values_from = 'indicator_value') %&gt;% \n  dplyr::rename(country = 'Country Name', \n                year = 'year', \n                clean_fuels = 'Access to clean fuels and technologies for cooking (% of population)',\n                access_elec = 'Access to electricity (% of population)',\n                co2 = 'CO2 emissions (kt)',\n                fossil_fuels = 'Fossil fuel energy consumption (% of total)',\n                water_stress = 'Level of water stress: freshwater withdrawal as a proportion of available freshwater resources') %&gt;% \n  dplyr::mutate(year = as.numeric(year))\n  \n\n# Recall you can get the names of columns easily using names(df)\n\n\n\n\n\n\n\nCritical thinking\n\n\n\n\n\nHow long should a piped sequence be before I store the output and start a new piped sequence? Can a piped sequence be too long? Can I always pipe into everything?\n\n\n\n\nEnd Interactive Session 6"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-5.html",
    "href": "course-materials/interactive-sessions/interactive-session-5.html",
    "title": "Interactive Session 5",
    "section": "",
    "text": "Fork then clone this repo to create a version-controlled R Project for Day 5"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-5.html#setup",
    "href": "course-materials/interactive-sessions/interactive-session-5.html#setup",
    "title": "Interactive Session 5",
    "section": "",
    "text": "Fork then clone this repo to create a version-controlled R Project for Day 5"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-5.html#warm-up---for-loops-revisited-leslie-matrix",
    "href": "course-materials/interactive-sessions/interactive-session-5.html#warm-up---for-loops-revisited-leslie-matrix",
    "title": "Interactive Session 5",
    "section": "2. Warm up - For loops revisited (Leslie Matrix)",
    "text": "2. Warm up - For loops revisited (Leslie Matrix)\nOpen the leslie_projection.Rmd file in docs/. All code shown below for Part 0 is in that file. You should be able to run it out-of-the-box. In EDS 212, we learned about Leslie matrices for projecting populations based on mortality and reproduction for different organism life stages. Let’s return to one example we checked out.\nA population of fish we’re interested in has four life stages: eggs (E), fry (F), juvenile (J), breeding adult (A). You are told that annually:\n\nEach breeding adult will produce, on average, 200 eggs\n5% of eggs will survive to become fry\n10% of fry will survive to become juveniles\n16% of juveniles will survive to become adults\nAdult survival rate year to year is 90%\n\n\nCreate the matrix\n\n# Make the Leslie Matrix:\nfish_leslie &lt;- matrix(c(0, 0, 0, 200, 0.05, 0, 0, 0, 0, 0.10, 0, 0, 0, 0, 0.16, 0.9), nrow = 4, ncol = 4, byrow = TRUE)\n\n# Check it out: \nfish_leslie\n\n     [,1] [,2] [,3]  [,4]\n[1,] 0.00  0.0 0.00 200.0\n[2,] 0.05  0.0 0.00   0.0\n[3,] 0.00  0.1 0.00   0.0\n[4,] 0.00  0.0 0.16   0.9\n\n\nRecall, we are able to use the dot product (%*%) to estimate the population at the next year (we’ll draw this on the board to remember what it looks like).\nThe initial population structure is given by:\n\n# Initial population structure (Roe, Fry, Juvenile, Adult): \nfish_year0 &lt;- c(5000, 8000, 600, 400)\n\n\n# ------ WHAT HAPPENS HERE? ------ #\ntime_yr &lt;- seq(from = 0, to = 8, by = 1)\nproj_year &lt;- matrix(ncol = length(fish_year0), nrow = length(time_yr))\nproj_year[1, ] &lt;- fish_year0\n\n\nfor (i in 2:length(time_yr)) {\n  proj_year[i,] &lt;- fish_leslie %*% proj_year[i-1,]\n}\n# -------------------------------- #\n\n# The rest is wrangling & visualization:\ncolnames(proj_year) &lt;- c(\"eggs\", \"fry\", \"juvenile\", \"adult\")\nproj_df &lt;- data.frame(time_yr, proj_year) %&gt;% \n  pivot_longer(cols = -time_yr, names_to = \"lifestage\", values_to = \"stage_population\")\n\nggplot(data = proj_df, aes(x = time_yr, y = stage_population)) +\n  geom_line(aes(color = lifestage)) +\n  scale_y_log10()"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-5.html#testing-functions-with-testthat",
    "href": "course-materials/interactive-sessions/interactive-session-5.html#testing-functions-with-testthat",
    "title": "Interactive Session 5",
    "section": "3. Testing functions with {testthat}",
    "text": "3. Testing functions with {testthat}\n\nCreate a new R Markdown file in your existing project (in docs/) saved as fun_testing.Rmd\nInstall the testthat package (install.packages(\"testthat\"))\nInstall the devtools package (install.packages(\"devtools\"))\nInstall the remotes packages (install.packages(\"remotes\"))\n\nAs we develop algorithms, we’ll change our code. We want a way to automatically check our work to make sure it’s behaving as expected. The testthat package “tries to make testing as fun as possible.”\n\n\n\n\n\n\nDefinition\n\n\n\nUnit test: A unit test is an automated check of a piece (“unit”) of your code\n\n\nLet’s consider an example. We’re writing a function to find the mean value of each column, then return the lowest and highest mean calculated (in that order). We would expect:\n\nThe outcome to be a numeric vector of length 2\nWhere the first value in the vector is smaller than the second value in that vector\n\n\nWrite the function\nLet’s write the function first, then create some accompanying tests to make sure they’re working.\n\nmean_range &lt;- function(df) {\n  col_means &lt;- apply(X = df, MARGIN = 2, FUN = mean, na.rm = TRUE) # Returns column means as a vector\n  col_mean_max &lt;- max(col_means) # Looks for the maximum value in the vector\n  col_mean_min &lt;- min(col_means) # Looks for the minimum value in the vector\n  return(c(col_mean_min, col_mean_max)) # Prints the vector with minimum & maximum\n}\n\n# Try it out:\nmean_range(df = mtcars)\n\n[1]   0.40625 230.72188\n\n\nOK great. But we’re doing some work on this code, and we don’t want to have to try a bunch of different things manually each time we change it to see how it breaks. Instead, let’s write some automated tests for this function that help us avoid that.\n\n\nCreate some tests with testthat\nThe testthat package contains a whole bunch of helper functions built for testing. Take a look at options in the package documentation.\nHere are some examples of the types of built-in functions for testing:\n\nexpect_length(): does the function return a vector of the expected length?\nexpect_equal(): does the function return an expected value?\nexpect_true(): does the code return TRUE or FALSE?\n\nFor example, let’s use expect_length() to test our function above, which should return a vector of length 2.\n\nexpect_length(mean_range(mtcars), 2)\n\nNothing is returned - that’s passing. You’ll get an error message if the test fails. What if we say the expected length of the vector returned is 3?\n\nexpect_length(mean_range(mtcars), 3)\n\nError: mean_range(mtcars) has length 2, not length 3.\n\n\nLet’s do another one!\nFor this function to be working correctly, the output of mean_range(mtcars) should have two values and we expect the first element to be smaller than the second element.\nOur test might look something like:\n\nexpect_true(mean_range(mtcars)[1] &lt; mean_range(mtcars)[2])\n\nThat passes! What happens if you change the alligator mouth direction?\n\nexpect_true(mean_range(mtcars)[1] &gt; mean_range(mtcars)[2])\n\nError: mean_range(mtcars)[1] &gt; mean_range(mtcars)[2] is not TRUE\n\n`actual`:   FALSE\n`expected`: TRUE \n\n\nThat test fails. This is just a little flavor of what unit tests do."
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-5.html#sourcing-functions",
    "href": "course-materials/interactive-sessions/interactive-session-5.html#sourcing-functions",
    "title": "Interactive Session 5",
    "section": "3. Sourcing functions",
    "text": "3. Sourcing functions\nWhen you’re writing functions (or working with someone else’s functions), often they’re not stored in the actual script or notebook you’re working in. If that’s the case, you can still use them by sourcing a function.\nLet’s make a function that’s stored in a script, save it in our project working directory, and use it in an R Markdown document.\n\nCreate a new R script (File &gt; New File &gt; R Script)\nSave the script in your project\n\nIn our new R script, let’s write a function that, when given inputs of the user’s favorite food and animal, returns the name of their future food cart.\n\nname_cart &lt;- function(food, animal) {\n  print(paste(\"Mc\", stringr::str_to_title(animal), \"'s \", stringr::str_to_title(food), \"Mart\", sep = \"\"))\n}\n\n# Try it out: \nname_cart(food = \"burrito\", animal = \"pika\")\n\nSave the script with a descriptive name, e.g. food_cart_functions.R (this could, in theory, contain multiple functions). Atop our .Rmd (in the setup chunk), we’ll source the script so we have access to its functions. Mine will look like this:\nsource(\"food_cart_functions.R\")\n\n\n\n\n\n\nNote\n\n\n\nYou may have your scripts in a subfolder (e.g. R/ or something) - you can use here::here() within the source() function to point to the right place within your R Project as needed.\n\n\nNow, add a code chunk in your R Markdown document that uses the name_cart() function you’ve created. It works over here, too!\n\nname_cart(food = \"strawberry\", animal = \"marmot\")\n\n[1] \"McMarmot's StrawberryMart\"\n\n\nThis gives us a valuable tool for organizing things within a project. Often, you’ll have a separate folder called R where you have your scripts / functions, and those are sourced as needed for use in your notebook or by another script you’re working on.\n\nA real sourcing example: cork oak growth\n\n\n\n\n\n\nCitation\n\n\n\nMariola Sánchez-González, Margarida Tomé, Gregorio Montero. Modelling height and diameter growth of dominant cork oak trees in Spain. Annals of Forest Science, Springer Nature (since 2011)/EDP Science (until 2010), 2005, 62 (7), pp.633-643.\n\n\nIn the src/ folder there is a script cork_oak_growth.R that contains one function height_t2 that estimates the height of a cork oak tree at some age (time 2), given a prior height of the tree, the age when that height was recorded (years), and the age you’re trying to estimate the new height for (these ages are t1 and t2, respectively, in the model).\nCreate a new .Rmd. Source the script by running source(here::here(\"path\", \"to\", \"script.R\")) in your setup chunk. Ensure that you can use the function in your .Rmd whenever you want to."
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-5.html#function-documentation",
    "href": "course-materials/interactive-sessions/interactive-session-5.html#function-documentation",
    "title": "Interactive Session 5",
    "section": "4. Function documentation",
    "text": "4. Function documentation\nDocumentation is a really important part of data science. Remember: “past you doesn’t respond to emails” (Wickham). I’ll also add that present you will forget things immediately, and future you is a grump. So make sure, for your sake and the sake of your collaborators, you document your functions (along with any useful annotation throughout your work) to make them easier for you to use later on.\nIt’s important to note here that documentation can mean different things.\nInformally, this can mean adding relevant comments to your script so that you know:\n\nArguments expected (name and units)\nVariable types expected (and output)\nA summary of what the function does\nAn example of how it works\nAny citations / relevant information\n\nFormally, in R, the {roxygen2} package can help guide our documentation.\nLet’s try creating some documentation for a little function. Write a function to calculate the maximum sustained harvest (\\(H\\)), given a fishery carrying capacity (\\(K\\)) and intrinsic growth rate, \\(r\\):\n\\[H = \\frac{Kr}{4}\\]\n\n# Write the functio\nmax_sustainable_harvest &lt;- function (K, r) {\n  harvest &lt;- (K * r) / 4\n  return(harvest)\n}\n\n# Try it out: \nmax_sustainable_harvest(K = 36000, r = 0.31)\n\n[1] 2790\n\n\nNow, how can we document this function?\nWe’ll use what’s called a Roxygen Skeleton - a skeleton set of documentation that prompts us to input important information about our function. Note: this exercise is just so you get a feel for what a roxygen skeleton looks like.\nTo add a Roxygen Skeleton:\n\nClick anywhere within your function\nIn RStudio, go up to ‘Code’ in the top menu, and click ‘Insert Roxygen Skeleton’\nImmediately above your function, you should see some auto-added text that looks like this (your parameters will already be added):\n\n\n#' Title\n#'\n#' @param  \n#' @param  \n#'\n#' @return\n#' @export\n#'\n#' @examples\n\n\nUpdate the fields with descriptions and types\n\n@param: information about the parameters (arguments) in your function\n@return: information about what the function returns to the user\n@export: we’ll return to this, but this lets an R package know that this is a function available for the user to use (not an internal function)\n@examples: add helpful examples for the user\n\n\n\n#' Maximum sustainable harvest\n#' \n#' A little function to return the maximum sustainable harvest given the carrying capacity and growth rate.\n#'\n#' @param K A number indicating the carrying capacity of the fishery (in individuals)  \n#' @param r A number indicating the intrinsic growth rate of the fishery (in 1 / yr)\n#'\n#' @return A number indicating the maximum annual sustainable harvest for the fishery\n#' @export\n#'\n#' @examples\n#' max_sustainable_yield(K = 3.8e5, r = 0.62)\n\nSo overall, our function code chunk might look like this:\n\n#' Maximum sustainable harvest\n#' \n#' A little function to return the maximum sustainable harvest given the carrying capacity and growth rate.\n#'\n#' @param K A number indicating the carrying capacity of the fishery (in individuals)  \n#' @param r A number indicating the intrinsic growth rate of the fishery (in 1 / yr)\n#'\n#' @return A number indicating the calculated maximum annual sustainable harvest for the fishery\n#' @export\n#'\n#' @examples\n#' max_sustainable_harvest(K = 3.8e5, r = 0.62)\n\nmax_sustainable_harvest &lt;- function (K, r) {\n  harvest &lt;- (K * r) / 4\n  return(harvest)\n}\n\n# Try it out: \nmax_sustainable_harvest(K = 36000, r = 0.31)\n\n[1] 2790\n\n\nNow, this might seem weird because it’s not obvious how that odd formatting of the Roxygen Skeleton actually helps. Why not just make them normal comments, and it words that a human can easily read?\nThe answer is: because this structure and syntax will make it possible for us to store our documentation as part of an R package containing our function. And that’s what we want to do next…"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-5.html#making-an-r-package",
    "href": "course-materials/interactive-sessions/interactive-session-5.html#making-an-r-package",
    "title": "Interactive Session 5",
    "section": "5. Making an R package",
    "text": "5. Making an R package\nLet’s put a bunch of what we’ve been working on together into an R package that you can use, and share with others so they can use your amazing function!\nStep-by-step:\n\nIn RStudio, new R Project &gt; New directory &gt; R package\nName your R package something awesome, like your favorite food and favorite animal (e.g. tacopika)\nSave your new package project in your EDS 221 folder, and open your project in a new session\nHey, you made an R package!\n\nSome placeholder example stuff exists in it already\nIncluding a single function called hello() that prints the worlds “Hello, world!”\nThe function is saved in a single .R script, with the same name, within the R folder\n\nWait you made an R package? Yup try it out.\n\nGo up to the Build tab, and click ‘Install and restart’\nYou should see that your package is attached (see library(your_package_name) in the Console)\nNow you can use any of the exported functions - which so far is only hello(). Try it!\n\nOK but let’s really make it your own…\n\n\nCreate a new R script in your project\nCreate a function within the script of your choosing (you’ll share this with a classmate). Some requirements:\n\nIt must have at least 3 parameters\nOf those 3 parameters, at least one must be a character, and one numeric\n\nSave the script in the R subfolder with the same name as your function. For example, if your function is called jurassic_park(), then the script should be saved in the R folder as jurassic_park.R.\nClick ‘Install and restart’ in the Build tab again\nTry your new function!\n\n\nDocumenting your function\n\nSo that’s cool that your new function exists within the package and you can use it. But now try checking the documentation on your function using ?function_name. What shows up? Zilch, right?\nWe want to add documentation for our function that we can check it out whenever we use the function, and so that other users will have critical information about what it does and how it works.\n\nIn the script with your function, click anywhere within your function\nAdd a roxygen skeleton (Code &gt; Insert Roxygen Skeleton)\nUpdate your documentation with at least a new title and parameter descriptions. Save.\nRun devtools::document() (note: if you see ‘Warning: Namespace not generated by Roxygen2’, you should delete the existing NAMESPACE file, then run devtools::document() again to resolve)\nSomething new is created - check the man/ folder and see that an .Rd (R documentation) file has been added that is associated with your function name, and that contains your updated documentation\nPress Install and restart in the Build tab\nCheck for your function documentation - does it exist now? Cool!\n\nThings to remember:\n\nRun devtools::document() any time you update your function or documentation\nYou must use Install and restart to see the changes when you test\n\n\nSharing your package\n\nPutting it on GitHub\nYour friends and family will definitely want to use the amazing R package you’ve just created. How can they install and use it?\nCollaborators can install your package straight from a GitHub repo. Let’s put it up there.\n\nIn your package project, run usethis::use_git()\nThen run usethis::use_github()\n\nThis should take you to your new GitHub repo for the package.\nInstalling a package from GitHub\nOnce your package is in a public repo on GitHub, anyone can install its contents by running:\n`remotes::install_github(\"username/reponame\")`\nFor example, if my package is in a repo called tacopika, then someone could install that package of mine using:\n`remotes::install_github(\"ryoliver/tacopika\")`\n\n\n\n\n\n\nNote\n\n\n\nYou can check all functions in a package by running lsf.str(\"package:packagename\") in the console. For example, after installing the package tacopika above, running lsf.str(\"package:tacopika\") in the Console will return all functions in it."
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-5.html#finding-vetting-and-using-other-packages",
    "href": "course-materials/interactive-sessions/interactive-session-5.html#finding-vetting-and-using-other-packages",
    "title": "Interactive Session 5",
    "section": "6. Finding, vetting and using other packages",
    "text": "6. Finding, vetting and using other packages\nNow that you’ve made your own package, let’s dive into packages that other developers have made so that we do more data science and less reinventing the wheel with code to do common useful things.\nLet’s spend a bit of time learning how to search for, choose, investigate put to use some R & Python Packages.\n\nFinding packages\n\nCRAN Task Views (search by topic): https://cran.r-project.org/web/views/\nMicrosoft R Application Network (MRAN) (search by keywords): https://mran.microsoft.com/packages\nSome trusted & awesome package sources:\n\nROpenSci: https://ropensci.org/packages/\nRStudio: https://www.rstudio.com/\npyOpenSci: https://www.pyopensci.org/\n\nOther great places to learn about package updates, releases, use:\n\n#rstats on Twitter (seriously)\nR Views blog by Joseph Rickert\nAlso…just a lot of googling (and using useful keywords, e.g. “tidyverse”)\n\n\n\n\nExploring / vetting packages\nExplore packages:\n\nUsually, on their GitHub repo\nContributors\nActivity (recent commits?)\nIssues (and responses)?\nHow many packages depend on this packages?\n\nDig a bit deeper:\n\nSource code\npkgdown website\nrelevant citations\n\n\n\nUsing and citing packages\nInstallation\nWe’ve seen the two main ways you’ll install R packages:\n\nFrom CRAN (using install.packages(\"packagename\"))\nFrom GitHub (using devtools::install_github(\"username/packagename\") or remotes::install_github(\"username/packagename\")\n\n\n\n\n\n\n\nNote\n\n\n\nThere are other ways to get R packages. For example, Bioconductor provides “open source software for bioinformatics” and is home to a lot of great software & packages for genomics work. See the Bioconductor installation page for information about how to install their packages & tools.\n\n\nWhat about Python packages? We haven’t dealt with this at all, since most of the packages we need are installed with Anaconda. What id we need something different?\nFollow along to make sure you can install packages with pip:\n\nOpen the Terminal\nCheck for pip by running the appropriate commands (make sure you choose the correct one for your OS)\nInstall pip if necessary (follow along with commands here)\nInstall Python packages by running the following in the command line, replacing “project_name”:\n\nMacOS: python3 -m pip install \"project_name\"\nWindows: py -m pip install \"project_name\"\n\n\nFor example, I have pip installed. To install the seaborn package, I run: python3 -m pip install \"seaborn\"\nGo ahead and try it: Use the appropriate command for your OS to install the Python version of the palmerpenguins package (also named palmerpenguins).\nUse and responsibility\nAnyone can make and publish an R or Python package to GitHub. That means it is your responsibility to determine if it is safe to use for your science. Once you’ve sufficiently explored, vetted and tested a package, the next step is to use it.\nCiting packages\nOpen source software is a major contribution to science and deserves to be credited. Often, developers are creating and maintaining packages voluntarily and without pay or support. Please remember to cite software and tools that helps you with your work.\nLuckily, packages (at least those on CRAN) come with a built-in citation to make it easy for you to see the citation. Use citation(packagename) to return package citation.\nFor example:\n\ncitation(\"palmerpenguins\")\n\nTo cite palmerpenguins in publications use:\n\n  Horst AM, Hill AP, Gorman KB (2020). palmerpenguins: Palmer\n  Archipelago (Antarctica) penguin data. R package version 0.1.0.\n  https://allisonhorst.github.io/palmerpenguins/. doi:\n  10.5281/zenodo.3960218.\n\nA BibTeX entry for LaTeX users is\n\n  @Manual{,\n    title = {palmerpenguins: Palmer Archipelago (Antarctica) penguin data},\n    author = {Allison Marie Horst and Alison Presmanes Hill and Kristen B Gorman},\n    year = {2020},\n    note = {R package version 0.1.0},\n    doi = {10.5281/zenodo.3960218},\n    url = {https://allisonhorst.github.io/palmerpenguins/},\n  }\n\n\nAnd an aside: R Markdown now makes it pretty nice to interface between your Zotero libraries and your R Markdown document. In the Visual Editor mode for R Markdown, you should see an `@` symbol. Clicking on it (if you have Zotero) should bring up your libraries.\n\nSelect the citation you want to insert. For example, data used in this example are from the palmerpenguins R package (Horst, Presmanes Hill, and Gorman 2020).\nClick on the citation text for a preview of how it’ll show up in the final document!\nLearn more about citations in R Markdown: https://blog.rstudio.com/2020/11/09/rstudio-1-4-preview-citations/\n\nEnd Interactive Session 5\n\n\n\n\n\n\n\nExtra examples\n\n\n\n\n\nExtra unit test example (from lecture):\n\nfish_mass &lt;- function(alpha, beta, fish_length) {\n  \n  if (fish_length &lt;= 0) {\n    stop(\"Fish length must be greater than or equal to 0.\")\n  }\n  \n  mass &lt;- alpha * (fish_length ^ beta)\n  return(mass)\n  \n}\n\n# Unit tests\n\nexpect_length(fish_mass(alpha = 1, beta = 2, fish_length = 3), 2)\n\nError: fish_mass(alpha = 1, beta = 2, fish_length = 3) has length 1, not length 2.\n\n\nExtra Roxygen example:\n\n#' Calculate the distance traveled in miles\n#'\n#' @param rate a number in units of miles per hour\n#' @param time a number in units of hours\n#'\n#' @return a number indicating the distance traveled in miles\n#' @export\n#'\n#' @examples\ndistance &lt;- function(rate, time) {\n  dist &lt;- rate * time\n  return(dist)\n}"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-3.html",
    "href": "course-materials/interactive-sessions/interactive-session-3.html",
    "title": "Interactive Session 3",
    "section": "",
    "text": "In EDS 212, we learned about Boolean operations and logic - the land of TRUE and FALSE. Boolean operations are ubiquitous in scientific programming. Whether looking for string pattern matches, comparing values, or filtering data frames, Boolean operators show up all the time - and even if we aren’t writing them explicitly, are working behind the scenes.\nLet’s refresh some basic Boolean (logical) operators for programming:\n\n# Create some objects (let's say these are tree heights)\npinyon_pine &lt;- 14\nlodgepole_pine &lt;- 46\n\n# Some logical expressions: \npinyon_pine == 10 # Exact match?\n\n[1] FALSE\n\npinyon_pine &lt; lodgepole_pine # Less than?\n\n[1] TRUE\n\nlodgepole_pine &gt;= 46 # Greater than or equal?\n\n[1] TRUE\n\npinyon_pine != 25 # Not equal to? \n\n[1] TRUE"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-3.html#boolean-operator-review",
    "href": "course-materials/interactive-sessions/interactive-session-3.html#boolean-operator-review",
    "title": "Interactive Session 3",
    "section": "",
    "text": "In EDS 212, we learned about Boolean operations and logic - the land of TRUE and FALSE. Boolean operations are ubiquitous in scientific programming. Whether looking for string pattern matches, comparing values, or filtering data frames, Boolean operators show up all the time - and even if we aren’t writing them explicitly, are working behind the scenes.\nLet’s refresh some basic Boolean (logical) operators for programming:\n\n# Create some objects (let's say these are tree heights)\npinyon_pine &lt;- 14\nlodgepole_pine &lt;- 46\n\n# Some logical expressions: \npinyon_pine == 10 # Exact match?\n\n[1] FALSE\n\npinyon_pine &lt; lodgepole_pine # Less than?\n\n[1] TRUE\n\nlodgepole_pine &gt;= 46 # Greater than or equal?\n\n[1] TRUE\n\npinyon_pine != 25 # Not equal to? \n\n[1] TRUE"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-3.html#conditionals",
    "href": "course-materials/interactive-sessions/interactive-session-3.html#conditionals",
    "title": "Interactive Session 3",
    "section": "2. Conditionals",
    "text": "2. Conditionals\nWe write conditionals to tell a computer what do to based on whether or not some conditions that we set are satisfied. For example, we may want to use conditionals to:\n\nOnly keep observations from counties with median home value &gt; $600,000\nRe-categorize farms as “moderate implementation” if they implement between 4 and 8 best management practices for mitigating nutrient runoff\n\n\nA basic if statement\nThe fundamental conditional statement is an if statement, which we can read as “If this condition is met, then do this.”\nAn example in R:\n\nburrito &lt;- 2.4 # Assign an object value\n\n# Write a short 'if' statement:\nif (burrito &gt; 2) {\n  print(\"I love burritos!\")\n}\n\n[1] \"I love burritos!\"\n\n\nTry changing the value of burritos to 1.5. What is returned when the if statement condition isn’t met?\nThis is important: for a solely “if” statement, there is no “else” option. So nothing happens if the condition isn’t met.\nIn Python:\n\nburrito = 2.4\n\nif burrito &gt; 2:\n  print(\"I love burritos!\")\n\nI love burritos!\n\n\n\n\nAn example with strings:\nHere, we’re using a new function from the stringr package: stringr::str_detect(). First, let’s learn something about how str_detect() works (see ?str_detect() for more information).\nstr_detect() “detects the presence or absence of a pattern in a string.” For example:\n\nmy_ships &lt;- c(\"Millenium Falcon\", \"X-wing\", \"Tie-Fighter\", \"Death Star\")\nstr_detect(my_ships, pattern = \"r\") # Asks: which elements in the vector contain \"r\"\n\n[1] FALSE FALSE  TRUE  TRUE\n\n\nNotice that it returns a logical TRUE or FALSE for each element in the vector, based on whether or not they contain the string pattern “r”.\nNow let’s try using it in a conditional statement. Here, if a phrase contains the word “love”, return the phrase “Big burrito fan!” Otherwise, return nothing.\n\nphrase &lt;- \"I love burritos\"\n\nif (str_detect(phrase, \"love\")) {\n  print(\"Big burrito fan!\")\n}\n\n[1] \"Big burrito fan!\"\n\n\nTry updating the phrase or string pattern in the code above to test different variations.\n\n\nA basic if-else statement\nIn the examples above, there was a lonely “if” statement, which returned something if the condition was met, but otherwise returned nothing. Usually, we’ll want our code to return something else if our condition is not met. In that case, we can write an if-else statement. Here are a couple of examples:\nIn R:\n\npika &lt;- 89.1\n\nif (pika &gt; 60) {\n  print(\"mega pika\")\n} else\n  print(\"normal pika\")\n\n[1] \"mega pika\"\n\n\nIn Python:\n\npika = 89.1\n\nif pika &gt; 60:\n  print(\"mega pika\")\nelse:\n  print(\"normal pika\")\n\nmega pika\n\n\n\n\nAn example with strings:\n\nfood &lt;- \"I love enchiladas!\"\n\nif (str_detect(food, \"burritos\")) {\n  print(\"yay burritos!\")\n} else\n  print(\"what about burritos?\")\n\n[1] \"what about burritos?\"\n\n\n\n\nMore options: if-else if-else statements\nSometimes there aren’t just two outcomes! In that case, you can specify different options using the if-else if-else structure. Several examples are shown below.\nIn R:\n\nmarmot &lt;- 2.8\n\nif (marmot &lt; 0.5) {\n  print(\"a small marmot!\")\n} else if (marmot &gt;= 0.5 & marmot &lt; 3) {\n  print(\"a medium marmot!\")\n} else \n  print(\"a large marmot!\")\n\n[1] \"a medium marmot!\"\n\n\nIn Python:\n\nmarmot = 2.8\n\nif marmot &lt; 0.5:\n  print(\"a small marmot!\")\nelif 0.5 &lt;= marmot &lt; 3: \n  print(\"a medium marmot!\")\nelse: \n  print(\"a large marmot!\")\n\na medium marmot!\n\n\n\n\nswitch statements\nA slightly more efficient tool is the switch() function, which allows you to “select one of a list of alternatives.” See ?switch for more information. This can be particularly useful for switching between different character strings, based on a condition or user selection.\nIn R:\n\nspecies = \"mouse\"\n\nswitch(species,\n       \"cat\" = print(\"Meow\"),\n       \"dog\" = print(\"Woof!\"),\n       \"mouse\" = print(\"Squeak\"))\n\n[1] \"Squeak\"\n\n\n\n\nHelpful functionals for conditional statements\nAs we get into Week 2 of EDS 221, we’ll learn other functions that make conditionals a bit more read and writable. For example, the dplyr::case_when() function is very helpful for writing vectorized if-else statements!"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-3.html#introduction-to-for-loops",
    "href": "course-materials/interactive-sessions/interactive-session-3.html#introduction-to-for-loops",
    "title": "Interactive Session 3",
    "section": "3. Introduction to for loops",
    "text": "3. Introduction to for loops\nA general guideline from RStudio Chief Scientist Hadley Wickham is that if we copy something more than twice, we should write a function or a loop. Avoiding redundancy in code can make it more readable, reproducible and efficient.\nWe write a for loop to iterate through different elements of a data structure (e.g. values in a vector, or columns in a data frame), applying some operation to each, and returning the new output. In this section, we’ll learn some for loop basics.\n\nBasic for loop\nLet’s start with a very basic for loop: for each element in a vector, do something to it and return the new thing. Here, we start with a vector of puppy names. Starting with the first name “Teddy”, we enter the loop and add “My dog’s name is” to the beginning of the string. Then we move on to the next name in the vector, continuing until we have applied the updated text to all puppy names.\nIn R:\n\ndog_names &lt;- c(\"Teddy\", \"Khora\", \"Banjo\", \"Waffle\")\n\nfor (pupster in dog_names) {\n  print(paste(\"My dog's name is\", pupster))\n}\n\n[1] \"My dog's name is Teddy\"\n[1] \"My dog's name is Khora\"\n[1] \"My dog's name is Banjo\"\n[1] \"My dog's name is Waffle\"\n\n# Or similarly (\\n is for new line):\nfor (pupster in dog_names) {\n  cat(\"My dog's name is\", pupster, \"\\n\")\n}\n\nMy dog's name is Teddy \nMy dog's name is Khora \nMy dog's name is Banjo \nMy dog's name is Waffle \n\n\nIn Python:\n\ndog_names = [\"Teddy\", \"Khora\", \"Banjo\", \"Waffle\"]\n\nfor i in dog_names: \n  print(\"My dog's name is \" + i)\n\nMy dog's name is Teddy\nMy dog's name is Khora\nMy dog's name is Banjo\nMy dog's name is Waffle\n\n\n\n\nAnother basic for loop example:\nLet’s check out another little example. Here, we create a sequence that ranges from 0 to 3 by increments of 0.5. Then, for each element in that vector, we add 2 to it, then move on to the next element.\nIn R:\n\nmass &lt;- seq(from = 0, to = 3, by = 0.5)\n\nfor (i in mass) {\n  new_val = i + 2\n  print(new_val)\n}\n\n[1] 2\n[1] 2.5\n[1] 3\n[1] 3.5\n[1] 4\n[1] 4.5\n[1] 5\n\n\nOr, using seq_along():\n\nmass &lt;- seq(from = 0, to = 3, by = 0.5)\n\nfor (i in seq_along(mass)) {\n  new_val = mass[i] + 2\n  print(new_val)\n}\n\n[1] 2\n[1] 2.5\n[1] 3\n[1] 3.5\n[1] 4\n[1] 4.5\n[1] 5\n\n\nLet’s try another one with seq_along():\nFor each element in a vector, find the sum of that value plus the next value in the sequence:\n\ntree_height &lt;- c(1,2,6,10)\n\nfor (i in seq_along(tree_height)) {\n  val = tree_height[i] + tree_height[i + 1]\n  print(val)\n}\n\n[1] 3\n[1] 8\n[1] 16\n[1] NA"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-3.html#for-loops-with-conditional-statements",
    "href": "course-materials/interactive-sessions/interactive-session-3.html#for-loops-with-conditional-statements",
    "title": "Interactive Session 3",
    "section": "4. For loops with conditional statements",
    "text": "4. For loops with conditional statements\nEarlier in this session, we learned how to write a conditional if or if-else statement. Sometimes we’ll want to change what a for loop does based on a conditional - so we’ll have a conditional statement within a for loop. Let’s take a look and talk through an example:\nA basic conditional for loop in R: Here, we have a vector of animals called animal. Running through each animal in the vector, if the species is “dog” we want to return “I love dogs!”. For all other animals, we’ll return “These are other animals!”\n\n# Create the animals vector:\nanimal &lt;- c(\"cat\", \"dog\", \"dog\", \"zebra\", \"dog\")\n\n# Create the for loop with conditional statement: \nfor (i in seq_along(animal)) {\n  if (animal[i] == \"dog\") {\n    print(\"I love dogs!\")\n  } else\n    print(\"These are other animals!\")\n}\n\n[1] \"These are other animals!\"\n[1] \"I love dogs!\"\n[1] \"I love dogs!\"\n[1] \"These are other animals!\"\n[1] \"I love dogs!\"\n\n\nOr, for a numerical example:\n\n# Animal types:\nspecies &lt;- c(\"dog\", \"elephant\", \"goat\", \"dog\", \"dog\", \"elephant\")\n\n# And their respective ages in human years:\nage_human &lt;- c(3, 8, 4, 6, 12, 18)\n\n# Convert ages to \"animal years\" using the following:\n# 1 human year = 7 in dog years\n# 1 human year = 0.88 in elephant years\n# 1 human year = 4.7 in goat years\n\nfor (i in seq_along(species)) {\n  if (species[i] == \"dog\") {\n    animal_age &lt;- age_human[i] * 7\n  } else if (species[i] == \"elephant\") {\n    animal_age &lt;- age_human[i] * 0.88\n  } else if (species[i] == \"goat\") {\n    animal_age &lt;- age_human[i] * 4.7\n  }\n  print(animal_age)\n}\n\n[1] 21\n[1] 7.04\n[1] 18.8\n[1] 42\n[1] 84\n[1] 15.84\n\n\n\n\n\n\n\n\nReminder\n\n\n\n\n\nKeep this idea in mind when we learn dplyr::case_when()!"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-3.html#storing-outputs-of-a-for-loop",
    "href": "course-materials/interactive-sessions/interactive-session-3.html#storing-outputs-of-a-for-loop",
    "title": "Interactive Session 3",
    "section": "5. Storing outputs of a for loop",
    "text": "5. Storing outputs of a for loop\nSo far, we’ve returned outputs of a for loop, but we haven’t stored the outputs of a for loop as a new object in our environment.\nTo store outputs of a for loop, we’ll create an empty vector, then populate it with the for loop elements as they’re created. It’s important to do this - it will make your loops quicker, which is critical once you start working with big data.\n\n# Create the empty vector animal_ages:\nanimal_ages &lt;- vector(mode = \"numeric\", length = length(species))\n\n# Vectors with species and human age: \nspecies &lt;- c(\"dog\", \"elephant\", \"goat\", \"dog\", \"dog\", \"elephant\")\n\nage_human &lt;- c(3, 8, 4, 6, 12, 18)\n\n# Same loop as above, with additional piece added\n# To populate our empty vector\n\nfor (i in seq_along(species)) {\n  if (species[i] == \"dog\") {\n    animal_age &lt;- age_human[i] * 7\n  } else if (species[i] == \"elephant\") {\n    animal_age &lt;- age_human[i] * 0.88\n  } else if (species[i] == \"goat\") {\n    animal_age &lt;- age_human[i] * 4.7\n  }\n  animal_ages[i] &lt;- animal_age # Populate our empty vector\n}\n\nAnother example of storing an output:\n\ntigers &lt;- c(29, 34, 82)\nlions &lt;- c(2, 18, 6)\n\nbig_cats &lt;- vector(mode = \"numeric\", length = length(tigers))\n\nfor (i in seq_along(tigers)) {\n  total_cats &lt;- tigers[i] + lions[i]\n  big_cats[i] &lt;- total_cats\n}\n\n\n\n\n\n\n\nCritical thinking\n\n\n\n\n\nDon’t make your life harder for no reason. What’s the easiest way to fine the big_cats values as calculated above?\n\n\n\n\nFor loops across columns of a data frame\nRecall from lecture: df[[i]] calls the ith column from the df data frame with simplification (i.e., it is pulled out as a vector, not a 1-d data frame).\nWrite a loop that iteratively calculates the mean of value of each column in mtcars.\n\n# Create our storage vector\n# Note: ncol() returns the number of columns in a data frame\nmean_mtcars &lt;- vector(mode = \"numeric\", length = ncol(mtcars))\n\n# Write the loop\nfor (i in 1:ncol(mtcars)) {\n  mean_val &lt;- mean(mtcars[[i]], na.rm = TRUE)\n  mean_mtcars[[i]] &lt;- mean_val\n}\n\n# Tada.\n\n\n\nA for loop over columns with a condition\nSometimes you’ll want to iterate over some, but not all, columns in a data frame. Then, you may want to write a for loop with a condition.\nFor example, starting with the penguins data frame (from the palmerpenguins package), let’s find the median value of all numeric variables.\n\nfor (i in seq_along(penguins)) {\n  if (is.numeric(penguins[[i]])) {\n    penguin_med &lt;- median(penguins[[i]], na.rm = TRUE)\n    print(penguin_med)\n  } else {\n    print(\"non-numeric\")\n  }\n}\n\n[1] \"non-numeric\"\n[1] \"non-numeric\"\n[1] 44.45\n[1] 17.3\n[1] 197\n[1] 4050\n[1] \"non-numeric\"\n[1] 2008"
  },
  {
    "objectID": "course-materials/interactive-sessions/interactive-session-3.html#functional-programming---some-sugar-in-r",
    "href": "course-materials/interactive-sessions/interactive-session-3.html#functional-programming---some-sugar-in-r",
    "title": "Interactive Session 3",
    "section": "6. Functional programming - some sugar in R",
    "text": "6. Functional programming - some sugar in R\nFor loops are a critical skill for any data scientist to understand. However, you may not end up writing many of them from scratch. That’s because there exist a number of useful tools (functions) to make iteration easier for us. Here, we’ll briefly learn about two:\n\nThe apply family of functions for iteration\nMaking iteration {purrr}\n\n\napply\nThe apply functions simplify iteration over elements of a data structure (e.g., a data frame). To use apply() most simply, we need to tell it 3 things:\n\nWhat is the data we’re iterating over?\nAre we iterating across rows (1) or columns (2)?\nWhat function are we applying to each element we’re iterating over?\n\nFor example, let’s say we want to find the mean value of all columns in the mtcars data frame:\n\napply(X = mtcars, MARGIN = 2, FUN = mean)\n\n       mpg        cyl       disp         hp       drat         wt       qsec \n 20.090625   6.187500 230.721875 146.687500   3.596563   3.217250  17.848750 \n        vs         am       gear       carb \n  0.437500   0.406250   3.687500   2.812500 \n\n\n\n\n\n\n\n\nCritical thinking\n\n\n\n\n\nTake a moment to break down what each argument does in the apply() function above. Keep this in mind - we can also write our own function that we’d want to apply to each element!\n\n\n\nThere are also variations on apply, like lapply and sapply, that are worth looking into for specific use cases.\n\n\ndplyr::across(), group_by() and summarize() in combo\nIf the takeaway is “Whoa, there are a lot of options…” - YES. There are many existing functions that can help you loop over elements of your data and apply a function.\nHere’ we’ll learn some of my favorites - to loop over columns and by group - and return a nice table of values.\n\npenguins %&gt;% \n  group_by(species) %&gt;% \n  summarize(across(where(is.numeric), mean, na.rm = TRUE))\n\nWarning: There was 1 warning in `summarize()`.\nℹ In argument: `across(where(is.numeric), mean, na.rm = TRUE)`.\nℹ In group 1: `species = Adelie`.\nCaused by warning:\n! The `...` argument of `across()` is deprecated as of dplyr 1.1.0.\nSupply arguments directly to `.fns` through an anonymous function instead.\n\n  # Previously\n  across(a:b, mean, na.rm = TRUE)\n\n  # Now\n  across(a:b, \\(x) mean(x, na.rm = TRUE))\n\n\n# A tibble: 3 × 6\n  species   bill_length_mm bill_depth_mm flipper_length_mm body_mass_g  year\n  &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt;\n1 Adelie              38.8          18.3              190.       3701. 2008.\n2 Chinstrap           48.8          18.4              196.       3733. 2008.\n3 Gentoo              47.5          15.0              217.       5076. 2008.\n\n\n\n\n{purrr}\nThe documentation for ?purrr::map() is titled “Apply a function to each element of a list or atomic vector.” Which should ring your for loop brain bells.\nThere are a number of functions within the purrr::map() family to best suit your specific needs.\nThe equivalent map() approach to the example above (finding the mean of each column in the mtcars data frame) is as follows:\n\nmap(.x = mtcars, .f = mean)\n\n$mpg\n[1] 20.09062\n\n$cyl\n[1] 6.1875\n\n$disp\n[1] 230.7219\n\n$hp\n[1] 146.6875\n\n$drat\n[1] 3.596563\n\n$wt\n[1] 3.21725\n\n$qsec\n[1] 17.84875\n\n$vs\n[1] 0.4375\n\n$am\n[1] 0.40625\n\n$gear\n[1] 3.6875\n\n$carb\n[1] 2.8125\n\n# Or, to return the output in a data frame (instead of a list):\nmap_df(.x = mtcars, .f = mean)\n\n# A tibble: 1 × 11\n    mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1  20.1  6.19  231.  147.  3.60  3.22  17.8 0.438 0.406  3.69  2.81\n\n\n\nEnd Interactive Session 3"
  },
  {
    "objectID": "course-materials/day3.html#class-materials",
    "href": "course-materials/day3.html#class-materials",
    "title": "Conditionals and logical operators",
    "section": "Class materials",
    "text": "Class materials\n\n\n\n\n\n\n\n\n Session\n Lecture slides\n Interactive session\n\n\n\n\nday 3 / morning\nConditionals and logical operations, intro to for loops\nRefresh logical operations, write basics for loops in R\n\n\nday 3 / afternoon\nLoops continued - and functions to help\nFor loops with conditions, apply() functions, and across()"
  },
  {
    "objectID": "course-materials/day3.html#end-of-day-practice",
    "href": "course-materials/day3.html#end-of-day-practice",
    "title": "Conditionals and logical operators",
    "section": "End-of-day practice",
    "text": "End-of-day practice\nComplete the following tasks / activities before heading home for the day!\n\n Presentation: Learning strategies for programming\n Day 3 Practice: Conditionals & for loops"
  },
  {
    "objectID": "course-materials/day3.html#additional-resources",
    "href": "course-materials/day3.html#additional-resources",
    "title": "Conditionals and logical operators",
    "section": "Additional Resources",
    "text": "Additional Resources\nTBD"
  },
  {
    "objectID": "course-materials/eod-keys/eod-day1-key.html",
    "href": "course-materials/eod-keys/eod-day1-key.html",
    "title": "Day 1: Tasks & activities - KEY",
    "section": "",
    "text": "Attach the tidyverse and janitor packages in a new code chunk\n\n\n\n\n\n\n\nSolution\n\n\n\n\nlibrary(tidyverse)\nlibrary(janitor)\n\n\n\n\nRead in the stl_blood_lead.csv data as stl_lead and use janitor::clean_names to convert all variable names to lower snake case\n\n\n\n\n\n\n\nSolution\n\n\n\n\nstl_lead &lt;- read_csv(here::here(\"data\", \"stl_blood_lead.csv\")) |&gt;\n  janitor::clean_names() # Convert variable names to lower snake case\n\n\n\n\nDo some basic exploration of the dataset\n\n\n\n\n\n\n\nSolution\n\n\n\n\nsummary(stl_lead) # View summary statistics of each variable\n\n     geo_id             tract_ce       name_lsad          count_tested   \n Min.   :2.951e+10   Min.   :101100   Length:106         Min.   :  23.0  \n 1st Qu.:2.951e+10   1st Qu.:106425   Class :character   1st Qu.: 411.0  \n Median :2.951e+10   Median :112350   Mode  :character   Median : 694.0  \n Mean   :2.951e+10   Mean   :113386                      Mean   : 737.4  \n 3rd Qu.:2.951e+10   3rd Qu.:119102                      3rd Qu.: 923.2  \n Max.   :2.951e+10   Max.   :127600                      Max.   :2116.0  \n  pct_elevated      total_pop    total_pop_moe       white       \n Min.   : 0.000   Min.   : 620   Min.   : 94.0   Min.   :   1.0  \n 1st Qu.: 4.588   1st Qu.:2025   1st Qu.:249.5   1st Qu.:  88.5  \n Median : 9.480   Median :2912   Median :333.5   Median :1290.0  \n Mean   :10.164   Mean   :2999   Mean   :353.3   Mean   :1371.7  \n 3rd Qu.:14.380   3rd Qu.:3784   3rd Qu.:439.5   3rd Qu.:2168.2  \n Max.   :23.280   Max.   :7069   Max.   :832.0   Max.   :6128.0  \n   white_moe         black          black_moe      poverty_tot    \n Min.   :  4.0   Min.   :  35.0   Min.   : 38.0   Min.   : 158.0  \n 1st Qu.: 60.5   1st Qu.: 633.2   1st Qu.:183.2   1st Qu.: 408.5  \n Median :212.5   Median :1334.5   Median :269.0   Median : 651.5  \n Mean   :201.4   Mean   :1429.9   Mean   :288.4   Mean   : 786.9  \n 3rd Qu.:299.8   3rd Qu.:2029.0   3rd Qu.:379.2   3rd Qu.: 955.8  \n Max.   :751.0   Max.   :4572.0   Max.   :760.0   Max.   :2801.0  \n poverty_tot_moe   poverty_u18     poverty_u18_moe \n Min.   :  65.0   Min.   :   0.0   Min.   :  3.00  \n 1st Qu.: 160.2   1st Qu.:  66.5   1st Qu.: 61.25  \n Median : 241.5   Median : 173.5   Median :120.50  \n Mean   : 270.5   Mean   : 249.8   Mean   :140.08  \n 3rd Qu.: 337.5   3rd Qu.: 341.8   3rd Qu.:194.75  \n Max.   :1049.0   Max.   :1320.0   Max.   :595.00  \n\n\n\n\n\nCreate a new data frame called stl_lead_prop that has one additional column called prop_white that returns the percent of each census tract identifying as white (variable white in the dataset divided by variable totalPop, times 100)\n\n\n\n\n\n\n\nSolution\n\n\n\n\nstl_lead_prop &lt;- stl_lead |&gt; # Call data for wrangling\n  mutate(prop_white = (white / total_pop)*100) # Create a new variable and populate"
  },
  {
    "objectID": "course-materials/eod-keys/eod-day1-key.html#data-import-and-exploration",
    "href": "course-materials/eod-keys/eod-day1-key.html#data-import-and-exploration",
    "title": "Day 1: Tasks & activities - KEY",
    "section": "",
    "text": "Attach the tidyverse and janitor packages in a new code chunk\n\n\n\n\n\n\n\nSolution\n\n\n\n\nlibrary(tidyverse)\nlibrary(janitor)\n\n\n\n\nRead in the stl_blood_lead.csv data as stl_lead and use janitor::clean_names to convert all variable names to lower snake case\n\n\n\n\n\n\n\nSolution\n\n\n\n\nstl_lead &lt;- read_csv(here::here(\"data\", \"stl_blood_lead.csv\")) |&gt;\n  janitor::clean_names() # Convert variable names to lower snake case\n\n\n\n\nDo some basic exploration of the dataset\n\n\n\n\n\n\n\nSolution\n\n\n\n\nsummary(stl_lead) # View summary statistics of each variable\n\n     geo_id             tract_ce       name_lsad          count_tested   \n Min.   :2.951e+10   Min.   :101100   Length:106         Min.   :  23.0  \n 1st Qu.:2.951e+10   1st Qu.:106425   Class :character   1st Qu.: 411.0  \n Median :2.951e+10   Median :112350   Mode  :character   Median : 694.0  \n Mean   :2.951e+10   Mean   :113386                      Mean   : 737.4  \n 3rd Qu.:2.951e+10   3rd Qu.:119102                      3rd Qu.: 923.2  \n Max.   :2.951e+10   Max.   :127600                      Max.   :2116.0  \n  pct_elevated      total_pop    total_pop_moe       white       \n Min.   : 0.000   Min.   : 620   Min.   : 94.0   Min.   :   1.0  \n 1st Qu.: 4.588   1st Qu.:2025   1st Qu.:249.5   1st Qu.:  88.5  \n Median : 9.480   Median :2912   Median :333.5   Median :1290.0  \n Mean   :10.164   Mean   :2999   Mean   :353.3   Mean   :1371.7  \n 3rd Qu.:14.380   3rd Qu.:3784   3rd Qu.:439.5   3rd Qu.:2168.2  \n Max.   :23.280   Max.   :7069   Max.   :832.0   Max.   :6128.0  \n   white_moe         black          black_moe      poverty_tot    \n Min.   :  4.0   Min.   :  35.0   Min.   : 38.0   Min.   : 158.0  \n 1st Qu.: 60.5   1st Qu.: 633.2   1st Qu.:183.2   1st Qu.: 408.5  \n Median :212.5   Median :1334.5   Median :269.0   Median : 651.5  \n Mean   :201.4   Mean   :1429.9   Mean   :288.4   Mean   : 786.9  \n 3rd Qu.:299.8   3rd Qu.:2029.0   3rd Qu.:379.2   3rd Qu.: 955.8  \n Max.   :751.0   Max.   :4572.0   Max.   :760.0   Max.   :2801.0  \n poverty_tot_moe   poverty_u18     poverty_u18_moe \n Min.   :  65.0   Min.   :   0.0   Min.   :  3.00  \n 1st Qu.: 160.2   1st Qu.:  66.5   1st Qu.: 61.25  \n Median : 241.5   Median : 173.5   Median :120.50  \n Mean   : 270.5   Mean   : 249.8   Mean   :140.08  \n 3rd Qu.: 337.5   3rd Qu.: 341.8   3rd Qu.:194.75  \n Max.   :1049.0   Max.   :1320.0   Max.   :595.00  \n\n\n\n\n\nCreate a new data frame called stl_lead_prop that has one additional column called prop_white that returns the percent of each census tract identifying as white (variable white in the dataset divided by variable totalPop, times 100)\n\n\n\n\n\n\n\nSolution\n\n\n\n\nstl_lead_prop &lt;- stl_lead |&gt; # Call data for wrangling\n  mutate(prop_white = (white / total_pop)*100) # Create a new variable and populate"
  },
  {
    "objectID": "course-materials/eod-keys/eod-day1-key.html#visualize-data",
    "href": "course-materials/eod-keys/eod-day1-key.html#visualize-data",
    "title": "Day 1: Tasks & activities - KEY",
    "section": "Visualize data",
    "text": "Visualize data\n\nCreate a scatterplot graph of the percentage of children in each census tract with elevated blood lead levels versus the percent of each census tract identifying as white\n\n\n\n\n\n\n\nSolution\n\n\n\n\nstl_lead_plot &lt;- ggplot(data = stl_lead_prop, # Set data for plotting\n                        aes(x = prop_white, y = pct_elevated)) + # Assign x- and y-axis variables\n  geom_point() # Create scatterplot\n\nstl_lead_plot # View scatterplot\n\n\n\n\n\n\n\n\n\n\n\nSave a .png of the scatterplot to figs, with dimensions of (6” x 5”) (width x height)\n\n\n\n\n\n\n\nSolution\n\n\n\n\nggsave(stl_lead_plot,\n       here::here(\"figs\", \"stl_lead_plot.png\"), # Set filepath to save scatterplot\n       width = 6, height = 5, units = c(\"in\")) # Set dimensions with units\n\n\n\n\nCreate a histogram of the percentage of children in each census tract with elevated blood lead levels\n\n\n\n\n\n\n\nSolution\n\n\n\n\nstl_lead_hist &lt;- ggplot(data = stl_lead_prop, # Set data for plotting\n       aes(x = pct_elevated)) + # Assign x-axis variable\n  geom_histogram() # Create histogram\n\nstl_lead_hist # View histogram\n\n\n\n\n\n\n\n\n\n\n\nSave a .jpg of the scatterplot to figs\n\n\n\n\n\n\n\nSolution\n\n\n\n\nggsave(stl_lead_hist,\n       here::here(\"figs\", \"stl_lead_hist.jpg\")) # Set filepath to save histogram"
  },
  {
    "objectID": "course-materials/eod-keys/eod-day2-key.html",
    "href": "course-materials/eod-keys/eod-day2-key.html",
    "title": "Day 2: Tasks & activities - KEY",
    "section": "",
    "text": "Create a vector called vec_1 containing the following:\n\n\nWhat is the class of the vector? class()\nWhat type of variable does it store? typeof()\nAccess the 3rd element and store as vec_1_e3\nAccess the 1st element and store as vec_1_e1\nAccess the 5th through 7th elements and store as vec_1_e5to7\nReassign vec_1 as a character using as.character, stored as vec_1_char. What does the output look like?\n\n\n\n\n\n\n\nSolution\n\n\n\n\nvec_1 &lt;- c(2, 5, 9, 10, 8, 12, 1, 0) # Create vector\nvec_1 # View vector\n\n[1]  2  5  9 10  8 12  1  0\n\nclass(vec_1) # Check vector class\n\n[1] \"numeric\"\n\ntypeof(vec_1) # Check data type\n\n[1] \"double\"\n\nvec_1_e3 &lt;- vec_1[3] # Extract 3rd element\nvec_1_e3 # Print element\n\n[1] 9\n\nvec_1_e1 &lt;- vec_1[1] # Extract 1st element\nvec_1_e1 # Print element\n\n[1] 2\n\nvec_1_e5to7 &lt;- vec_1[5:7] # Extract 5th-7th elements\nvec_1_e5to7 # Print elements\n\n[1]  8 12  1\n\nvec_1_char &lt;- as.character(vec_1) # Reassign to character vector\nvec_1_logical &lt;- as.logical(vec_1) # Reassign to logical vector\n\n\n\n\nCreate a vector called vec_2 of named elements, where town = \"Santa Barbara, location = \"Rincon\", swell = \"south\"\n\n\nTake a look at what you’ve made\nWhat is the class of vector elements? class()\nWhat is the length of vec_2?\nAccess the 2nd element by name and store as vec_2_e2\n\n\n\n\n\n\n\nSolution\n\n\n\n\nvec_2 &lt;- c(town = \"Santa Barbara\", location = \"Rincon\", swell = \"south\")\nvec_2 # View vector\n\n           town        location           swell \n\"Santa Barbara\"        \"Rincon\"         \"south\" \n\nclass(vec_2) # Check vector class\n\n[1] \"character\"\n\nlength(vec_2) # Check vector length\n\n[1] 3\n\nvec_2_e2 &lt;- vec_2[2] # Extract 2nd element\nvec_2_e2 # Print element\n\nlocation \n\"Rincon\" \n\n\n\n\n\nCreate a data frame in R\n\n\nReturn the class of the entire data frame\nReturn the class of the species column\nFind the maximum value of the count() column, store as max_count\n\n\n\n\n\n\n\nSolution\n\n\n\n\ndf_1 &lt;- data.frame(region = c(\"A\", \"B\", \"A\",\"D\"),\n                   species = c(\"otter\", \"great white\", \"sea lion\", \"gray whale\"),\n                   count = c(12, 2, 36, 6))\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\nclass(df_1) # Check df class\n\n[1] \"data.frame\"\n\nclass(df_1$species) # Check species column class\n\n[1] \"character\"\n\nmax_count &lt;- max(df_1$count) # Find maximum value of count column\nmax_count # Print maximum value\n\n[1] 36"
  },
  {
    "objectID": "course-materials/eod-keys/eod-day2-key.html#check-data-types",
    "href": "course-materials/eod-keys/eod-day2-key.html#check-data-types",
    "title": "Day 2: Tasks & activities - KEY",
    "section": "",
    "text": "Create a vector called vec_1 containing the following:\n\n\nWhat is the class of the vector? class()\nWhat type of variable does it store? typeof()\nAccess the 3rd element and store as vec_1_e3\nAccess the 1st element and store as vec_1_e1\nAccess the 5th through 7th elements and store as vec_1_e5to7\nReassign vec_1 as a character using as.character, stored as vec_1_char. What does the output look like?\n\n\n\n\n\n\n\nSolution\n\n\n\n\nvec_1 &lt;- c(2, 5, 9, 10, 8, 12, 1, 0) # Create vector\nvec_1 # View vector\n\n[1]  2  5  9 10  8 12  1  0\n\nclass(vec_1) # Check vector class\n\n[1] \"numeric\"\n\ntypeof(vec_1) # Check data type\n\n[1] \"double\"\n\nvec_1_e3 &lt;- vec_1[3] # Extract 3rd element\nvec_1_e3 # Print element\n\n[1] 9\n\nvec_1_e1 &lt;- vec_1[1] # Extract 1st element\nvec_1_e1 # Print element\n\n[1] 2\n\nvec_1_e5to7 &lt;- vec_1[5:7] # Extract 5th-7th elements\nvec_1_e5to7 # Print elements\n\n[1]  8 12  1\n\nvec_1_char &lt;- as.character(vec_1) # Reassign to character vector\nvec_1_logical &lt;- as.logical(vec_1) # Reassign to logical vector\n\n\n\n\nCreate a vector called vec_2 of named elements, where town = \"Santa Barbara, location = \"Rincon\", swell = \"south\"\n\n\nTake a look at what you’ve made\nWhat is the class of vector elements? class()\nWhat is the length of vec_2?\nAccess the 2nd element by name and store as vec_2_e2\n\n\n\n\n\n\n\nSolution\n\n\n\n\nvec_2 &lt;- c(town = \"Santa Barbara\", location = \"Rincon\", swell = \"south\")\nvec_2 # View vector\n\n           town        location           swell \n\"Santa Barbara\"        \"Rincon\"         \"south\" \n\nclass(vec_2) # Check vector class\n\n[1] \"character\"\n\nlength(vec_2) # Check vector length\n\n[1] 3\n\nvec_2_e2 &lt;- vec_2[2] # Extract 2nd element\nvec_2_e2 # Print element\n\nlocation \n\"Rincon\" \n\n\n\n\n\nCreate a data frame in R\n\n\nReturn the class of the entire data frame\nReturn the class of the species column\nFind the maximum value of the count() column, store as max_count\n\n\n\n\n\n\n\nSolution\n\n\n\n\ndf_1 &lt;- data.frame(region = c(\"A\", \"B\", \"A\",\"D\"),\n                   species = c(\"otter\", \"great white\", \"sea lion\", \"gray whale\"),\n                   count = c(12, 2, 36, 6))\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\nclass(df_1) # Check df class\n\n[1] \"data.frame\"\n\nclass(df_1$species) # Check species column class\n\n[1] \"character\"\n\nmax_count &lt;- max(df_1$count) # Find maximum value of count column\nmax_count # Print maximum value\n\n[1] 36"
  },
  {
    "objectID": "course-materials/eod-keys/eod-day2-key.html#wild-data",
    "href": "course-materials/eod-keys/eod-day2-key.html#wild-data",
    "title": "Day 2: Tasks & activities - KEY",
    "section": "Wild data",
    "text": "Wild data\n\nRead in the data using read_csv() with here(), store as mack_verts\n\n\n\n\n\n\n\nSolution\n\n\n\n\nmack_verts &lt;- read_csv(here::here(\"data\", \"AS00601.csv\"))\nView(mack_verts) # View dataset\n\n\n\n\nUpdate the variable names in mack_verts to lower snake case\n\n\n\n\n\n\n\nSolution\n\n\n\n\nmack_verts &lt;- clean_names(mack_verts) # Update to lower snake case\n\n\n\n\nIn a new code chunk, practice accessing individual pieces of the data frame:\n\n\nStore the 5th value in column WEIGHT as mc_wt_5\nStore the 8th - 20th value in the LENGTH1 column as mc_length_8_20\nStore everything in column SAMPLEDATE as a vector called mc_dates\n\n\n\n\n\n\n\nSolution\n\n\n\n\nmc_wt_5 &lt;- mack_verts[5, 'weight'] # Extract 5th value in column `weight`\nmc_wt_5 # Print value\n\n# A tibble: 1 × 1\n  weight\n   &lt;dbl&gt;\n1    6.9\n\nmc_length_8_20 &lt;- mack_verts[8:20, 'length1'] # Extract 8th-20th values in column `length1`\nmc_length_8_20 # Print values\n\n# A tibble: 13 × 1\n   length1\n     &lt;dbl&gt;\n 1     131\n 2     103\n 3     117\n 4     100\n 5     127\n 6      99\n 7     111\n 8     149\n 9     102\n10      53\n11      58\n12      58\n13     105\n\nmc_dates &lt;- mack_verts[,'sampledate'] # Extract column `sampledate`\nmc_dates &lt;- mack_verts$sampledate # Extract column `sampledate`\n\n\n\n\nCreate a subset that only contains observations for Pacific Giant Salamanders (species Dicamptodon tenebrosus, stored in species as DITE). Store the subset as mc_salamanders. Hint: see dplyr::filter()!\n\n\n\n\n\n\n\nSolution\n\n\n\n\nmc_salamanders &lt;- mack_verts |&gt;  \n  filter(species == \"DITE\") # Keep rows where species == \"DITE\"\n\n\n\n\nCreate a scatterplot of length1 (snout-vent length in millimeters) versus weight (grams) for all salamanders in the subset you created above, mc_salamanders\n\n\n\n\n\n\n\nSolution\n\n\n\n\nsalamander_plot &lt;- ggplot(data = mc_salamanders,\n                          aes(x = length1, y = weight)) + \n  geom_point(alpha = 0.5, color = \"purple\") +\n  theme_minimal()\n\nsalamander_plot # View plot\n\n\n\n\n\n\n\n\n\n\n\nExport your scatterplot as salamander_size.png to your figs folder.\n\n\n\n\n\n\n\nSolution\n\n\n\n\nggsave(plot = salamander_plot, here::here(\"figs\", \"salamander_size.png\"))\n\n\n\n\nMake a subset called mc_trout that only contains observations for cutthroat trout\n\n\n\n\n\n\n\nSolution\n\n\n\n\nmc_trout &lt;- mack_verts |&gt; \n  filter(species == \"ONCL\") # Keep rows where species == \"ONCL\"\n\n\n\n\nCreate a scatterplot of length1 by weight for all trout in the dataset\n\n\nCustomize so that the point color depends on reach\nCustomize your color scheme (e.g. scale_color_manual())\nFacet your plot by creek reach (hint: facet_wrap(~...))\nUpdate graph axis labels and title\nExport your graph as cutthroat_size.png to the figs folder\n\n\n\n\n\n\n\nSolution\n\n\n\n\nunique(mc_trout$reach) # Check unique values in column\n\n[1] \"L\" \"M\" \"U\"\n\n# Create named vector of custom colors\ncustom_colors &lt;- c(\"L\" = \"darkblue\", \"M\" = \"darkgreen\", \"U\" = \"orange\") \n\nggplot(data = mc_trout, aes(x = length1, y = weight)) +\n  geom_point(aes(color = reach)) +\n  scale_color_manual(values = custom_colors) + # Assign custom colors\n  facet_wrap(~reach) + # Facet by variable `reach`\n  theme_minimal()"
  },
  {
    "objectID": "course-materials/eod-keys/eod-day3-key.html",
    "href": "course-materials/eod-keys/eod-day3-key.html",
    "title": "Day 3: Tasks & activities - KEY",
    "section": "",
    "text": "Create an object called pm2_5 with a value of 48 (representing Particulate Matter 2.5, an indicator for air quality, in $). Write an if - else if - else statement that returns “Low to moderate risk” if pm2_5 is less than 100, “Unhealthy for sensitive groups” if PM 2.5 is 100 &lt;= pm2_5 &lt; 150, and “Health risk present” if PM 2.5 is &gt;= 150\n\n\n\n\n\n\n\nSolution\n\n\n\n\npm2_5 &lt;- 48\n\nif (pm2_5 &lt; 100) {\n  print(\"Low to moderate health risk\")\n} else if (pm2_5 &gt;= 100 & pm2_5 &lt; 150) {\n  print(\"Unhealthy for sensitive groups\")\n} else if (pm2_5 &gt;= 150) {\n  print(\"Health risk present\")\n}\n\n[1] \"Low to moderate health risk\"\n\n\n\n\n\nStore the string “blue whale” as an object called species. Write an if statement that returns “You found a whale!” if the string “whale” is detected in species, otherwise return nothing\n\n\n\n\n\n\n\nSolution\n\n\n\n\nspecies &lt;- \"gray whale\"\n\nif (str_detect(species, \"whale\")) {\n  print(\"You found a whale!\")\n}\n\n[1] \"You found a whale!\"\n\n\n\n\n\nStore the base price of a burrito as base_burrito with a value of 6.50. Store main_ingredient with a starting string of “veggie.” Write a statement that will return the price of a burrito based on what a user specifies as “main_ingredient” (either “veggie”, “chicken” or “steak”) given the following:\n\n\nA veggie burrito is the cost of a base burrito\nA chicken burrito costs 3.00 more than a base burrito\nA steak burrito costs 3.25 more than a base burrito\n\n\n\n\n\n\n\nSolution\n\n\n\n\nbase_burrito &lt;- 6.50\nmain_ingredient &lt;- \"steak\"\n\nif (main_ingredient == \"veggie\") {\n  price = base_burrito\n} else if (main_ingredient == \"chicken\") {\n  price = base_burrito + 3.00\n} else if (main_ingredient == \"steak\") {\n  price = base_burrito + 3.25\n}\n\nprint(price)\n\n[1] 9.75"
  },
  {
    "objectID": "course-materials/eod-keys/eod-day3-key.html#part-1",
    "href": "course-materials/eod-keys/eod-day3-key.html#part-1",
    "title": "Day 3: Tasks & activities - KEY",
    "section": "",
    "text": "Loading packages:\n\nlibrary(dplyr)"
  },
  {
    "objectID": "course-materials/eod-keys/eod-day3-key.html#part-2---real-data",
    "href": "course-materials/eod-keys/eod-day3-key.html#part-2---real-data",
    "title": "Day 3: Tasks & activities - KEY",
    "section": "Part 2 - Real data",
    "text": "Part 2 - Real data\nOpening and cleaning:\n\ntoolik_biochem &lt;- read.csv(here::here(\"data\", \"2011_Kling_Akchem.csv\") , na.strings = c(\".\", \"NA\"))\ntoolik_biochem &lt;- janitor::clean_names(toolik_biochem)\n\nChecking the variables names:\n\nvariable.names(toolik_biochem)\n\nCreating subset:\n\ninlet_biochem &lt;- toolik_biochem %&gt;% dplyr::select(p_h,doc_u_m, tdn_u_m)\n\nFinding the mean value of each column:\nUsing a for loop:\n\n# Vector where I will store the means\nmean_column &lt;- c()\n\nfor (i in 1:ncol(inlet_biochem)){\n  mean_column &lt;- c(mean_column, mean(inlet_biochem[,i], na.rm=TRUE))\n}\n\nUsing purrr:map_df:\n\nlibrary(purrr)\nmean_df &lt;- inlet_biochem %&gt;%\n  map_df(~ mean(.x, na.rm = TRUE))"
  },
  {
    "objectID": "course-materials/eod-keys/eod-day4-key.html",
    "href": "course-materials/eod-keys/eod-day4-key.html",
    "title": "Day 4: Tasks & activities - KEY",
    "section": "",
    "text": "Create two sequences, one called weekdays that contains days of the week (“Monday”, “Tuesday”, “Wednesday”, etc.) and one called transects that contains the series of transect names “Transect A”, “Transect B,”Transect C”. Write a nested for loop that creates a matrix containing the following:\n\n\n\n\n\n\n\nSolution\n\n\n\n\nweekdays &lt;- c(\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\")\n\ntransects &lt;- c(\"Transect A\", \"Transect B\", \"Transect C\")\n\nstudy_matrix &lt;- matrix(ncol = length(transects),\n                       nrow = length(weekdays))\n\nfor (i in seq_along(weekdays)) {\n  \n  for (j in seq_along(transects)) {\n    \n    study &lt;- paste0(weekdays[i], \" - \", transects[j])\n    study_matrix[i, j] &lt;- study\n    \n  }\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\nMonday - Transect A\nMonday - Transect B\nMonday - Transect C\n\n\nTuesday - Transect A\nTuesday - Transect B\nTuesday - Transect C\n\n\nWednesday - Transect A\nWednesday - Transect B\nWednesday - Transect C\n\n\nThursday - Transect A\nThursday - Transect B\nThursday - Transect C\n\n\nFriday - Transect A\nFriday - Transect B\nFriday - Transect C\n\n\nSaturday - Transect A\nSaturday - Transect B\nSaturday - Transect C\n\n\nSunday - Transect A\nSunday - Transect B\nSunday - Transect C\n\n\n\n\n\n\n\n\n\n\nWrite a function called force that calculates a force (in Newtons), given inputs of mass (in kg) and acceleration (in \\(\\frac{m}{s^2}\\) (recall: \\(F = ma\\)), and returns a statement “The resulting force is ___ Newtons.”\n\n\n\n\n\n\n\nSolution\n\n\n\n\nforce &lt;- function(mass, acceleration) {\n  force_val &lt;- mass * acceleration\n  print(paste(\"The resulting force is\", force_val, \"Newtons.\"))\n}\n\nforce(100, 2.9)\n\n[1] \"The resulting force is 290 Newtons.\"\n\n\n\n\n\nThe length:weight relationship for fish is: \\(W=aL^b\\), where where L is total fish length (centimeters), W is the expected fish weight (grams), and a and b are species-dependent parameter values (shown below for several fish from Peyton et al. 2016).\n\n\n\n\n\n\nsci_name\ncommon_name\na_est\nb_est\n\n\n\n\nChanos chanos\nMilkfish\n0.0905\n2.52\n\n\nSphyraena barracuda\nGreat barracuda\n0.0181\n3.27\n\n\nCaranx ignobilis\nGiant trevally\n0.0353\n3.05\n\n\n\n\n\n\n\nRecreate the table above as a data frame stored as fish_parms. Then, write a function called fish_weight that allows a user to only enter the common name (argument fish_name) and total length (argument tot_length) (in centimeters) of a fish, to return the expected fish weight in grams. Test it out for different species and lengths.\n\n\n\n\n\n\nSolution\n\n\n\n\nfish_weight &lt;- function(fish_name, tot_length) {\n  \n  fish_sub &lt;- fish_parms |&gt; \n    filter(common_name == fish_name)\n  \n  wt &lt;- fish_sub$a_est * (tot_length ^ fish_sub$b_est)\n  \n  return(wt)\n}\n\nfish_weight(fish_name = \"Milkfish\", tot_length = 57)\n\n[1] 2406.873\n\n\n\n\nNow, try creating a vector of lengths (e.g. 0 to 100, by increments of 1) and ensuring that your function will calculate the fish weight over a range of lengths for the given species (try this for milkfish, storing the output weights as milkfish_weights.\n\n\n\n\n\n\nSolution\n\n\n\n\n# Create the vector of lengths\nlengths_vector &lt;- seq(from = 0, to = 100, by = 1)\n\n# Send it to the function: \nmilkfish_weights &lt;- fish_weight(fish_name = \"Milkfish\", tot_length = lengths_vector)\n\n\n\n\nWave power (more accurately wave energy flux) in deep water is approximated by:\n\n\\[P_{deep}=0.5 H^2 T\\]\nwhere \\(P\\) is power in \\(\\frac{kW}{m}\\) (potential power per wave meter), \\(H\\) is wave height in meters (more specifically, the significant wave height), and \\(T\\) is the wave period in seconds. Learn more here.\nWrite a function called wave_power that calculates potential ocean wave power given inputs of wave height and period.\n\n\n\n\n\n\nSolution\n\n\n\n\nwave_power &lt;- function(wave_height, wave_period) {\n  0.5 * (wave_height ^ 2) * wave_period\n}\n\n\nwave_heights &lt;- seq(from = 0, to = 3, by = 0.2)\n\nwave_power(wave_height = wave_heights, wave_period = 8)\n\n [1]  0.00  0.16  0.64  1.44  2.56  4.00  5.76  7.84 10.24 12.96 16.00 19.36\n[13] 23.04 27.04 31.36 36.00\n\n\n\n\n\nThe wave energy equation changes based on ocean depth. Along the coast of Brenville, which has a very sharp shelf as the wave approaches the coast, wave energy is approximated using the deep ocean equation (the one you used above) for depths &gt; 12 meters, and a shallow equation for depths &lt;= 12 meters. The Brenville team estimates shallow wave power by:\n\n\\[P_{shallow}=0.81 H^2 T\\]\nCreate a function that requires inputs of water depth, wave height and period, then returns the approximated wave power using the correct equation for the depth entered. It should also include a message (hint: use message() just like you would use warning!) that lets the user know if the shallow or deep water equation was used.\n\n\n\n\n\n\nSolution\n\n\n\n\nbrenville_waves &lt;- function(wave_height, wave_period, depth) {\n  \n  if (depth &gt; 12) {\n    message(\"Using the deep wave equation.\")\n    bren_wave_energy &lt;- 0.5 * (wave_height ^ 2) * wave_period\n  }\n  \n  else if (depth &lt;= 12) {\n    message(\"Using the shallow wave equation.\")\n    bren_wave_energy &lt;- 0.81 * (wave_height ^ 2) * wave_period\n  }\n  \n  return(bren_wave_energy)\n}\n\nbrenville_waves(wave_height = 5, wave_period = 10, depth = 4)\n\nUsing the shallow wave equation.\n\n\n[1] 202.5"
  },
  {
    "objectID": "course-materials/eod-keys/eod-day4-key.html#task-1",
    "href": "course-materials/eod-keys/eod-day4-key.html#task-1",
    "title": "Day 4: Tasks & activities - KEY",
    "section": "",
    "text": "Create two sequences, one called weekdays that contains days of the week (“Monday”, “Tuesday”, “Wednesday”, etc.) and one called transects that contains the series of transect names “Transect A”, “Transect B,”Transect C”. Write a nested for loop that creates a matrix containing the following:\nCreating the sequences:\n\nweekdays &lt;- c(\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\")\ntransect &lt;- c(\"Transect A\", \"Transect B\", \"Transect C\")\n\nCreating a matrix using a nested loop:\n\n# Creating matrix:\nmatrix &lt;- matrix(1:9, nrow = 7, ncol = 3)\n\n#Nested loop:\nfor (i in seq_along(weekdays)) { # Outer loop is the growth rates\n  for (j in seq_along(transect)) { # Inner loop is the time sequence values\n  matrix[i,j] &lt;- paste(weekdays[i], \"-\", transect[j])\n  } \n}\nmatrix"
  },
  {
    "objectID": "course-materials/eod-keys/eod-day4-key.html#task-2",
    "href": "course-materials/eod-keys/eod-day4-key.html#task-2",
    "title": "Day 4: Tasks & activities - KEY",
    "section": "Task 2",
    "text": "Task 2\nWriting the function:\n\nforce &lt;- function(mass,acc){\n  force = mass*acc\n  print(paste(\"The resulting force is\", force, \"Newtowns\"))\n}\n\nChecking if it works:\n\nforce(10,6)"
  },
  {
    "objectID": "course-materials/eod-keys/eod-day4-key.html#task-3",
    "href": "course-materials/eod-keys/eod-day4-key.html#task-3",
    "title": "Day 4: Tasks & activities - KEY",
    "section": "Task 3",
    "text": "Task 3\nCreating the data frame:\n\nfish_parms &lt;- data.frame(\nsci_name= c(\"Chanos chanos\",\"Sphyraena barracuda\",\"Sphyraena barracuda\"),\ncommon_name = c(\"Milkfish\",\"Great barracuda\",\"Great barracuda\"),\na_est = c(0.0905, 0.0181    ,0.0353 ),\nb_est = c(2.52, 3.27, 3.05)\n)\n\nCreating the function:\n\nfish_weight &lt;- function(name, length){\n  i &lt;- which(fish_parms$common_name == name)\n  a&lt;-fish_parms[i,3]\n  b&lt;-fish_parms[i,4]\n  w= a *(length^b)\n  return(w)\n}\n\nTesting:\n\nfish_weight('Milkfish', 10)"
  },
  {
    "objectID": "course-materials/eod-keys/eod-day4-key.html#task-4",
    "href": "course-materials/eod-keys/eod-day4-key.html#task-4",
    "title": "Day 4: Tasks & activities - KEY",
    "section": "Task 4",
    "text": "Task 4\nCreating the function:\n\nwave_power &lt;- function(h, t){\n  p= 0.5 * t * h^2\n  return(p)\n}\n\nCreating the vector:\n\nwaves &lt;- seq(from = 0, to = 3, by = 0.2)\n\nApplying over the wave heights range:\n\nresult &lt;- sapply(waves, wave_power, t = 8)\nresult"
  },
  {
    "objectID": "course-materials/eod-keys/eod-day4-key.html#task-5",
    "href": "course-materials/eod-keys/eod-day4-key.html#task-5",
    "title": "Day 4: Tasks & activities - KEY",
    "section": "Task 5",
    "text": "Task 5\nCreating the function:\n\nwave_power &lt;- function(d,h, t){\n  if (d&lt;=12){\n     p= 0.81 * t * h^2\n      message(\"Message: Shallow water equation was used\")\n  } else {\n      p= 0.5 * t * h^2\n      message(\"Message: Deep water equation was used\")\n  }\n  return(p)\n}\n\nTesting:\n\nwave_power(10,3,1)"
  },
  {
    "objectID": "course-materials/eod-keys/eod-day3-key.html#conditional-statements",
    "href": "course-materials/eod-keys/eod-day3-key.html#conditional-statements",
    "title": "Day 3: Tasks & activities - KEY",
    "section": "",
    "text": "Create an object called pm2_5 with a value of 48 (representing Particulate Matter 2.5, an indicator for air quality, in $). Write an if - else if - else statement that returns “Low to moderate risk” if pm2_5 is less than 100, “Unhealthy for sensitive groups” if PM 2.5 is 100 &lt;= pm2_5 &lt; 150, and “Health risk present” if PM 2.5 is &gt;= 150\n\n\n\n\n\n\n\nSolution\n\n\n\n\npm2_5 &lt;- 48\n\nif (pm2_5 &lt; 100) {\n  print(\"Low to moderate health risk\")\n} else if (pm2_5 &gt;= 100 & pm2_5 &lt; 150) {\n  print(\"Unhealthy for sensitive groups\")\n} else if (pm2_5 &gt;= 150) {\n  print(\"Health risk present\")\n}\n\n[1] \"Low to moderate health risk\"\n\n\n\n\n\nStore the string “blue whale” as an object called species. Write an if statement that returns “You found a whale!” if the string “whale” is detected in species, otherwise return nothing\n\n\n\n\n\n\n\nSolution\n\n\n\n\nspecies &lt;- \"gray whale\"\n\nif (str_detect(species, \"whale\")) {\n  print(\"You found a whale!\")\n}\n\n[1] \"You found a whale!\"\n\n\n\n\n\nStore the base price of a burrito as base_burrito with a value of 6.50. Store main_ingredient with a starting string of “veggie.” Write a statement that will return the price of a burrito based on what a user specifies as “main_ingredient” (either “veggie”, “chicken” or “steak”) given the following:\n\n\nA veggie burrito is the cost of a base burrito\nA chicken burrito costs 3.00 more than a base burrito\nA steak burrito costs 3.25 more than a base burrito\n\n\n\n\n\n\n\nSolution\n\n\n\n\nbase_burrito &lt;- 6.50\nmain_ingredient &lt;- \"steak\"\n\nif (main_ingredient == \"veggie\") {\n  price = base_burrito\n} else if (main_ingredient == \"chicken\") {\n  price = base_burrito + 3.00\n} else if (main_ingredient == \"steak\") {\n  price = base_burrito + 3.25\n}\n\nprint(price)\n\n[1] 9.75"
  },
  {
    "objectID": "course-materials/eod-keys/eod-day3-key.html#for-loops",
    "href": "course-materials/eod-keys/eod-day3-key.html#for-loops",
    "title": "Day 3: Tasks & activities - KEY",
    "section": "For loops",
    "text": "For loops\n\nCreate a new vector called fish that contains the values 8, 10, 12, 23 representing counts of different fish types in a fish tank (goldfish, tetras, guppies, and mollies, respectively). Write a for loop that iterates through fish, and returns what proportion of total fish in the tank are that species. Assume that these counts represent all fish in the tank.\n\n\n\n\n\n\n\nSolution\n\n\n\n\nfish &lt;- c(goldfish = 8, tetras = 10, guppies = 12, mollies = 23)\n\nfor (i in seq_along(fish)) {\n  fish_prop &lt;- fish[i] / sum(fish)\n  print(fish_prop)\n}\n\n goldfish \n0.1509434 \n   tetras \n0.1886792 \n  guppies \n0.2264151 \n  mollies \n0.4339623 \n\n\n\n\n\nWrite a for loop that iterates over all months in month.name and prints “January is month 1,” “February is month 2”, etc.\n\nHint: you can index values in the month.name vector (e.g., try running month.name[5])\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\nmonth.name\n\n [1] \"January\"   \"February\"  \"March\"     \"April\"     \"May\"       \"June\"     \n [7] \"July\"      \"August\"    \"September\" \"October\"   \"November\"  \"December\" \n\nfor (i in seq_along(month.name)) {\n  print(paste(month.name[i], \"is month\", i))\n}\n\n[1] \"January is month 1\"\n[1] \"February is month 2\"\n[1] \"March is month 3\"\n[1] \"April is month 4\"\n[1] \"May is month 5\"\n[1] \"June is month 6\"\n[1] \"July is month 7\"\n[1] \"August is month 8\"\n[1] \"September is month 9\"\n[1] \"October is month 10\"\n[1] \"November is month 11\"\n[1] \"December is month 12\""
  },
  {
    "objectID": "course-materials/eod-keys/eod-day3-key.html#biogeochemistry-of-toolik-lake-north-slope-of-alaska",
    "href": "course-materials/eod-keys/eod-day3-key.html#biogeochemistry-of-toolik-lake-north-slope-of-alaska",
    "title": "Day 3: Tasks & activities - KEY",
    "section": "Biogeochemistry of Toolik Lake, North Slope of Alaska",
    "text": "Biogeochemistry of Toolik Lake, North Slope of Alaska\n\nRead in the data as toolik_biochem. Remember, you’ll want to specify here how NA values are stored. Pipe directly into janitor::clean_names() following your import code to get all column names into lower snake case.\n\n\n\n\n\n\n\nSolution\n\n\n\n\ntoolik_biochem &lt;- read_csv(here::here(\"data\", \"2011_Kling_Akchem.csv\"), na = c(\".\", \"NA\")) |&gt; janitor::clean_names()\n\n\n\n\nCreate a subset of the data that contains only observations from the “Toolik Inlet” site, and that only contains the variables (columns) for pH, dissolved organic carbon (DOC), and total dissolved nitrogen (TDN)\n\nHint: see dplyr::select()). Store this subset as inlet_biochem. Make sure to look at the subset you’ve created.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\nnames(toolik_biochem) # Check variable names\n\n [1] \"sort_chem\"             \"site\"                  \"date\"                 \n [4] \"time_hr_dst\"           \"depth_m\"               \"distance_km\"          \n [7] \"elevation_m\"           \"description_treatment\" \"catsort\"              \n[10] \"water_type\"            \"temp_c\"                \"cond_u_s\"             \n[13] \"p_h\"                   \"alk_ueq_l\"             \"pco2_uatm\"            \n[16] \"pch4_uatm\"             \"co2_u_m\"               \"ch4_u_m\"              \n[19] \"doc_u_m\"               \"nh4_u_m\"               \"po4_u_m\"              \n[22] \"no3_u_m\"               \"tdn_u_m\"               \"tdp_u_m\"              \n[25] \"pc_ug_l\"               \"pn_ug_l\"               \"pp_u_m\"               \n[28] \"ca_u_m\"                \"mg_u_m\"                \"na_u_m\"               \n[31] \"k_u_m\"                 \"si_u_m\"                \"so4_u_m\"              \n[34] \"cl_u_m\"                \"oxygen_mg_l\"           \"chla_ug_l\"            \n[37] \"phaeopigment_ug_l\"     \"chla_raw_ug_l\"         \"secchi_m\"             \n[40] \"thaw_depth_cm\"         \"x5cm_soil_temp_c\"      \"x10cm_soil_temp_c\"    \n[43] \"well_height_cm\"        \"discharge_lsec\"        \"stage_cm\"             \n\ninlet_biochem &lt;- toolik_biochem |&gt;\n  filter(site == \"Toolik Inlet\") |&gt;\n  select(p_h, doc_u_m, tdn_u_m)\n\n\n\n\nFind the mean value of each column in inlet_biochem 3 different ways:\n\n\nWrite a for loop from scratch to calculate the mean for each\nUse one other method (e.g. apply, across, or purrr::map_df) to find the mean for each column.\n\n\n\n\n\n\n\nSolution\n\n\n\n\nfor (i in seq_along(inlet_biochem)) {\n  mean_val &lt;- mean(inlet_biochem[[i]], na.rm = TRUE)\n  print(mean_val)\n}\n\n[1] 7.063182\n[1] 409.9615\n[1] 13.36538\n\napply(X = inlet_biochem, MARGIN = 2, FUN = mean, na.rm = TRUE)\n\n       p_h    doc_u_m    tdn_u_m \n  7.063182 409.961538  13.365385 \n\npurrr::map_df(.x = inlet_biochem, .f = mean, na.rm = TRUE)\n\n# A tibble: 1 × 3\n    p_h doc_u_m tdn_u_m\n  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1  7.06    410.    13.4"
  },
  {
    "objectID": "course-materials/eod-keys/eod-day5-key.html",
    "href": "course-materials/eod-keys/eod-day5-key.html",
    "title": "Day 5: Tasks & activities - KEY",
    "section": "",
    "text": "One established way to calculate the volume of stormwater expected for a watershed (necessary to design best management practices & systems) is the Simple Method, which involves two steps. First, the runoff coefficient \\(R_v\\) (storm runoff/storm rainfall) is calculated from:\n\\[R_v = 0.05 + 0.9 * I_A\\]\nWhere \\(R_v\\) is the runoff coefficient (unitless), and \\(I_A\\) is the fraction of the watershed that is considered “impervious” (unitless).\nThe volume of stormwater that needs to be handled, \\(V\\) in cubic feet, is then calculated by:\n\\[V=3630 * R_D * R_v * A\\] where \\(R_D\\) is the “design storm rainfall depth” in inches, usually set to 1.0 or 1.5, \\(R_v\\) is the runoff coefficient calculated above, and \\(A\\) is the watershed area in acres.\n\nCreate a function called predict_runoff that estimates the storm runoff volume using inputs for the impervious fraction and watershed area (you can use a constant value of 1 for \\(R_D\\) here)\n\n\n\n\n\n\n\nSolution\n\n\n\n\npredict_runoff &lt;- function(frac_impervious, watershed_area) {\n  \n  ifelse(frac_impervious &lt;= 1, TRUE, stop(\"NOPE\"))\n  \n  runoff_coef &lt;- 0.05 + 0.9 * frac_impervious\n  runoff_volume &lt;- 3630 * 1.0 * {runoff_coef} * watershed_area\n  print(runoff_volume)\n}\n\n\n#' Estimate storm runoff volume\n#'\n#' @param frac_impervious \n#' @param watershed_area \n#'\n#' @returns runoff_volume\n#' @export\n#'\n#' @examples\n#' \npredict_runoff &lt;- function(frac_impervious, watershed_area) {\n  \n  ifelse(frac_impervious &lt;= 1, TRUE, stop(\"NOPE\"))\n  \n  runoff_coef &lt;- 0.05 + 0.9 * frac_impervious\n  runoff_volume &lt;- 3630 * 1.0 * {runoff_coef} * watershed_area\n  print(runoff_volume)\n}\n\n\n\n\nSource your storm_runoff.R script so you are able to use the predict_runoff function in your .Rmd\n\n\n\n\n\n\n\nSolution\n\n\n\n\nsource(here::here(\"storm_runoff.R\"))\n\n\n\n\nIn a code chunk in your runoff_volumes.Rmd, use your predict_runoff function to estimate stormwater volume for a watershed of 182 acres, over a range of estimates for the impervious fraction (from 0.6 to 0.8, by increments of 0.01)\n\n\n\n\n\n\n\nSolution\n\n\n\n\n# Make the sequence of impervious fractions\nimpervious_sequence &lt;- seq(from = 0.6, to = 0.8, by = 0.01)\n\n# Make predictions for volume at all values of impervious fraction, for watershed area = 182\nval &lt;- predict_runoff(frac_impervious = impervious_sequence, watershed_area = 182)\n\n [1] 389789.4 395735.3 401681.3 407627.2 413573.2 419519.1 425465.0 431411.0\n [9] 437356.9 443302.9 449248.8 455194.7 461140.7 467086.6 473032.6 478978.5\n[17] 484924.4 490870.4 496816.3 502762.3 508708.2\n\n\n\n\n\nBind into a data frame\n\n\n\n\n\n\n\nSolution\n\n\n\n\nrunoff_df &lt;- data.frame(impervious_sequence, val)\n\n\n\n\nCreate a ggplot graph that has both dots and connecting lines (i.e., you’ll layer geom_point() and geom_line()). Update axis labels. Export a png of your graph to the figs folder using ggsave.\n\n\n\n\n\n\n\nSolution\n\n\n\n\nggplot(data = runoff_df, aes(x = impervious_sequence, y = val)) +\n  geom_point() +\n  geom_line() +\n  theme_minimal() +\n  labs(x = \"Fraction impervious surface in the watershed\",\n       y = \"Expected runoff volume (cubic feet)\")"
  },
  {
    "objectID": "course-materials/eod-keys/eod-day5-key.html#task-1",
    "href": "course-materials/eod-keys/eod-day5-key.html#task-1",
    "title": "Day 5: Tasks & activities - KEY",
    "section": "",
    "text": "Creating the function:\n\npredict_runoff &lt;- function(fraction,area){\n    v = 3630 * 1 * (0.05 + 0.9 * fraction) * area\n}\n\nUsing it:\n\nfraction &lt;- seq(from=0.6, to=0.8, by=0.01)\nest &lt;- predict_runoff(fraction,182)\n\nCreating data frame:\n\ndata_frame &lt;- data.frame(fraction,est)\n\nPlotting:\n\nlibrary(ggplot2)\n\nggplot(data=data_frame,aes(x=fraction,y=est)) +\n  geom_line()+\n  geom_point()+\n  labs(x=\"Fraction\", y=\"Estimate\")\n\nSaving:\n\nggsave(here::here(\"figs\", \"plot.png\"), height = 10, width = 10)"
  },
  {
    "objectID": "course-materials/eod-keys/eod-day5-key.html#task-2",
    "href": "course-materials/eod-keys/eod-day5-key.html#task-2",
    "title": "Day 5: Tasks & activities - KEY",
    "section": "Task 2",
    "text": "Task 2\nAttaching the packages we will use:\n\nlibrary(tidyverse)\nlibrary(here)\nlibrary(janitor)\n\nOpening the data:\n\nus_tilapia_imports &lt;- read.csv(here::here(\"data\", \"us_tilapia_imports.csv\"))\n\nExploring it:\n\n#Checking the variable names\nnames(us_tilapia_imports) \n\n\n#Checking the number of rows and columns(variables)\ndim(us_tilapia_imports) \n\nReshaping the dataset from wide to long:\n\nus_tilapia_imports &lt;- us_tilapia_imports %&gt;%\n  pivot_longer(\n    cols = starts_with(\"X\"),\n    names_to = \"year\",\n    names_prefix = \"X\",\n    values_to = \"imports\"\n  )\n\nChecking the year column type:\n\nclass(us_tilapia_imports$year)\nclass(us_tilapia_imports$imports)\n\nConveting to numeric:\n\nus_tilapia_imports &lt;- us_tilapia_imports %&gt;%\n  dplyr::mutate(year=as.numeric(year)) %&gt;%\n  mutate(imports = gsub(\"[^0-9.-]\", \"\", imports)) %&gt;% \n  mutate(imports = as.numeric(imports)) #also had to convert imports to numeric otherwise the next step wouldnt work\n\nSummarizing the data by year:\n\nyearly_tilapia_tot &lt;- us_tilapia_imports %&gt;% dplyr::group_by(year) %&gt;%\n  dplyr::summarise(imports=sum(imports))\n\nPlotting:\n\nyearly_tilapia_plot &lt;- ggplot(yearly_tilapia_tot, aes(x = year, y=imports)) +\n  geom_line() +\n  labs( x = \"Year\",  y = \"Imports\") +\n   theme_minimal()\nyearly_tilapia_plot"
  },
  {
    "objectID": "course-materials/eod-keys/eod-day4-key.html#for-loops-revisited",
    "href": "course-materials/eod-keys/eod-day4-key.html#for-loops-revisited",
    "title": "Day 4: Tasks & activities - KEY",
    "section": "",
    "text": "Create two sequences, one called weekdays that contains days of the week (“Monday”, “Tuesday”, “Wednesday”, etc.) and one called transects that contains the series of transect names “Transect A”, “Transect B,”Transect C”. Write a nested for loop that creates a matrix containing the following:\n\n\n\n\n\n\n\nSolution\n\n\n\n\nweekdays &lt;- c(\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\")\n\ntransects &lt;- c(\"Transect A\", \"Transect B\", \"Transect C\")\n\nstudy_matrix &lt;- matrix(ncol = length(transects),\n                       nrow = length(weekdays))\n\nfor (i in seq_along(weekdays)) {\n  \n  for (j in seq_along(transects)) {\n    \n    study &lt;- paste0(weekdays[i], \" - \", transects[j])\n    study_matrix[i, j] &lt;- study\n    \n  }\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\nMonday - Transect A\nMonday - Transect B\nMonday - Transect C\n\n\nTuesday - Transect A\nTuesday - Transect B\nTuesday - Transect C\n\n\nWednesday - Transect A\nWednesday - Transect B\nWednesday - Transect C\n\n\nThursday - Transect A\nThursday - Transect B\nThursday - Transect C\n\n\nFriday - Transect A\nFriday - Transect B\nFriday - Transect C\n\n\nSaturday - Transect A\nSaturday - Transect B\nSaturday - Transect C\n\n\nSunday - Transect A\nSunday - Transect B\nSunday - Transect C\n\n\n\n\n\n\n\n\n\n\nWrite a function called force that calculates a force (in Newtons), given inputs of mass (in kg) and acceleration (in \\(\\frac{m}{s^2}\\) (recall: \\(F = ma\\)), and returns a statement “The resulting force is ___ Newtons.”\n\n\n\n\n\n\n\nSolution\n\n\n\n\nforce &lt;- function(mass, acceleration) {\n  force_val &lt;- mass * acceleration\n  print(paste(\"The resulting force is\", force_val, \"Newtons.\"))\n}\n\nforce(100, 2.9)\n\n[1] \"The resulting force is 290 Newtons.\"\n\n\n\n\n\nThe length:weight relationship for fish is: \\(W=aL^b\\), where where L is total fish length (centimeters), W is the expected fish weight (grams), and a and b are species-dependent parameter values (shown below for several fish from Peyton et al. 2016).\n\n\n\n\n\n\nsci_name\ncommon_name\na_est\nb_est\n\n\n\n\nChanos chanos\nMilkfish\n0.0905\n2.52\n\n\nSphyraena barracuda\nGreat barracuda\n0.0181\n3.27\n\n\nCaranx ignobilis\nGiant trevally\n0.0353\n3.05\n\n\n\n\n\n\n\nRecreate the table above as a data frame stored as fish_parms. Then, write a function called fish_weight that allows a user to only enter the common name (argument fish_name) and total length (argument tot_length) (in centimeters) of a fish, to return the expected fish weight in grams. Test it out for different species and lengths.\n\n\n\n\n\n\nSolution\n\n\n\n\nfish_weight &lt;- function(fish_name, tot_length) {\n  \n  fish_sub &lt;- fish_parms |&gt; \n    filter(common_name == fish_name)\n  \n  wt &lt;- fish_sub$a_est * (tot_length ^ fish_sub$b_est)\n  \n  return(wt)\n}\n\nfish_weight(fish_name = \"Milkfish\", tot_length = 57)\n\n[1] 2406.873\n\n\n\n\nNow, try creating a vector of lengths (e.g. 0 to 100, by increments of 1) and ensuring that your function will calculate the fish weight over a range of lengths for the given species (try this for milkfish, storing the output weights as milkfish_weights.\n\n\n\n\n\n\nSolution\n\n\n\n\n# Create the vector of lengths\nlengths_vector &lt;- seq(from = 0, to = 100, by = 1)\n\n# Send it to the function: \nmilkfish_weights &lt;- fish_weight(fish_name = \"Milkfish\", tot_length = lengths_vector)\n\n\n\n\nWave power (more accurately wave energy flux) in deep water is approximated by:\n\n\\[P_{deep}=0.5 H^2 T\\]\nwhere \\(P\\) is power in \\(\\frac{kW}{m}\\) (potential power per wave meter), \\(H\\) is wave height in meters (more specifically, the significant wave height), and \\(T\\) is the wave period in seconds. Learn more here.\nWrite a function called wave_power that calculates potential ocean wave power given inputs of wave height and period.\n\n\n\n\n\n\nSolution\n\n\n\n\nwave_power &lt;- function(wave_height, wave_period) {\n  0.5 * (wave_height ^ 2) * wave_period\n}\n\n\nwave_heights &lt;- seq(from = 0, to = 3, by = 0.2)\n\nwave_power(wave_height = wave_heights, wave_period = 8)\n\n [1]  0.00  0.16  0.64  1.44  2.56  4.00  5.76  7.84 10.24 12.96 16.00 19.36\n[13] 23.04 27.04 31.36 36.00\n\n\n\n\n\nThe wave energy equation changes based on ocean depth. Along the coast of Brenville, which has a very sharp shelf as the wave approaches the coast, wave energy is approximated using the deep ocean equation (the one you used above) for depths &gt; 12 meters, and a shallow equation for depths &lt;= 12 meters. The Brenville team estimates shallow wave power by:\n\n\\[P_{shallow}=0.81 H^2 T\\]\nCreate a function that requires inputs of water depth, wave height and period, then returns the approximated wave power using the correct equation for the depth entered. It should also include a message (hint: use message() just like you would use warning!) that lets the user know if the shallow or deep water equation was used.\n\n\n\n\n\n\nSolution\n\n\n\n\nbrenville_waves &lt;- function(wave_height, wave_period, depth) {\n  \n  if (depth &gt; 12) {\n    message(\"Using the deep wave equation.\")\n    bren_wave_energy &lt;- 0.5 * (wave_height ^ 2) * wave_period\n  }\n  \n  else if (depth &lt;= 12) {\n    message(\"Using the shallow wave equation.\")\n    bren_wave_energy &lt;- 0.81 * (wave_height ^ 2) * wave_period\n  }\n  \n  return(bren_wave_energy)\n}\n\nbrenville_waves(wave_height = 5, wave_period = 10, depth = 4)\n\nUsing the shallow wave equation.\n\n\n[1] 202.5"
  },
  {
    "objectID": "course-materials/eod-practice/eod-day5.html#make-a-function-source-in-a-quarto-doc",
    "href": "course-materials/eod-practice/eod-day5.html#make-a-function-source-in-a-quarto-doc",
    "title": "Day 5: Task & Activities",
    "section": "2. Make a function, source in a Quarto doc",
    "text": "2. Make a function, source in a Quarto doc\n\n\n\n\n\n\nCitation\n\n\n\nNCDENR Stormwater BMP Manual\n\n\nOne established way to calculate the volume of stormwater expected for a watershed (necessary to design best management practices & systems) is the Simple Method, which involves two steps. First, the runoff coefficient \\(R_v\\) (storm runoff / storm rainfall) is calculated from: \\[R_v = 0.05 + 0.9 * I_A\\]\nWhere \\(R_v\\) is the runoff coefficient (unitless), and \\(I_A\\) is the fraction of the watershed that is considered “impervious” (unitless). The volume of stormwater that needs to be handled, \\(V\\) in cubic feet, is then calculated by: \\[V=3630 * R_D * R_v * A\\] where \\(R_D\\) is the “design storm rainfall depth” in inches, usually set to 1.0 or 1.5, \\(R_v\\) is the runoff coefficient calculated above, and \\(A\\) is the watershed area in acres.\nYOUR TASK:\n\nCreate a new R script in src, saved as storm_runoff.R\nIn the script, create a function called predict_runoff that estimates the storm runoff volume using inputs for the impervious fraction and watershed area (you can use a constant value of 1 for \\(R_D\\) here). In other words, your function should only require two arguments\nAdd documentation to your function using Roxygen comments for practice\nTry out your function in the Console to ensure that it works\nCreate a new R Markdown document in docs, saved as runoff_volumes.Rmd\nAttach the tidyverse and here packages\nSource your storm_runoff.R script so you are able to use the predict_runoff function in your .Rmd\nIn a code chunk in your runoff_volumes.Rmd, use your predict_runoff function to estimate stormwater volume for a watershed of 182 acres, over a range of estimates for the impervious fraction (from 0.6 to 0.8, by increments of 0.01). Note: you do not need to write a for loop here.\nBind your sequence of impervious fractions together with the resulting runoff volume calculated into a data frame\nCreate a ggplot graph that has both dots and connecting lines (i.e., you’ll layer geom_point() and geom_line()). Update axis labels. Export a png of your graph to the figs folder using ggsave."
  },
  {
    "objectID": "course-materials/eod-keys/eod-day5-key.html#estimate-storm-runoff-volume",
    "href": "course-materials/eod-keys/eod-day5-key.html#estimate-storm-runoff-volume",
    "title": "Day 5: Tasks & activities - KEY",
    "section": "",
    "text": "One established way to calculate the volume of stormwater expected for a watershed (necessary to design best management practices & systems) is the Simple Method, which involves two steps. First, the runoff coefficient \\(R_v\\) (storm runoff/storm rainfall) is calculated from:\n\\[R_v = 0.05 + 0.9 * I_A\\]\nWhere \\(R_v\\) is the runoff coefficient (unitless), and \\(I_A\\) is the fraction of the watershed that is considered “impervious” (unitless).\nThe volume of stormwater that needs to be handled, \\(V\\) in cubic feet, is then calculated by:\n\\[V=3630 * R_D * R_v * A\\] where \\(R_D\\) is the “design storm rainfall depth” in inches, usually set to 1.0 or 1.5, \\(R_v\\) is the runoff coefficient calculated above, and \\(A\\) is the watershed area in acres.\n\nCreate a function called predict_runoff that estimates the storm runoff volume using inputs for the impervious fraction and watershed area (you can use a constant value of 1 for \\(R_D\\) here)\n\n\n\n\n\n\n\nSolution\n\n\n\n\npredict_runoff &lt;- function(frac_impervious, watershed_area) {\n  \n  ifelse(frac_impervious &lt;= 1, TRUE, stop(\"NOPE\"))\n  \n  runoff_coef &lt;- 0.05 + 0.9 * frac_impervious\n  runoff_volume &lt;- 3630 * 1.0 * {runoff_coef} * watershed_area\n  print(runoff_volume)\n}\n\n\n#' Estimate storm runoff volume\n#'\n#' @param frac_impervious \n#' @param watershed_area \n#'\n#' @returns runoff_volume\n#' @export\n#'\n#' @examples\n#' \npredict_runoff &lt;- function(frac_impervious, watershed_area) {\n  \n  ifelse(frac_impervious &lt;= 1, TRUE, stop(\"NOPE\"))\n  \n  runoff_coef &lt;- 0.05 + 0.9 * frac_impervious\n  runoff_volume &lt;- 3630 * 1.0 * {runoff_coef} * watershed_area\n  print(runoff_volume)\n}\n\n\n\n\nSource your storm_runoff.R script so you are able to use the predict_runoff function in your .Rmd\n\n\n\n\n\n\n\nSolution\n\n\n\n\nsource(here::here(\"storm_runoff.R\"))\n\n\n\n\nIn a code chunk in your runoff_volumes.Rmd, use your predict_runoff function to estimate stormwater volume for a watershed of 182 acres, over a range of estimates for the impervious fraction (from 0.6 to 0.8, by increments of 0.01)\n\n\n\n\n\n\n\nSolution\n\n\n\n\n# Make the sequence of impervious fractions\nimpervious_sequence &lt;- seq(from = 0.6, to = 0.8, by = 0.01)\n\n# Make predictions for volume at all values of impervious fraction, for watershed area = 182\nval &lt;- predict_runoff(frac_impervious = impervious_sequence, watershed_area = 182)\n\n [1] 389789.4 395735.3 401681.3 407627.2 413573.2 419519.1 425465.0 431411.0\n [9] 437356.9 443302.9 449248.8 455194.7 461140.7 467086.6 473032.6 478978.5\n[17] 484924.4 490870.4 496816.3 502762.3 508708.2\n\n\n\n\n\nBind into a data frame\n\n\n\n\n\n\n\nSolution\n\n\n\n\nrunoff_df &lt;- data.frame(impervious_sequence, val)\n\n\n\n\nCreate a ggplot graph that has both dots and connecting lines (i.e., you’ll layer geom_point() and geom_line()). Update axis labels. Export a png of your graph to the figs folder using ggsave.\n\n\n\n\n\n\n\nSolution\n\n\n\n\nggplot(data = runoff_df, aes(x = impervious_sequence, y = val)) +\n  geom_point() +\n  geom_line() +\n  theme_minimal() +\n  labs(x = \"Fraction impervious surface in the watershed\",\n       y = \"Expected runoff volume (cubic feet)\")"
  },
  {
    "objectID": "course-materials/eod-keys/eod-day5-key.html#tilapia-imports-in-the-us",
    "href": "course-materials/eod-keys/eod-day5-key.html#tilapia-imports-in-the-us",
    "title": "Day 5: Tasks & activities - KEY",
    "section": "Tilapia imports in the US",
    "text": "Tilapia imports in the US\n\nRead in the data as us_tilapia_imports\n\n\n\n\n\n\n\nSolution\n\n\n\n\nus_tilapia_imports &lt;- read_csv(here::here(\"data\", \"us_tilapia_imports.csv\"))\n\n\nnames(us_tilapia_imports) # Check variable names\n\n [1] \"country\" \"1992\"    \"1993\"    \"1994\"    \"1995\"    \"1996\"    \"1997\"   \n [8] \"1998\"    \"1999\"    \"2000\"    \"2001\"    \"2002\"    \"2003\"    \"2004\"   \n[15] \"2005\"    \"2006\"    \"2007\"    \"2008\"    \"2009\"    \"2010\"    \"2011\"   \n[22] \"2012\"    \"2013\"    \"2014\"    \"2015\"    \"2016\"    \"2017\"    \"2018\"   \n\ndim(us_tilapia_imports)  # Check number of rows and columns\n\n[1] 207  28\n\n\n\n\n\nUse pivot_longer() to reshape the data into long format and coerce the year column to numeric\n\n\n\n\n\n\n\nSolution\n\n\n\n\nus_tilapia_imports_long &lt;- us_tilapia_imports |&gt; \n  pivot_longer(cols = '1992':'2018', \n               names_to = 'year', \n               values_to = 'tilapia_volume_kpounds') |&gt; \n  mutate(year = as.numeric(year))\n\n\n\n\nUse dplyr::group_by() %&gt;% summarize() to find the total US tilapia imports by year, store as yearly_tilapia_tot\n\n\n\n\n\n\n\nSolution\n\n\n\n\nyearly_tilapia_tot &lt;- us_tilapia_imports_long |&gt;  \n  group_by(year) |&gt; \n  summarize(annual_total = sum(tilapia_volume_kpounds, na.rm = TRUE))\n\n\n\n\nCreate a ggplot line graph of total US tilapia imports for all years in yearly_tilapia_tot. Update axis labels (include units as necessary), then export your graph as a .png to figs\n\n\n\n\n\n\n\nSolution\n\n\n\n\nggplot(data = yearly_tilapia_tot, aes(x = year, y = annual_total)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\n\nCreate a subset that only retains imports from Ecuador, Honduras, Costa Rica, and Mexico\n\n\n\n\n\n\n\nSolution\n\n\n\n\nlimited_us_tilapia &lt;- us_tilapia_imports_long |&gt; \n  filter(country %in% c(\"Ecuador\", \"Honduras\", \"Costa Rica\", \"Mexico\"))\n\n\n\n\nCreate a ggplot graph of total US tilapia imports over time, for those four countries in the subset you created above, separated by country. Update axis labels, add a title, customize your color scheme, update the theme. Export a .jpg of your graph to figs\n\n\n\n\n\n\n\nSolution\n\n\n\n\nggplot(data = limited_us_tilapia, \n       aes(x = year, y = tilapia_volume_kpounds)) +\n  geom_point(aes(color = country))"
  }
]